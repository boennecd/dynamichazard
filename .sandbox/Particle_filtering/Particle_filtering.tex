\RequirePackage{filecontents}

\begin{filecontents*}{PF.bib}
@article{doucet09,
  title={A tutorial on particle filtering and smoothing: Fifteen years later},
  author={Doucet, Arnaud and Johansen, Adam M},
  journal={Handbook of nonlinear filtering},
  volume={12},
  number={656-704},
  pages={3},
  year={2009}
}

@article{kitagawa96,
  title={Monte Carlo filter and smoother for non-Gaussian nonlinear state space models},
  author={Kitagawa, Genshiro},
  journal={Journal of computational and graphical statistics},
  volume={5},
  number={1},
  pages={1--25},
  year={1996},
  publisher={Taylor \& Francis}
}

@inproceedings{douc05,
  title={Comparison of resampling schemes for particle filtering},
  author={Douc, Randal and Capp{\'e}, Olivier},
  booktitle={Image and Signal Processing and Analysis, 2005. ISPA 2005. Proceedings of the 4th International Symposium on},
  pages={64--69},
  year={2005},
  organization={IEEE}
}

@article{carpenter99,
  title={Improved particle filter for nonlinear problems},
  author={Carpenter, James and Clifford, Peter and Fearnhead, Paul},
  journal={IEE Proceedings-Radar, Sonar and Navigation},
  volume={146},
  number={1},
  pages={2--7},
  year={1999},
  publisher={IET}
}

@article{pitt99,
  title={Filtering via simulation: Auxiliary particle filters},
  author={Pitt, Michael K and Shephard, Neil},
  journal={Journal of the American statistical association},
  volume={94},
  number={446},
  pages={590--599},
  year={1999},
  publisher={Taylor \& Francis}
}

@incollection{pitt01,
  title={Auxiliary variable based particle filters},
  author={Pitt, Michael K and Shephard, Neil},
  booktitle={Sequential Monte Carlo methods in practice},
  pages={273--293},
  year={2001},
  publisher={Springer}
}

@article{andrieu02,
  title={Particle filtering for partially observed Gaussian state space models},
  author={Andrieu, Christophe and Doucet, Arnaud},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={64},
  number={4},
  pages={827--836},
  year={2002},
  publisher={Wiley Online Library}
}

@article{fearnhead10,
  title={A sequential smoothing algorithm with linear computational cost},
  author={Fearnhead, Paul and Wyncoll, David and Tawn, Jonathan},
  journal={Biometrika},
  volume={97},
  number={2},
  pages={447--464},
  year={2010},
  publisher={Oxford University Press}
}

@inproceedings{briers05,
  title={Sequential auxiliary particle belief propagation},
  author={Briers, Mark and Doucet, Arnaud and Singh, Sumeetpal S},
  booktitle={Information Fusion, 2005 8th International Conference on},
  volume={1},
  pages={8--pp},
  year={2005},
  organization={IEEE}
}

@article{de97,
  title={The scan sampler for time series models},
  author={De Jong, Piet},
  journal={Biometrika},
  volume={84},
  number={4},
  pages={929--937},
  year={1997},
  publisher={Oxford University Press}
}

@article{briers10,
  title={Smoothing algorithms for state--space models},
  author={Briers, Mark and Doucet, Arnaud and Maskell, Simon},
  journal={Annals of the Institute of Statistical Mathematics},
  volume={62},
  number={1},
  pages={61--89},
  year={2010},
  publisher={Springer}
}

@article{kantas15,
  title={On particle methods for parameter estimation in state-space models},
  author={Kantas, Nikolas and Doucet, Arnaud and Singh, Sumeetpal S and Maciejowski, Jan and Chopin, Nicolas and others},
  journal={Statistical science},
  volume={30},
  number={3},
  pages={328--351},
  year={2015},
  publisher={Institute of Mathematical Statistics}
}

@article{malik11,
  title={Particle filters for continuous likelihood evaluation and maximisation},
  author={Malik, Sheheryar and Pitt, Michael K},
  journal={Journal of Econometrics},
  volume={165},
  number={2},
  pages={190--209},
  year={2011},
  publisher={Elsevier}
}

@article{schon11,
  title={System identification of nonlinear state-space models},
  author={Sch{\"o}n, Thomas B and Wills, Adrian and Ninness, Brett},
  journal={Automatica},
  volume={47},
  number={1},
  pages={39--49},
  year={2011},
  publisher={Elsevier}
}

@article{del10,
  title={Forward smoothing using sequential Monte Carlo},
  author={Del Moral, Pierre and Doucet, Arnaud and Singh, Sumeetpal},
  journal={arXiv preprint arXiv:1012.5390},
  year={2010}
}

@article{dempster77,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the royal statistical society. Series B (methodological)},
  pages={1--38},
  year={1977},
  publisher={JSTOR}
}

@inproceedings{klaas06,
  title={Fast particle smoothing: If I had a million particles},
  author={Klaas, Mike and Briers, Mark and De Freitas, Nando and Doucet, Arnaud and Maskell, Simon and Lang, Dustin},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={481--488},
  year={2006},
  organization={ACM}
}
\end{filecontents*}

\documentclass[9pt, notitlepage]{article}

\usepackage[round]{natbib}
\usepackage{amsmath} \usepackage{bm} \usepackage{amsfonts}
\usepackage{algorithm} \usepackage{algpseudocode} \usepackage{hyperref}
\usepackage{float}

% algorithm and algpseudocode definitions
\newcommand\StateX{\Statex\hspace{\algorithmicindent}}
\newcommand\StateXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}}
\newcommand\StateXXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}}

\algnewcommand{\UntilElse}[2]{\Until{#1\ \algorithmicelse\ #2}}

\algtext*{EndFor} \algtext*{EndProcedure}

\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}

\newcommand{\citeAlgLine}[2]{line~\ref{#1} of algorithm~\ref{#2}}
\newcommand{\citeAlgLineTwo}[3]{line~\ref{#1} and~\ref{#2} of algorithm~\ref{#3}}
\newcommand{\citeAlgLineTo}[3]{lines~\ref{#1}-\ref{#2} of algorithm~\ref{#3}}

% Math commands
\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\vect}[1]{\widetilde{\vec{#1}}}
\newcommand{\vecb}[1]{\bar{\vec{#1}}}
\newcommand{\vecLarrow}[1]{\overleftarrow{\vec{#1}}}
\newcommand{\vecLRarrow}[1]{\overleftrightarrow{\vec{#1}}}


\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\matt}[1]{\widetilde{\mat{#1}}}
\newcommand{\matLarrow}[1]{\overleftarrow{\mat{#1}}}
\newcommand{\matLRarrow}[1]{\overleftrightarrow{\mat{#1}}}

\newcommand{\Lbrac}[1]{\left[ #1\right]}
\newcommand{\Lbrace}[1]{\left\{ #1\right\}}
\newcommand{\Lparen}[1]{\left( #1\right)}
\newcommand{\Cond}[2]{\left. #1 \vphantom{#2} \right\vert  #2}

% Operators
\newcommand{\Prob}{\text{P}}
\newcommand{\VAR}{\text{Var}}
\newcommand{\E}{\text{E}}
\newcommand{\COV}{\text{E}}

\newcommand{\optor}[2]{#1\Lparen{#2}}
\newcommand{\optorC}[3]{\optor{#1}{\Cond{#2}{#3}}}

\newcommand{\prop}[1]{\optor{\Prob}{#1}}
\newcommand{\propC}[2]{\optorC{\Prob}{#1}{#2}}

\newcommand{\expec}[1]{\optor{\E}{#1}}
\newcommand{\expecC}[2]{\optorC{\E}{#1}{#2}}

\newcommand{\varp}[1]{\optor{\VAR}{#1}}
\newcommand{\varpC}[2]{\optorC{\VAR}{#1}{#2}}

\newcommand{\covp}[1]{\optor{\COV}{#1}}
\newcommand{\covpC}[2]{\optorC{\COV}{#1}{#2}}

\newcommand{\propAproxC}[2]{\optorC{\widetilde{p}}{#1}{#2}}

\newcommand{\dirac}[1]{\optor{\delta}{#1}}

% Normal distribution
\newcommand{\normal}[2]{\optor{\mathcal{N}}{#1,#2}}
\newcommand{\normalC}[3]{\optorC{\mathcal{N}}{#1}{#2,#3}}

% ID: Importance density 
\newcommand{\IDC}[2]{\optorC{q}{#1}{#2}}
\newcommand{\IDAproxC}[2]{\optorC{\widetilde{q}}{#1}{#2}}

% Diagonal operator
\newcommand{\diag}[1]{\optor{\text{diag}}{#1}}

% KF notation
\newcommand{\KF}[3]{#1_{\left. #2 \right\vert #3}}
\newcommand{\KFSup}[4]{#1_{\left. #2 \right\vert #3}^{(#4)}}

% PF notation
\newcommand{\partic}[3]{#1_{#2}^{\Lparen{#3}}}
% B for backwards
\newcommand{\particB}[3]{\widetilde{#1}_{#2}^{\Lparen{#3}}}
% S for smoothed
\newcommand{\particS}[3]{\widehat{#1}_{#2}^{\Lparen{#3}}}

\newcommand{\bigO}[1]{\mathcal{O}\Lparen{#1}}

% titlepage
\newcommand*{\myTitle}{\begingroup 
\centering 
{\LARGE Particle filters in the dynamichazard package} \\[\baselineskip]
\scshape

Benjamin Christoffersen \\[\baselineskip]
\today \\[\baselineskip]
\vspace*{3\baselineskip}
\endgroup}

\begin{document}
\myTitle
This is vignette covers the particle filter for the \verb|dynamichazard| package in \verb|R|. See \url{https://cran.r-project.org/web/packages/dynamichazard/vignettes/ddhazard.pdf} for more information on the package.

I assume that you are familiar with the setup in the \verb|dynamichazard| package and the other estimation methods in the package. Further, some prior knowledge of particle filters is required.  If you lag knowledge of particle filter then \cite{doucet09} provides a tutorial on particle filters and \cite{kantas15} covers parameter estimation with particle filters. This vignette relies heavily on \cite{fearnhead10}.

\section{Method}
\subsection*{Model}
The model is:

\begin{equation}
\begin{array}{ll}
 	y_{it} \sim \propC{y_{it}}{\theta_{it}} & \\
%
 	\vec{\theta}_{t} = \mat{X}_t\vec{\alpha}_t \\
% 
 	\vec{\alpha}_t = \mat{F}\vec{\alpha}_{t - 1} + \mat{R}\vec{\eta}_t &
 		\vec{\eta}_t \sim N\Lparen{\vec{0}, \mat{Q}} \\
%
	&	\vec{\alpha}_0 \sim N\Lparen{\vec{a}_0, \mat{Q}_0}
 \end{array}
\end{equation}%
%
where I  denote the conditional densities as $\vec{y}_t \sim \optorC{g}{\cdot}{\vec{\alpha}_t}$ and $\vec{\alpha}_t \sim \optorC{f}{\cdot}{\vec{\alpha}_{t-1}}$. We are in a survival analysis setting where the simplest model has an indicator of death of individual $i$ in time $t$ such that $y_{it} \in \Lbrace{0, 1}$ where $\theta_{it}$ is the linear predictor where we use the logistic function as the link function. For each $t=1,\dots,d$, we a have risk set given by $R_t \subseteq \Lbrace{1,2,\dots,n}$. The observed outcomes are denoted by $\vec{y}_t = \Lbrace{y_{it}}_{i \in R_t}$. $\mat{X}_t$ is the matrix of the covariates and $\vec{\alpha}_t \in \mathbb{R}^p$ is the time-varying coefficients. The problems we are looking at have $n \gg p$ (e.g. $n = 100000$ and $p = 20$). 

I will use a particle filter and smoother to get smoothed estimates of $\vec{\alpha}_1, \dots, \vec{\alpha}_d$ given the outcomes $\vec{y}_{1:d} = \Lbrace{\vec{y}_1,\vec{y}_2,\dots, \vec{y}_d}$ and use an EM-algorithm to estimate $\mat{Q}$ and $\vec{a}_0$. One choice of smoother is the generalized two-filter smoothing in \cite{fearnhead10} and \cite{briers10}. I have included the $\bigO{N}$ smoother in \cite{fearnhead10} shown in algorithm~\ref{alg:ONsmoother}. The rest of vignette is structured as follows: first I cover the particle filter and smoother. Then I cover the EM-algorithm and other miscellaneous topics. I will end with what is implemented at this point.

\subsection*{Considerations}
Algorithm~\ref{alg:ONsmoother} shows one of the generalized two-filter smoother from \cite{fearnhead10}. It requires that we specify the following importance densities and re-sampling weights ("optimal" values are given as the right hand side):

\begin{equation}\begin{matrix}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = \propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \\
	\partic{\beta}{t}{j} \propto \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j} \\
%
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}}\particB{\beta}{t}{k} \approx %
		\gamma_t\Lparen{\vec{\alpha}_t}
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\particB{w}{t + 1}{k}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
%
	\IDAproxC{\particS{\alpha}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} = 
		\propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}
\end{matrix}\end{equation}%
%
Further, we need to define a backwards filter distribution approximation:

\begin{equation}
	\propAproxC{\vec{\alpha}_t}{\vec{y}_{t:T}} \propto \gamma_t \Lparen{\vec{\alpha}_t}\propC{\vec{y}_{t:T}}{\vec{\alpha}_t}
\end{equation}% 
%
with an artificial prior distribution $\gamma_t \Lparen{\vec{\alpha}_t}$. See \cite{briers10} for how to select $\gamma_t$ and examples hereof. \cite{fearnhead10} also provide examples. 

Given the models of interest we have that:

\begin{itemize}
	\item Evaluating $\propC{\vec{y}_t}{\vec{\alpha}_t}$ is an expensive operation as $n \gg p$ and it has a $\bigO{np}$ computational cost. Any $\bigO{n}$ operation is going to take considerable time. 
	\item Evaluating $\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t -1}}$ and $\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t + 1}}$ is cheap and can be done in closed form and sampling from these distribution can be done in closed form.
	\item The second example in \cite{fearnhead10} is close to the model here though with $n = 1$ and $p = 2$. 
\end{itemize}

The following sections will closely follow the example shown in \cite{fearnhead10} and the appendix of the paper. 

\subsubsection*{Forward filter (algorithm~\ref{alg:forward})}
This section will cover some options for algorithm~\ref{alg:forward}. Let $\normalC{\cdot}{\cdot}{\cdot}$ denote a multivariate normal distribution. We can select the proposal density as:
\begin{equation}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = %
		\normalC{\vec{\alpha}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
\end{equation}%
%
which we can sample from in $\bigO{Np^2}$ time if we have a pre-computed Cholesky decomposition of $\mat{Q}$. This is often called the \emph{bootstrap filter}. Another option is to use normal approximation of $\vec{y}_t$'s conditional density:

\begin{equation}\begin{array}{cl}
	\optorC{g}{\vec{y}_t}{\vec{\alpha}_t} & \simeq  \optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\alpha}_t} \\ &= %
		\normalC{
			\mat{X}_t\vec{\alpha}_t
		}{ % end of arg1 \normalC
			\mat{X}_t\mat{F}\vecb{\alpha}_{t - 1} - 
			\mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
			\vec{g}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}
		}{ % end of arg2 \normalC
			- \mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
		}
\end{array}\end{equation}
%
% 
where:
\begin{equation}\begin{array}{c}
\mat{g}_t\Lparen{\vec{\alpha}} = 
		\Lbrace{\left.\frac{
		\partial \log \propC{y_{it}}{\theta_{it}}
	}{
		\partial\theta_{it}
	}\right|_{\theta_{it} = \vec{x}_{it}^\top\vec{\alpha}} }_{i \in R_t} \\
%
	\mat{G}_t\Lparen{\vec{\alpha}} = 
		\diag{\Lbrace{\left.\frac{
		\partial^2 \log \propC{y_{it}}{\theta_{it}}
	}{
		\partial\theta_{it}^2
	}\right|_{\theta_{it} = \vec{x}_{it}^\top\vec{\alpha}} }_{i \in R_t}}
\end{array}\end{equation}
%
%
to get:
\begin{equation}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \propto %
		\normalC{\vec{\alpha}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}}{\vec{y}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}
\end{equation}
%
%
Thus, we need to sample from:
\begin{equation}\label{eqn:TaylorProposalForward}\begin{array}{rcl}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} &=&  %
		\normalC{\vec{\alpha}_t}{\vec{\mu}_t}{\mat{\Sigma}_t} \\
%
	\mat{\Sigma}_t^{-1} &=& \mat{X}_t^\top 
		\Lparen{-\mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}}
		\mat{X}_t + \mat{Q}^{-1}  \\
%
	\vec{\mu}_t &=& \mat{\Sigma}_t\Lparen{
		\mat{Q}^{-1}\mat{F}\partic{\vec{\alpha}}{t-1}{j} + 
		\mat{X}_t^\top \Lparen{-\mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}}
		\Lparen{
			\mat{X}_t\mat{F}\vecb{\alpha}_{t - 1} - 
			\mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
			\vec{g}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}
		}
	} \\
%
	 &=& \mat{\Sigma}_t\Lparen{
		\mat{Q}^{-1}\mat{F}\partic{\vec{\alpha}}{t-1}{j} + 
		\mat{X}_t^\top
		\Lparen{
			\Lparen{-\mat{G}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}}
			\mat{X}_t\mat{F}\vecb{\alpha}_{t - 1} +
			\vec{g}_t\Lparen{\mat{F}\vecb{\alpha}_{t - 1}}
		}
	}
\end{array}\end{equation}
%
%

We can select  $\vecb{\alpha}_{t - 1}$ as the weighted mean given the particle cloud at time $t-1$ (that is, %
$\Lbrace{\partic{\vec{\alpha}}{t-1}{1}, \partic{\vec{\alpha}}{t-1}{2}, \dots \partic{\vec{\alpha}}{t-1}{N}}$%
). This is similar to the second order random walk example in \cite{fearnhead10}. They use the mode which is feasible as the outcome only depends on one element of the state vector. The downside is an $\bigO{np^2+p^3}$ computational cost though independent of the number of particles. The total cost of sampling is $\bigO{np^2+p^3 + Np^2}$. Another option is to set $\vecb{\alpha}_{t - 1} = \partic{\vec{\alpha}}{t-1}{j}$ for each particle $j = 1, 2, \dots, N$ in the particle cloud at time $t -1$. This will improve the Taylor expansion but yields an $\bigO{N\Lparen{np^2+p^3}}$ computational cost. 

Next, we have the re-sampling weights. A simple solution is not to use an auxiliary particle filter as in the examples of \cite{fearnhead10} and set:

\begin{equation}
	\partic{\beta}{t}{j} \propto \partic{w}{t-1}{j}
\end{equation}
%
which has an $\bigO{N}$ cost of sampling. Another options is to set:

\begin{equation}\label{eqn:FWWeights}
\begin{split}
	\partic{\beta}{t}{j} &\propto  \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j} \\
%
	& =  \partic{w}{t-1}{j} \int_{\vec{\alpha}_t} 
		\normalC{\vec{\alpha}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{g}{\vec{y}_t}{\vec{\alpha}_t}
		\partial \vec{\alpha}_t \\
%
	& \approx \partic{w}{t-1}{j} \int_{\vec{\alpha}_t} 
		\normalC{\vec{\alpha}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\alpha}_t}
		\partial \vec{\alpha}_t \\
%
	& \approx \frac{
		\partic{w}{t-1}{j}
		\normalC{\vec{\mu}_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\mu}_t}
	}{ % end of frac arg1
		\IDC{\vec{\mu}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t}
	}
\end{split}
\end{equation}

This come at an $\bigO{Np^2}$ computational cost assuming that we are using \eqref{eqn:TaylorProposalForward} already. Otherwise it has the same computational cost as mentioned when I covered the importance density since we have to make the Taylor expansion approximation. 

\subsubsection*{Backward filter (algorithm~\ref{alg:backward})}
We need to specify the artificial prior $\gamma_t\Lparen{\vec{\alpha}_t}$. \citet[page 69 and 70]{briers10} provides recommendation on the selection. This leads to:
\begin{equation}\begin{split}
	\gamma_t\Lparen{\vec{\alpha}_t} &=
		\normalC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t} \\
%
	\vecLarrow{m}_t &= \mat{F}^t\vec{a}_0 \\
%
	\matLarrow{P}_t &= \left\{
		\begin{matrix} \mat{Q}_0 & t = 0 \\ \mat{F}\mat{P}_{t - 1}\mat{F}^\top + \mat{Q} & t > 0   \end{matrix} \right.
\end{split}\end{equation}
%
%
\cite{fearnhead10} writes that then we end with:
\begin{equation}\begin{split}
	\propC{\vec{\alpha}_t}{\vec{\alpha}_{t+1}} &= 
	\normalC{\vec{\alpha}_t}{\vecLarrow{a}_t}{\matLarrow{S}_t} \\ 
%
	\matLarrow{S}_t &= \matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\mat{Q}\Lparen{\mat{F}^\top}^{-1} \\
%
	\vecLarrow{a}_t &= 
		\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\vec{\alpha}_{t+1}
		+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t
\end{split}\end{equation}%
%
which simplifies for the first order random walk to:

\begin{equation}\begin{split}
	\vecLarrow{m}_t &= \vec{a}_0 \\
%
	\matLarrow{P}_t &= t\mat{Q} + \mat{Q}_0 \\
%
	\matLarrow{S}_t &= 
		\Lparen{t\mat{Q} + \mat{Q}_0}
		\Lparen{(t+1)\mat{Q} + \mat{Q}_0}^{-1}\mat{Q} \\
%
	\vecLarrow{a}_t &= 
		\Lparen{t\mat{Q} + \mat{Q}_0}
		\Lparen{(t+1)\mat{Q} + \mat{Q}_0}^{-1}\vec{\alpha}_{t+1} 
		+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t
\end{split}\end{equation}%
%
Further, setting $\mat{Q}_0 = \mat{Q}$ (only in the artificial prior where we may alter $\gamma_0$ -- see \citet[page 70]{briers10}) gives us:
%
\begin{equation}\begin{split}\label{eqn:FirstOrderStrange}
	\matLarrow{S}_t &= 
		\mat{Q}^0 \\
%
	\vecLarrow{a}_t &= 
		\mat{Q}^{-1}\vec{\alpha}_{t+1}
		+ \frac{1}{t + 1}\mat{Q}^{-1}  \vec{a}_0
\end{split}\end{equation}
%
%
which makes no sense (assuming that I have not made an error) but this is what they write as the intermediate results in the appendix of \cite{fearnhead10}. I figure the result should have been:

\begin{equation}\begin{split}\label{eqn:bwTransProp}
	\propC{\vec{\alpha}_t}{\vec{\alpha}_{t+1}} &= 
	\normalC{\vec{\alpha}_t}{\vecLarrow{a}_t}{\matLarrow{Z}_t} \\ 
%
	\matLarrow{Z}_t &= 
		\Lparen{
			\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}
			+ \matLarrow{S}_t\matLarrow{P}_t^{-1}
		}^{-1} \\
%
	\vecLarrow{a}_t &= 
		\matLarrow{Z}_t\Lparen{
			\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\vec{\alpha}_{t+1}
			+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t
		}
\end{split}\end{equation}
%
%
such that the equivalent version of equation~\eqref{eqn:FirstOrderStrange} is:

\begin{equation}\begin{split}
	\matLarrow{Z}_t &= 
		\Lparen{\mat{Q}^{-1} + \frac{1}{t + 1}\mat{Q}^{-1}}^{-1} \\
%
	\vecLarrow{a}_t &= 
		\matLarrow{Z}_t\Lparen{
			\mat{Q}^{-1}\vec{\alpha}_{t+1}
			+ \frac{1}{t + 1}\mat{Q}^{-1}  \vec{a}_0
		}
\end{split}\end{equation}


The end results in the appendix of \cite{fearnhead10} make sense. This yields the following backward version of equation~\eqref{eqn:TaylorProposalForward}:
%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} &=   %
		\normalC{\vec{\alpha}_t}{\vecLarrow{\mu}_t}{\matLarrow{\Sigma}_t} \\
%
	\matLarrow{\Sigma}_t^{-1} &= 
		\mat{P}_t^{-1} + 
		\mat{X}_t^\top\Lparen{-\mat{G}_t\Lparen{\mat{F}^{-1}\vecb{\alpha}_{t + 1}}}
		\mat{X}_t + \mat{F}^{-1}\mat{Q}^{-1}\Lparen{\mat{F}^{-1}}^\top  \\
%
	\vecLarrow{\mu}_t 
	 &=  \matLarrow{\Sigma}_t \Lparen{
		\matLarrow{P}_t^{-1}\vecLarrow{m}_t + 
		\mat{F}^{-1}\mat{Q}^{-1}\particB{\vec{\alpha}}{t + 1}{k} + 
		\mat{X}_t^\top
		\Lparen{
			\Lparen{-\mat{G}_t\Lparen{\mat{F}^{-1}\vecb{\alpha}_{t + 1}}}
			\mat{X}_t\mat{F}^{-1}\vecb{\alpha}_{t + 1} +
			\vec{g}_t\Lparen{\mat{F}^{-1}\vecb{\alpha}_{t + 1}}
		}}
\end{split}\end{equation}
%
%
which is (/should be) an approximation of:

\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} & \propto  
		\optorC{g}{\vec{y}_t}{\vec{\alpha}_t}
		\optorC{f}{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\gamma_t\Lparen{\vec{\alpha}_t}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
%
	& \approx \optorC{\widetilde{g}}{\vec{y}_t}{\vec{\alpha}_t}
		\normalC{\particB{\vec{\alpha}}{t + 1}{k}}{\mat{F}\vec{\alpha}_t}{\mat{Q}}
		\frac{
			\normalC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t}
		}{ % End of frac arg1
			\normalC{\particB{\vec{\alpha}}{t + 1}{k}}{\vecLarrow{m}_{t + 1}}{\matLarrow{P}_{t + 1}}
		}
\end{split}\end{equation}

The re-sampling weights can be computed similarly to the forward filter using the backward proposal density in equation~\eqref{eqn:bwTransProp} in the numerator for the backward transition density. We can also use a bootstrap like filter with the importance density by sampling from~\eqref{eqn:bwTransProp}.

\subsubsection*{Combining / smoothing (algorithm~\ref{alg:ONsmoother})}
We need to specify the importance density $\IDAproxC{\cdot}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}$ (see \citet[page 453] {fearnhead10}). Again, we can use a similar idea to those in the appendix of \cite{fearnhead10} and choose:

\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}  &=   %
		\normalC{\vec{\alpha}_t}{\vecLRarrow{\mu}_t}{\matLRarrow{\Sigma}_t} \\
%
	\matLRarrow{\Sigma}_t^{-1} &= 
		\mat{Q}^{-1} + 
		\mat{X}_t^\top\Lparen{-\mat{G}_t\Lparen{\vecb{\alpha}_{t}}}
		\mat{X}_t + \mat{F}^{-1}\mat{Q}^{-1}\Lparen{\mat{F}^{-1}}^\top  \\
%
	\vecLRarrow{\mu}_t 
	 &=  \matLRarrow{\Sigma}_t \Lparen{
		\mat{Q}^{-1}\partic{\vec{\alpha}}{t-1}{j} + 
		\mat{F}^{-1}\mat{Q}^{-1}\particB{\vec{\alpha}}{t + 1}{k} + 
		\mat{X}_t^\top
		\Lparen{
			\Lparen{-\mat{G}_t\Lparen{\vecb{\alpha}_{t}}}
			\mat{X}_t\vecb{\alpha}_{t} +
			\vec{g}_t\Lparen{\vecb{\alpha}_{t}}
		}}
\end{split}\end{equation}%
%
where $\vecb{\alpha}_{t}$ can be a combined mean given the cloud means at time $t - 1$ and $t + 1$ or a mean for each of the  two drawn particles in the $(j_i,k_i)$ pairs. This is to approximate:
%
%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} \propto %
%
	\optorC{\widetilde{g}}{\vec{y}_t}{\vec{\alpha}_t}
		\optorC{f}{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}}
		\frac{
			\optorC{f}{\particB{\vec{\alpha}}{t+1}{k}}{\vec{\alpha}_t}
		}{
			\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t+1}{k}}
		}
\end{split}\end{equation}
%
We can also use a bootstrap like filter by sampling from:

\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} &=
		\normalC{\vec{\alpha}_t}{\vect{m}}{\matt{S}} \\
%
	\matt{S} &= \Lparen{\mat{Q}^{-1} + \mat{F}^{-1}\mat{Q}^{-1}\Lparen{\mat{F}^{-1}}^\top}^{-1} \\
% 
	\vect{m} &= \matt{S}\Lparen{
			 \mat{Q}^{-1}\mat{F}\partic{\vec{\alpha}}{t-1}{j} +
			 \mat{F}^{-1}\mat{Q}^{-1}\particB{\vec{\alpha}}{t + 1}{k}}
\end{split}\end{equation}

\newpage

\begin{algorithm}[H]
\caption{$\bigO{N}$ generalized two filter smoother using the method in \cite{fearnhead10}.}\label{alg:ONsmoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $\mat{Q},\mat{Q}_0,\vec{a}_0,\mat{X}_1,\dots,\mat{X}_d,\vec{y}_1,\dots,\vec{y}_d,R_1,\dots,R_d,\mat{S}$
%
\Statex Importance density which optimally is (see \citet[page 453]{fearnhead10}): 
\Statex \begin{equation}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} = 
%
	\propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}
\end{equation}
%
%
\Statex Let $\partic{\vec{\alpha}}{t}{i}$ denote particle $i$ at time $t$, $\partic{w}{t}{i}$ denote the weight of the particle and $\partic{\beta}{t}{i}$ denote the re-sampling weight.
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get a particle clouds % 
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,N}$ %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, d$. See algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,N}$  %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}$ for $t = d + 1, d, d-1, \dots, 1$. See algorithm~\ref{alg:backward}.
\EndProcedure
% 
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, d$}
\StateXX \emph{Re-sample:}
\State $i=1,2,\dots,N_s$ pairs of $\Lparen{j_i, k_i}$ where each component is independently sampled using re-sampling weights $\partic{\beta}{t}{j}$ and $\particB{\beta}{t}{k}$.
%
\StateXX \emph{Propagate:} 
\State Sample particles $\particS{\vec{\alpha}}{t}{i}$ from importance density %
	$\IDAproxC{\cdot}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k_i}}$%
.%
\StateXX \emph{Re-weight:}
\State Assign each particle weights:
\StateXX \begin{equation}\label{eqn:combineWeight}
 \particS{w}{t}{i} \propto \frac{
 	\propC{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j_i}}
 	\propC{\vec{y}_t}{\particS{\vec{\alpha}}{t}{i}}
 	\propC{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particS{\vec{\alpha}}{t}{i}}
 	\partic{w}{t - 1}{j_i}\particB{w}{t + 1}{k_i}
 	}{ % end of first argument of \frac
 	\IDAproxC{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k_i}}
 	\partic{\beta}{t}{j_i}\particB{\beta}{t}{k_i}\gamma_{t +1}\Lparen{\particB{\vec{\alpha}}{t+1}{k_i}}
 	} % end of frac
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Forward filter due to \cite{pitt99}. You can compare with \citet[page 20 and 25]{doucet09}. The version and notation below is from \citet[page 449]{fearnhead10}.}\label{alg:forward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex Importance density and specification of weights are optimally given by: 
\Statex \begin{equation}\begin{matrix}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = \propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \\
	\partic{\beta}{t}{j} \propto \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j}
\end{matrix}\end{equation}
%
\State Sample $\partic{\vec{\alpha}}{0}{1},\dots,\partic{\vec{\alpha}}{0}{N_f}$ particles from $\normalC{\cdot}{\vec{a}_0}{\mat{Q}_0}$ and set the weights $\partic{w}{0}{1},\dots,\partic{w}{0}{N_f}$ to $1 / N_f$.
%
\For{$t=1,\dots, d$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\partic{\beta}{t}{j}$ and re-sample according to $\partic{\beta}{t}{j}$ to get indices $j_1,\dots j_N$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\partic{\vec{\alpha}}{t}{i}$ using importance density $\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using:
\StateX \begin{equation}\label{eqn:forwardWeight}
	\partic{w}{t}{i} \propto \frac{
		\propC{\vec{y}_t}{\partic{\vec{\alpha}}{t}{i}}
		\propC{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}}
		\partic{w}{t-1}{j_i}
	}{ % \frag arg1 end
		\IDC{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}
		\partic{\beta}{t}{j_i}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Backwards filter. See \cite{briers10} and \cite{fearnhead10}.}\label{alg:backward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex A backwards filter distribution approximation:
\begin{equation}
	\propAproxC{\vec{\alpha}_t}{\vec{y}_{t:d}} \propto \gamma_t \Lparen{\vec{\alpha}_t}\propC{\vec{y}_{t:d}}{\vec{\alpha}_t}
\end{equation} 
\Statex with an  artificial prior distribution $\gamma_t \Lparen{\vec{\alpha}_t}$. This is introduced as $\propC{\vec{y}_{t:d}}{\vec{\alpha}_t}$ is not a density function in $\vec{\alpha}_t$.
\Statex Importance density and specification of weights {\footnotesize (\citet[page 451 -- look in the example in the appendix]{fearnhead10})}:
\Statex\begin{equation}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}}\particB{\beta}{t}{k} \approx %
		\gamma_t\Lparen{\vec{\alpha}_t}
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\particB{w}{t + 1}{k}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}}
\end{equation}
\Statex where we want {\footnotesize (see \citet[page 74]{briers10})}:
\Statex\begin{equation}\begin{matrix}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} \propto %
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\gamma_t\Lparen{\vec{\alpha}_t}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
	\particB{\beta}{t}{k} \propto %
		 \propAproxC{\vec{y}_t}{\particB{\vec{\alpha}}{t + 1}{k}}\particB{w}{t + 1}{k}
\end{matrix}\end{equation}
%
\State Sample $\particB{\vec{\alpha}}{d+1}{1},\dots,\particB{\vec{\alpha}}{d+1}{N_f}$ particles from $\gamma_{d+1}(\cdot)$ and set the weights $\particB{w}{d + 1}{1},\dots,\partic{w}{d+1}{N_f}$ to $1 / N_f$.
%
\For{$t=d,\dots, 1$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\particB{\beta}{t}{k}$ and re-sample according to $\particB{\beta}{t}{k}$ to get indices $k_1,\dots k_N$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\particB{\vec{\alpha}}{t}{i}$ using importance density $\IDAproxC{\vec{\alpha}_t}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using {\footnotesize (see \citet[page 72]{briers10} and add the ratio of prior probability and re-sampling weight)}:
\StateX \begin{equation}\label{eqn:backwardWeight}
	\particB{w}{t}{i} \propto \frac{
		\propC{\vec{y}_t}{\particB{\vec{\alpha}}{t}{i}}
		\propC{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particB{\vec{\alpha}}{t}{i}}
		\particB{w}{t + 1}{k_i}
		\gamma_t\Lparen{\particB{\vec{\alpha}}{t}{i}}
	}{ % \frag arg1 end
		\IDC{\particB{\vec{\alpha}}{t}{i}}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}
		\partic{\beta}{t}{k_i}
		\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k_i}}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}

\newpage

\section{Log likelihood evaluation}
We can evaluate the log likelihood for a particular value of $\vec{\theta} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec{a}_0}$ as described in \citet[page 5]{doucet09} and \citet[page 193]{malik11} using the forward particle filter shown in algorithm~\ref{alg:forward}.

\section{Parameter estimation}
We can use the EM-algorithm \citep{dempster77} to estimate $\mat{Q}$ and $\vec{a}_0$ elements of $\vec{\theta} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec{a}_0}$. We do this by running algorithm~\ref{alg:ONsmoother} for the current $\vec{\theta}$. Then we compute the so-called \emph{smoothed additive functional} or summary statistics:

\begin{equation}\begin{split}
\vec{t}_t^{(\vec{\theta})} &= \int_{\vec{\alpha}_t} \vec{\alpha}_t 
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_t}{\vec{y}_{1:d}} \partial \vec{\alpha}_t \\
%
& \approx \sum_{i = 1}^{N_s} \particS{\vec{\alpha}}{t}{i} \particS{w}{t}{i} 
\approx \sum_{i = 1}^{N_s} \partic{\vec{\alpha}}{t}{j_i} \particS{w}{t + 1}{i} 
\approx \sum_{i = 1}^{N_s} \particB{\vec{\alpha}}{t}{k_i} \particS{w}{t-1}{i} \\
%
\vec{T}_t^{(\vec{\theta})} &= \int_{\vec{\alpha}_{(t-1):t}} 
	\Lparen{\vec{\alpha}_t - \mat{F}\vec{\alpha}_{t-1}}
	\Lparen{\vec{\alpha}_t - \mat{F}\vec{\alpha}_{t-1}}^\top 
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):t}}{\vec{y}_{1:d}} 
	\partial \vec{\alpha}_{(t-1):t} \\
%
&\approx \sum_{i = 1}^{N_s}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_i}}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_i}}^\top
	\particS{w}{t}{i} \\
%
&\approx \sum_{i = 1}^{N_s}
	\Lparen{\particB{\vec{\alpha}}{t}{k_i} - \mat{F}\particS{\vec{\alpha}}{t-1}{i}}
	\Lparen{\particB{\vec{\alpha}}{t}{k_i} - \mat{F}\particS{\vec{\alpha}}{t-1}{i}}^\top
	\particS{w}{t-1}{i}
\end{split}\end{equation}%
%
% 
where $\vec{\alpha}_{s:t} = \Lbrace{\vec{\alpha}_s, \vec{\alpha}_{s +1}, \dots \vec{\alpha}_t}$ and the subscript in $\Prob$ denotes that it is the probability given the parameter $\vec{\theta}$. I use that the normalized weights $\particS{w}{t}{i}$ and the pairs $\Lbrace{\partic{\vec{\alpha}}{t-1}{j_i}, \particS{\vec{\alpha}}{t}{i}, \particB{\vec{\alpha}}{t + 1}{k_i}}$ form a discrete approximation of $\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):(t+1)}}{{\vec{y}_{1:d}}}$. That is, 

\begin{equation}\begin{split}
\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):{t+1}}}{\vec{y}_{1:d}} \hspace{-50pt} & \\
%
	& \approx \sum_{i=1}^{N_s}\particS{w}{t}{i} 
		\dirac{\vec{\alpha}_{t - 1} - \partic{\vec{\alpha}}{t-1}{j_i}}
		\dirac{\vec{\alpha}_{t} - \particS{\vec{\alpha}}{t}{i}}
		\dirac{\vec{\alpha}_{t + 1} - \particB{\vec{\alpha}}{t + 1}{k_i}}
\end{split}\end{equation} %
%
% 
where $\dirac{\cdot}$ is the Dirac delta function. The update of $\vec{a}_0$ and $\mat{Q}$ given the summary statistics is:

\begin{equation}
\vec{a}_0 = \vec{t}_0^{(\vec{\theta})} \qquad
%
\mat{Q} = \frac{1}{d}\sum_{t = 1}^d \mat{R}^\top\vec{T}_t^{(\vec{\theta})}\mat{R}
\end{equation}

We then repeat with the new $\vec{a}_0$ and $\mat{Q}$ for a given number of iterations or till a convergence criteria is satisfied.  See \cite{kantas15}, \cite{del10} and \cite{schon11} for further details on parameter estimation with particle filters.

We can do parts of the probability estimates exact at time $1$ by using:

\begin{equation}\begin{split}
\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{\alpha}_0}{\vec{y}_{1:d}} \hspace{-50pt} & \\
%
& = \optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}{\vec{\alpha}_1, \vec{y}_{1:d}}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& = \frac{
		\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{y}_{1:d}}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{y}_{1:d}}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& = \frac{
		\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:d}}{\vec{\alpha}_1, \vec{\alpha}_0}
		\optorC{f_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}
		\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:d}}{\vec{\alpha}_1}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& = \frac{
		\optorC{f_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& = \optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}{\vec{\alpha}_1}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& = \normalC{\vec{\alpha}_0}{
		\optor{\vec{m}_{\vec{\theta}}}{\vec{\alpha}_1}
	}{ % end of arg2 of normalC
		\mat{S}_{\vec{\theta}}
	}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:d}} \\
%
& \approx \sum_{i=1}^{N_s}
	\normalC{\vec{\alpha}_0}{
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
	}{ % end of arg2 of normalC
		\mat{S}_{\vec{\theta}}
	}
	\particS{w}{t}{i}\dirac{\vec{\alpha}_1 - \particS{\vec{\alpha}}{1}{i}}
\end{split}\end{equation} %
%
% 
where we use that %
$\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:d}}{\vec{\alpha}_1, \vec{\alpha}_0} = \optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:d}}{\vec{\alpha}_1}$%
~and have:

\begin{equation}\begin{split}
	\mat{S}_{\vec{\theta}}^{-1} &= 
		\mat{Q}_0^{-1} + \mat{F}^{-1}\mat{Q}^{-1}\Lparen{\mat{F}^{-1}}^\top \\ 
%
	\optor{\vec{m}_{\vec{\theta}}}{\vec{\alpha}} &= 
		\mat{S}_{\vec{\theta}}
		\Lparen{\mat{Q}_0^{-1}\vec{a}_0 + \mat{F}^{-1}\mat{Q}^{-1}\vec{a}}
\end{split}\end{equation}%
%
Thus, we end with:

\begin{equation}\begin{split}
\vec{T}_1^{(\vec{\theta})} \approx  
	\sum_{i = 1}^{N_s} \hspace{30pt} & \hspace{-30pt} \particS{w}{1}{i}\left(
		\particS{\vec{\alpha}}{1}{i}\Lparen{\particS{\vec{\alpha}}{1}{i}}^\top \right. \\
%
	&  -\mat{F}\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
		\Lparen{\particS{\vec{\alpha}}{1}{i}}^\top
	- \particS{\vec{\alpha}}{1}{i}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}^\top\mat{F}^\top \\
%
	& \left. + \mat{F}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}^\top
	\mat{F}^\top \right) + \mat{S}_{\vec{\theta}} 
\end{split}\end{equation}

\section{Other options}
The $\bigO{N^2}$ two-filter smoother in \cite{fearnhead10} is going to be computationally expensive as an approximation is going to be needed for equation (8) in the article. For instance, only the Taylor expansion approximation around a single point to approximate $g$ would be feasible. The non-auxiliary version in \citet{briers10} is more feasible as it only requires evaluation of $f$ in the smoothing part of two-filter smoother (see equation (46) in the paper). Similar conclusions applies to the forward smoother in \cite{del10} and the backward smoother as presented in \cite{kantas15}. Both have a $\bigO{N^2}$ computational cost.

Despite the $\bigO{N^2}$ cost of the method in \citet{briers10} and \cite{del10} they are still worthy candidates as the computational cost is independent of the number of observations, $n$.  Further, the computational cost can be reduced to $\bigO{N\log(N)}$ with the approximations in \cite{klaas06}.

The method in \citet[see particularly section 6.2 on page 203]{malik11} can be used to do continuous likelihood evaluation. I am not sure how well these method scale with higher state dimension, $p$.

\citet{kantas15} show empirically that it may be worth just using a forward filter. However, the example is with a univariate outcome ($n=1$ -- not to be confused with the number of periods $d$). The cost here of the forward filter is at least $\bigO{dNnp}$. Every new particle yields an $\bigO{dnp}$ cost which is expensive due to the large number of outcomes, $n$. Thus, the considerations are different and a $\bigO{dNnp + N^2}$ method will not make a big difference unless $N$ is large.

Another alternative is to add noise to $\vec{\theta}_{t}$ and use the methods in \cite{andrieu02}.

\section{\citet{briers10}}
The $\bigO{N^2}$ smother from \citet{briers10} is also implemented as it is feasible for a moderate number of particles (though, we can use the approximations in \cite{kantas15} to reduce the computational complexity). It is shown in algorithm \ref{alg:ON2smoother}. The weights in equation~\eqref{eqn:combineWeightO2} comes from the two-filter formula:

\begin{equation}\begin{split}
\propC{\vec{\alpha}_t}{\vec{y}_{1:d}} &= 
	\frac{
		\propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
		\propC{\vec{y}_{t:d}}{\vec{\alpha}_t}
	}{ \propC{\vec{y}_{t:d}}{\vec{y}_{1:{t-1}}}} \\
%
& \propto
	\propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}\propC{\vec{y}_{t:d}}{\vec{\alpha}_t} \\
%
& = \propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}\frac{
		\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}\prop{\vec{y}_{t:d}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \propto \propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
	\frac{\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& = 
	\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}
	\frac{
		\Lbrac{\int_{\vec{\alpha}_{t - 1}}
		\propC{\vec{\alpha}_{t-1}}{\vec{y}_{1:{t-1}}}
		\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
		\partial\vec{\alpha}_{t - 1}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \approx \sum_{i=1}^N
	\particB{w}{t}{i}
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\frac{
		\Lbrac{\sum_{j = 1}^N
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} }
\end{split}\end{equation}%
%
Similar arguments leads to:

\begin{equation}\begin{split}
\propC{\vec{\alpha}_t, \vec{\alpha}_{t-1}}{\vec{y}_{1:d}} \hspace{-50pt} & \hspace{50pt} \\
%
& \propto 
	\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}
	\frac{
		\propC{\vec{\alpha}_{t-1}}{\vec{y}_{1:{t-1}}}
		\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \approx \sum_{i=1}^N\sum_{j=1}^N
	\particB{w}{t}{i}
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\frac{
		\Lbrac{\sum_{j = 1}^N
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} }
	\frac{
		\partic{w}{t -1}{j}
		\dirac{\vec{\alpha}_{t -1} - \partic{\vec{\alpha}}{t - 1}{j}}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{j = 1}^N
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	} \\
%
& = \sum_{i=1}^N\sum_{j=1}^N
	\particS{w}{t}{i,j} 
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\dirac{\vec{\alpha}_{t -1} - \partic{\vec{\alpha}}{t - 1}{j}} \\
\end{split}\end{equation}
%
%
where 

\begin{equation}
\particS{w}{t}{i,j} = \particS{w}{t}{i} 
	\frac{
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{j = 1}^N
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}
\end{equation}

The above is what we need for the EM-algorithm.

\begin{algorithm}[H]
\caption{$\bigO{N^2}$ generalized two filter smoother using the method in \citet{briers10}.}\label{alg:ON2smoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $\mat{Q},\mat{Q}_0,\vec{a}_0,\mat{X}_1,\dots,\mat{X}_d,\vec{y}_1,\dots,\vec{y}_d,R_1,\dots,R_d,\mat{S}$
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get a particle clouds % 
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,N}$ %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, d$. See algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,N}$  %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{t:d}}$ for $t = d + 1, d, d-1, \dots, 1$. See algorithm~\ref{alg:backward}.
\EndProcedure
% 
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, d$}
\State Assign each backward filter particle a smoothing weight given by:
\StateXX \begin{equation}\label{eqn:combineWeightO2}
\particS{w}{t}{i} \propto
	\particB{w}{t}{i} \frac{\Lbrac{
		\sum_{j = 1}^N \partic{w}{t - 1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}}}
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}


\section{Implementation}
The \verb|PF_EM| method in the \verb|dynamichazard| package contains an implementation of the above described method. You specify the number of particles by the \verb|N_first|, \verb|N_fw_n_bw| and \verb|N_smooth| argument for respectively the $N_f$, $N$ and $N_s$ in the algorithm \ref{alg:ONsmoother}-\ref{alg:backward}. We may want more particle in the smoothing step, $N_s > N$, as pointed out in the discussion in \citet[page 460 and 461]{fearnhead10}. Further, selecting $N_f > N$ may be preferable to ensure coverage of the state space at time $0$ and $d + 1$.

The \verb|method| argument specify how the filters are set up. The argument can take the following values:

\begin{itemize}
	\item \verb|"bootstrap_filter"| for a bootstrap filter.
	\item \verb|"PF_normal_approx_w_cloud_mean"| and \verb|"AUX_normal_approx_w_cloud_mean"| for the Taylor expansion normal approximation of the conditional density of $\vec{y}_t$ made around the weighted mean of the previous cloud. The \verb|PF| and \verb|AUX| prefix specifies whether or not the auxiliary version should be used.
	\item \verb|"PF_normal_approx_w_particles"| and \verb|"AUX_normal_approx_w_particles"| for the Taylor expansion normal approximation of the conditional density of $\vec{y}_t$ made around the parent (or/and child) particle. The \verb|PF_| and \verb|AUX_| prefix specifies whether or not the auxiliary version should be used.
\end{itemize}

The smoother is selected with the \verb|smoother| argument. \verb|"Fearnhead_O_N"| gives the smoother in algorithm~\ref{alg:ONsmoother} and \verb|"Brier_O_N_square"| gives the smoother in algorithm~\ref{alg:ON2smoother}.

The \emph{Systematic Resampling} \citep{kitagawa96} is used in all re-sampling steps. See \cite{douc05} for a comparison of re-sampling methods. The rest of the arguments to \verb|PF_EM| are similar to those of the \verb|ddhazard| function.





\iffalse
\section{Literature review}
\subsubsection*{\cite{doucet09}}
\begin{itemize}
	\item Do re-sample and likely use \emph{Systematic Resampling} from \cite{kitagawa96}. If you use it, then read up on \cite{douc05}.
	\item Use threshold on \emph{effective sample size} to deside when to re-sample.
	\item Use \emph{Auxiliary Particle Filtering}. That is, use the information from the $t + 1$ outcome when re-computing the weights (\textit{sample before re-sampling}). See \cite{carpenter99}, \cite{pitt01} and \cite{pitt99}.
	\item Likely use MCMC Moves (re-sample moves) or block sampling limit degeneracy problem. See text for references.
	\item Rao-Blackwellised Particle Filtering: always exploit when you can have closed form solutions like when parts of the problem is (conditional) multivariate Gaussian. See the text and \cite{andrieu02} for examples. 
	\item Two filter smother is likely the way to go. It may be better `\textit{the support of the smoothed estimate differs substantially from that of the filtering estimate}`. The cost is $\bigO{N^2T}$ but can be reduced to $\bigO{NT}$ using the methods in \cite{fearnhead10} and \cite{briers05}.
\end{itemize}

\subsubsection*{\cite{andrieu02}}
Covers a Raoâ€“Blackwellized particle filtering where the state is linear and Gaussian and observations are (potentially) non-linear and non-Gaussian. 

\begin{itemize}
	\item The filter exploits closed form solutions from Gaussian part.
	\item It is not an auxiliary particle filter so w likely want to change this.
	\item Has a low memory requirement as we do not need to store a smooth covariance matrix for each particle.
	\item Mentions a MCMC move approach for sampling to deal with degeneracy. See \cite{de97}.
\end{itemize}

\subsubsection*{\cite{fearnhead10}}
Covers a two filter smoother:
\begin{itemize}
	\item Run an \emph{auxiliary particle filtering} forward and backward filter.
	\item The backwards filter uses samples from `\textit{marginal smoothing densities direct than re-weight those drawn from another distribution}`. This solves degeneracy problems  like those that occurs for a second order random walk. They use that the forward and backwards sets of particle clouds (or swarms) are independent. Then we sample in the combination step using particles from $t-1$ from the forward filter and particles from $t + 1$ from the backwards filter. The computational cost in $\bigO{N^2T}$.
	\item Get an $\bigO{NT}$ filter by sampling a forward particle and backward particle pair at each time $t$ while combining.
	\item Shows examples which are fully or partially linear Gaussian models. Derivations are in the appendix.
	\item Points out in the discussion that we likely want more particles in smoothing/combination step than in the forward and backwards filters.
\end{itemize}
\fi



\iffalse
Our model is:

\begin{equation}
\begin{array}{ll}
 	y_{it} \sim \propC{y_{it}}{\theta_{it}} & \\
%
 	\vec{\theta}_{t} = \mat{X}_t\vec{\alpha}_t + \vec{\epsilon}_t & 
  		\vec{\epsilon}_t \sim N\Lparen{\vec{0}, \mat{G}_t} \\
% 
 	\vec{\alpha}_t = \mat{F}\vec{\alpha}_{t - 1} + \mat{R}\vec{\eta}_t &
 		\vec{\eta}_t \sim N\Lparen{\vec{0}, \mat{Q}} \\
%
	&	\vec{\alpha}_0 \sim N\Lparen{\vec{a}_0, \mat{Q}_0}
 \end{array}
\end{equation}

where $y_{it}$ and $y_{jt}$ with $i\neq j$ are conditionally independent given $\theta_{it}$ and $\theta_{jt}$. This is the setup in \cite{andrieu02}. For each $t$ we have risk set given by $R_t \subseteq \Lbrace{1,2,\dots,n}$.

Next, we define:

\begin{equation}
\begin{matrix}
\KF{\vec{a}}{t}{s} = \expecC{\vec{\alpha}_t}{\vec{\theta}_{s}} \\
\KF{\mat{P}}{t}{s} = \varpC{\vec{\alpha}_t}{\vec{\theta}_{s}} \\
%
\KF{\vec{t}}{t}{s} = \expecC{\vec{\theta}_t}{\vec{\theta}_{s}} \\
\KF{\mat{S}}{t}{s} = \varpC{\vec{\alpha}_t}{\vec{\theta}_{s}}
\end{matrix}
\end{equation}

where it follows from Standard Kalman filtering that: 
\begin{equation}
\begin{matrix}
\KF{\vec{a}}{t}{1:(t - 1)} = \mat{F}\KF{\vec{a}}{t - 1}{1:(t - 1)} \\
\KF{\mat{P}}{t}{1:(t - 1)} = \mat{F}\KF{\mat{P}}{t - 1}{1:(t - 1)}\mat{F}^\top + \mat{Q} \\
\KF{\vec{\theta}}{t}{1:(t - 1)} = \mat{X}_t \KF{\vec{a}}{t}{1:(t - 1)} \\
\KF{\mat{S}}{t}{1:(t - 1)} = \mat{X}_t \KF{\mat{P}}{t}{1:(t - 1)} \mat{X}_t^\top + \mat{G}_t \\
%
\KF{\vec{a}}{t}{1:t} = \KF{\vec{a}}{t}{1:(t - 1)} + \KF{\mat{P}}{t}{1:(t - 1)} \mat{X}_t^\top %
	\KF{\mat{S}}{t}{1:(t - 1)}^{-1}\Lparen{ \vec{\theta}_t - \KF{\vec{\theta}}{t}{1:(t - 1)} } \\
\KF{\mat{P}}{t}{1:t} = \KF{\mat{P}}{t}{1:(t - 1)} - \KF{\mat{P}}{t}{1:(t - 1)} \mat{X}_t^\top \KF{\mat{S}}{t}{1:(t - 1)}^{-1} %
	\mat{X}_t\KF{\mat{P}}{t}{1:(t - 1)}
\end{matrix}
\end{equation}

We will use the forward filter in \cite{andrieu02} in we add superscripts fot he particle index and the above formulas become:
\fi

\newpage
\bibliographystyle{plainnat}
\bibliography{PF}

\end{document} 