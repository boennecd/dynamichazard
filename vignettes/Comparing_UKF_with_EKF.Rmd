---
title: "Comparing UKF with EKF"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

  ## Set the width of the R-terminal to # characters
  options(width = 80, warn = -1)

# Derfine function to make small margin in pictures
# you can use the bool flag to set what to excute before, after chunk 
# or always
# If you do not whant to excute the code than do e.g. small.mar = F
knitr::knit_hooks$set(small.mar = function(before, options, envir){
  if (before){ par(
    mar = c(5,5,0.5,0.5), 
    tcl = -0.3, 
    mgp = c(2.5,.5,0), 
    oma = c(0,0,0,0),
    pch=16,
    cex=.6,
    cex.axis = 1,
    cex.lab = .8/.6,
    lwd= 1
  )}},
  my.options=function(before, options, envir){
    if(before){
      options(digits = 3)
    }})

## opts_chunk$set() can change the default global options in a document (e.g. put this in a code chunk
knitr::opts_chunk$set(fig.path='figures/',
               fig.align='center',
               fig.width=6, fig.height=4,
               out.width="0.7\\textwidth",
               size='tiny',                ## See R highligt package for possible values (https://cran.r-project.org/web/packages/highlight/highlight.pdf)
               small.mar = TRUE,
               my.options = TRUE,
               comment = "##", 
               warnings = T,
               errors = T
)
```

## Introduction
This note will compare the dynamic discrete model fitted with the Extended Kalman (EKF) filter to with Unscented Kalman Filter (UKF) for the logistic model. We will use a simulated data set in order to compare the two 


TODO: Write about main findings

## Simulation
First, we will need to simulate the data. We first simulate $\vec{ \beta }_t = \vec{\beta}_{t-1} + \vec{\eta}_t$ where $\vec{\eta}_t \sim N(\vec{0}, I)$. We then model the death of invidual $i$ in period $t$ by $\pi_i = \exp (\vec{\beta}^T \vec{x}_it) / (1 + \exp (\vec{\beta}^T \vec{x}_it))$. We update the covariate vector for the $i$'th invidual with gabs of $1 + z$ where $z \sim \text{Pois} (1)$. We let $x_{itk} ~ \text{Unif}(a,b)$ for given values $a$ and $b$

There is a function to do in the `R` folder called `test_sim_func_logit`: 
```{r}
# We are currenlty in the vignettes folder
getwd()
source("../R./test_utils.R")
test_sim_func_logit
```

The `get_zyx_draw` functions are conveniente function that runs faster than the equivelent sampling function like `rnorm` when we simulate few outcomes:
```{r}
# We are currenlty in the vignettes folder
microbenchmark::microbenchmark(
  get_unif_draw(1),
  runif(1),
  times = 1e6
)

microbenchmark::microbenchmark(
  get_unif_draw(10),
  runif(10),
  times = 1e5
)
```

## Comparing with one sample
We simulate as follows:

```{r}
set.seed(20160904) # a good day
beta_start <- 1
sims_args <- list(n_series = (n_series <- 1e3), 
                            n_vars = (n_vars <- 3), 
                            t_0 = (t_0 <- 0), 
                            t_max = (t_max <- 5),
                            x_range = (x_range <- 1), 
                            x_mean = (x_mean <- .5), 
                            beta_start = beta_start,
                            intercept_start = (intercept_start <- 
                                                 - (.5 * 3 * beta_start + 1)),
                            re_draw = T)

sims <- do.call(test_sim_func_logit, sims_args)
sims$res <- as.data.frame(sims$res)
```

We have a total of `r n_series` series, with `r n_vars` parameters and a intercept. The simulated parameters are:
```{r}
sims$betas
matplot(sims$betas, type = "l")
```

Further we start at time `r t_0` and end at time `r t_max` giving us `r t_max - t_0` intervals. The $\vec{\beta}_0$ starts at (`r c(intercept_start, rep(beta_start, n_vars))`). Lastly, the co-variates are simulated to uniformly distributed within [`r x_mean + c(-1, 1) * x_range / 2`]. The first 10 rows of the final data frame are: 
```{r}
head(sims$res, 10)
```

Next, we get the design matrix and risk set object for `ddhazard_fit_cpp_prelim` by using the the following functions from `benssurvutils`:
```{r}
design_mat <- benssurvutils::get_design_matrix(
  survival::Surv(tstart, tstop, event) ~ x1 + x2 + x3, sims$res)
risk_obj <- benssurvutils::get_risk_sets(design_mat$Y, by = 1, 
                                         max_T = t_max, id = sims$res$id)

design_mat$Y[, 2] <- risk_obj$stop_new
design_mat$Y[, 3] <- risk_obj$new_events_flags
```

The last two lines update the failure flags and stop times. It is need for the logic in `ddhazard_fit_cpp_prelim` to check in which period a row counts as a death or as a control. E.g. say that we have row from time [3, 7.5] with a failure at the end. It is a control period [3, 4), [4, 5), [5, 6) and [6, 7) and a case in period [7, 8)

The final number of failures series that end with a death with `r t_max` are:
```{r}
sum(design_mat$Y[, 3] & design_mat$Y[, 2] <= t_max)
```

### Fitting EKF
We start by fitting the EKF. We do it with the following call:

```{r}
arg_list <- list(X = design_mat$X, tstart = design_mat$Y[, 1],  
                 tstop = design_mat$Y[, 2], events = design_mat$Y[, 3],
                 a_0 = (a_0 <- rep(0, ncol(design_mat$X))),
                 Q_0 = (Q_0 <- diag(1, ncol(design_mat$X))),
                 Q = (Q <- diag(1, ncol(design_mat$X))),
                 F_ = diag(1, ncol(design_mat$X)),
                 risk_obj = risk_obj,
                 eps = 10^-2, n_max = 10^4,
                 order_ = 1,
                 est_Q_0 = F,
                 verbose = T)

system.time(fit_EKF <- do.call(dynamichazard::ddhazard_fit_cpp_prelim, arg_list))
```

The `arg_list` is saved as we will ned it when we use the UKF. We start with $\vec{\beta}_0$ as [`r a_0`], the initial co-variance, $Q_0$, as a digonal matrix with elements [`r diag(Q_0)`] and the co-variance matrix in state space queation, $Q$, as a diagonal matrix with elements [`r diag(Q)`]. Further, we keep $Q_0$ fixed in each iteration by setting `est_Q_0 = F`. The convergence criteria is the relative norm of the change $\vert\vec{\beta}_0^{(k)} - \vec{\beta}_0^{(k - 1)}\vert/\vert\vec{\beta}_0^{(k - 1) \vert$. That is, the norm of the initial state space vector

### Fitting UKF
Next, we fit the same model with the UKF:
```{r}
arg_list$method = "UKF"

system.time(fit_UKF <- do.call(dynamichazard::ddhazard_fit_cpp_prelim, arg_list))
```

Note, the big difference in computation time. We will return to this in later. We can compare the two in terms of mean square error of the state space vectors:
```{r}
MSE_func <- function(b, betas = sims$betas) 
  mean((b - betas)^2) 

MSE_func(fit_EKF$a_t_d_s)
MSE_func(fit_UKF$a_t_d_s)
```

Further, we can compare plots:
```{r}
f_plot <- function(UKF, EKF, betas = sims$betas){
  par(mfcol = c(2, 2))
  for(i in 1:4){
    b <- sims$betas[, i]
    b_UKF <- UKF$a_t_d_s[, i]
    b_EKF <- EKF$a_t_d_s[, i]
    plot((seq_len(t_max - t_0 + 1) - 1) ,sims$betas[, i], 
         ylim = range(b, b_UKF, b_EKF), type = "l",
         xlab = "time (t)", ylab = paste("beta", i - 1))
    lines((seq_len(t_max - t_0 + 1) - 1), b_EKF, col = "blue")
    lines((seq_len(t_max - t_0 + 1) - 1), b_UKF, col = "red")
  }
}

f_plot(UKF = fit_UKF, EKF = fit_EKF)
```

The blue line is the EKF and rhe red line is the UKF. Lastly, we can compare in-sample estimates versus actual outcomes. We call `dynamichazard::ddhazard` in order to use the S3 generic `predict`. This method was not used before to illustarte the computation time (we avoid redundant computation that applies for both methods)
```{r}
arg_list <- list(
  formula = formula(survival::Surv(tstart, tstop, event) ~ x1 + x2 + x3),
  data = sims$res, by = 1, a_0 = a_0, Q_0 = Q_0, id = sims$res$id,
  Q = Q, n_max = 1e3, eps = 1e-2, max_T = t_max, est_Q_0 = F)

fit_EKF_new <- do.call(dynamichazard::ddhazard, arg_list)

testthat::test_that("Estimates are equal", {
  testthat::expect_equal(fit_EKF$a_t_d_s,  fit_EKF_new$a_t_d_s, check.attributes = F)
})

# New object has more information
str(fit_EKF_new)
str(fit_EKF)

# Compute predicted chance of death and then brier score
brier_func <- function(fit, pred_dat = sims$res){
  # We have to set some of the stop times to t_max when predicitng
  pred_dat$tstop = pmin(pred_dat$tstop, t_max)
  
  pred <- predict(fit, new_data = pred_dat, 
                  tstart = "tstart", tstop = "tstop")
  c("Brier score" = mean((pred_dat$event - pred$fits)^2))
}
brier_func(fit_EKF_new)

# Do the same for UKF
arg_list$method <- "UKF"
fit_UKF_new <- do.call(dynamichazard::ddhazard, arg_list)
brier_func(fit_UKF_new)
```

Lastly, we can compare the fits with a model where we do not take into account that parameters change

```{r}
static_glm <- 
  benssurvutils::static_glm(formula = arg_list$formula, data = arg_list$data, 
                            by = arg_list$by, use_risk_set_to_weight = T)
summary(static_glm)
```

We cannot use the fitted values directly as some of the observations appears in multiple bins which we have to account for

```{r}
n_bins_apperance <- rep(0, nrow(sims$res))
for(t in 1:t_max){
  is_in_bin <- sims$res$tstart <= t & t <= sims$res$tstop
  n_bins_apperance[is_in_bin] <- n_bins_apperance[is_in_bin] + 1
}

static_glm$pred <- 1 - (1- static_glm$fitted.values)^(n_bins_apperance)

mean((static_glm$pred - sims$res$event)^2) # compute brier score
```

## Comparing more than one simulation
We will simulate a number of times and compare the mean square predicting error and the brier score:

```{r}
n_sim <- 10
outcome <- matrix(NA_real_, nrow = n_sim, ncol = 4, 
                  dimnames = list(NULL, c("EKF MSE", "EKF Brier",
                                          "UKF MSE", "UKF Brier")))

for(i in seq_len(n_sim)){
  sims <- do.call(test_sim_func_logit, sims_args)
  arg_list$data <- data.frame(sims$res)
  arg_list$id <- arg_list$data$id
  
  cat("Iteration", i, "has", sum(arg_list$data$event & arg_list$data$tstop <= t_max),
      "deaths\n")
  
  for(method in c("EKF", "UKF"))
    tryCatch({
      arg_list$method <- method
      fit <- do.call(dynamichazard::ddhazard, arg_list)
      outcome[i, paste(method, c("MSE", "Brier"))] <- 
        c(MSE_func(fit$a_t_d_s, betas = sims$betas), 
          brier_func(fit,pred_dat = arg_list$data))
    }, error = function(e){
      cat("Failed with method ", method, ". Error was:\n")
      print(e)
    })
}
```

The code above simulate r n_sim outcomes and fit them using the EKF and UKF. 

```{r}
outcome
outcome[, c("EKF MSE")] - outcome[, c("UKF MSE")]
outcome[, c("EKF Brier")] - outcome[, c("UKF Brier")]
```

## Improving UKF computation time
TODO: Metion % parallel and  

## Issues with UKF

## Installation
TODO: write about install both packages
TODO: Write about openBlas
