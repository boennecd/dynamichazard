---
title: "Simulating cloglog"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

  ## Set the width of the R-terminal to # characters
  options(width = 80, warn = -1)

# Derfine function to make small margin in pictures
# you can use the bool flag to set what to excute before, after chunk 
# or always
# If you do not whant to excute the code than do e.g. small.mar = F
knitr::knit_hooks$set(small.mar = function(before, options, envir){
  if (before){ par(
    mar = c(5,5,0.5,0.5), 
    tcl = -0.3, 
    mgp = c(2.5,.5,0), 
    oma = c(0,0,0,0),
    pch=16,
    cex=.6,
    cex.axis = 1,
    cex.lab = .8/.6,
    lwd= 1
  )}},
  my.options=function(before, options, envir){
    if(before){
      options(digits = 3)
    }})

## opts_chunk$set() can change the default global options in a document (e.g. put this in a code chunk
knitr::opts_chunk$set(fig.path='figures/',
               fig.align='center',
               fig.width=6, fig.height=4,
               out.width="0.7\\textwidth",
               size='tiny',                ## See R highligt package for possible values (https://cran.r-project.org/web/packages/highlight/highlight.pdf)
               small.mar = TRUE,
               my.options = TRUE,
               comment = "##", 
               warnings = T,
               errors = T
)
```

## Intro 
This note will illustrate the implemented continuous time exponential model. The note shows:

1. How the model work on simulated data illustrated with plots
2. That the model decrease in mean square error in the state space variables estimates when the number of series increase
3. The model do have convergence issues in some cases 
4. The resulting fit differs if you fit the model twice

## Simulating

First, we need simulate our data sets. The parameters we will pass to `test_sim_func_exp` in the file `R/test_utils.R` are:

```{r}
n_plots <- 6
arg_list <- list(n_series = 1e4, 
                 n_vars = 5, 
                 x_range = 1, 
                 x_mean = 0, 
                 beta_start = 1,
                 intercept_start = -5, 
                 sds = c(.1, rep(1, 5)))
```

We end up simulating `r arg_list$n_series` individuals. Co-variates for individuals are changed with increments of a $s\sim \text{exp}(1)$ random variables. The co-variates are simulated drawn from a uniform distribution on [`r arg_list$x_mean + c(-.5, .5) * arg_list$x_range`]. The state space vector chance with increments of 1. We have `r arg_list$n_vars` parameters all starting at `r arg_list$beta_start`. Further, we have an intercept starting at `r arg_list$intercept_start`. The standard deviation of the intercept and parameters are respectively (`r arg_list$sds`). The function we use to simulate with is printed below (Skip it if you like):

```{r}
# We are currenlty in the vignettes folder
getwd()
source("../R/test_utils.R")
test_sim_func_exp
```

This version differs from the previous version named `..._poisson`. Before I interval censored every observation that had an outcome. To be concrete what is did before was:

1. We are given co-variate $\vec{x}_{ij}$ with start time $t^L$ and stop time $t^S$. Note that $t^L > \lceil t \rceil - 1$ and $t^S < \lceil t \rceil$ due to change of co-variates values or right censoring where $\lceil \cdot \rceil$ is the ceiling operator. I then computed the chance of dying by $p = 1 - \exp (- \exp(\vec{x}_{ij}\vec{\alpha}_{\lceil t \rceil})(\min\{\lceil t \rceil, t^S\} - \max\{\lceil t \rceil - 1, t^L\}))$
2. Draw a uniform variable $U$ on $[0, 1]$. If $p>U$ then set it as an event AND set the stop time to $\lceil t^S \rceil$

The latter is what I do not do in the new version. Here I replace 2. with: 

2. The same as before but in the case an event then I draw a the stop time uniformly from $[t^L, t^S]$


## Results
### Plot examples
We are now ready to simulate and make plots of the fitted parameters and actual parameters. This is done below `r n_plots` times. The dashed lines are estimates and the continuous lines are actual values of the parameters. The thick lines are the intercepts and the thin ones are the parameters for the co-variates



```{r}
set.seed(20160911)
for(i in seq_len(n_plots)){
  sims <- do.call(test_sim_func_exp, arg_list)
  
  # Try catch is used in case the estimation fails
  tryCatch({  
    
    fit_args <- list(
      survival::Surv(tstart, tstop, event) ~ . - tstart - tstop - event - id, 
      data = sims$res, 
      by = 1,
      id = sims$res$id,
      Q_0 = diag(10, arg_list$n_vars + 1),
      est_Q_0 = F, 
      eps = 1e-2,
      a_0 = c(-3, rep(0, arg_list$n_vars)),
      verbose = 5,
      model = "exponential"
    )
    
    fit <- do.call(dynamichazard::ddhazard, fit_args)
    
    matplot(fit$a_t_d_s, type = "l", ylim = range(fit$a_t_d_s, sims$betas), 
            lty = 2, lwd = c(2, rep(1, arg_list$n_vars)),
            xlab = "time", ylab = "parameter estimate")
    matplot(sims$betas, type = "l", lty = 1, add = T,
            lwd = c(2, rep(1, arg_list$n_vars)))
  }, error = function(e){
    cat("\n\n\n!!!!!!!!!!!!!!!!!!!\nFailed to fit\n!!!!!!!!!!!!!!!!!!!\n")
  })
}
```

The estimates seems close to the actual values. Notice that the model fails to fit the model once. What goes wrong is that one of the margins in the state variable $\vec{\beta}_t$ gets absolute large after which some of the score terms tend toward infinity or minus infinity. I figure this is due to divergence. This should not be uncommon with Extended Kalman filters from what I have read. What is your take?

### Mean Square error
Another question is whether the mean square error (or another metric?) between estimated state variables and actual values decrease as the number of observation increase. The simulation function starts by simulating the state variables $\vec{\beta}_0, \dots, \vec{\beta}_T$. Hence, we get the same variables if we use the same seed. This is done below where the number of series varies change with the same seed (and thus the same state space vectors):

```{r}
set.seed(20160928)
ns <- 2^(9:16) # number of series
seeds <- round(runif(5, max = 1e5)) # seeds we want to use

# Resulting MSE matrix and number of cases
n_cases <- MSEs <- 
  matrix(NA_real_, nrow = length(seeds), ncol = length(ns),
         dimnames = list(NULL, ns))

# Simulate and compute MSE
fit_args$verbose <- F
j <- 0
for(seed in seeds){
  i <- 0
  j <- j + 1
  for(n in ns){
    i <- i + 1
    set.seed(seed)
    arg_list$n_series <- n
    
    sims <- do.call(test_sim_func_exp, arg_list)
    n_cases[j, i] <- sum(sims$res$event)
    
    fit_args$data <- sims$res
    fit_args$id <- sims$res$id
    
    try({
      fit <- do.call(dynamichazard::ddhazard, fit_args)
      
      MSEs[j, i] <- mean((sims$betas[-1, ] - fit$a_t_d_s[-1, ])^2)
    })
  }
}

# Print the mean square errors (column name is number of series) 
print(MSEs, digits = 4)

# Print the number of cases
n_cases
```

### Issues with varying results
The last issue I will stress is that results differ if you fit the model twice. This is illustrated below:

```{r}
set.seed(1992)
arg_list$n_series <- 1e4
sims <- do.call(test_sim_func_exp, arg_list)

fit_args$data <- sims$res
fit_args$id <- sims$res$id
fit_1 <- do.call(dynamichazard::ddhazard, fit_args)

for(i in 1:10){
  cat("Fit number", i, "\n")
  fit_2 <- do.call(dynamichazard::ddhazard, fit_args)
  
  print(all.equal(fit_1$a_t_d_s, fit_2$a_t_d_s))
  print(all.equal(fit_1$V_t_d_s, fit_2$V_t_d_s))
  print(all.equal(fit_1$lag_one_cor, fit_2$lag_one_cor))
}
```

The relative difference is minor but present. I figure it might have to do with the order of summation when we compute the score vector $\vec{u}_t(\vec{\beta}_t)$ and information matrix $\mathbf{U}_t(\vec{\beta}_t)$. Some of the terms we add are small and they are computed in parallel so the order in which intermediates are added is non-deterministic. This could course varying results. What do you think?

## Running the code

You run the code yourself by installing this version of the package by calling:

```{r , eval=FALSE}
devtools::install_github(
  "boennecd/dynamichazard@4ef968eac5706df99fc31941747ccd3e1c10e1a8")
```
