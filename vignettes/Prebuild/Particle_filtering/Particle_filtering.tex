\RequirePackage{filecontents}

\documentclass[9pt, notitlepage]{article}

\usepackage[round]{natbib}
\usepackage{amsmath} \usepackage{bm} \usepackage{amsfonts}
\usepackage{algorithm} \usepackage{algpseudocode} \usepackage{hyperref}
\usepackage{float} \usepackage{array}

% algorithm and algpseudocode definitions
\newcommand\StateX{\Statex\hspace{\algorithmicindent}}
\newcommand\StateXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}}
\newcommand\StateXXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}}

\algnewcommand{\UntilElse}[2]{\Until{#1\ \algorithmicelse\ #2}}

\algtext*{EndFor} \algtext*{EndProcedure}

\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}

\newcommand{\citeAlgLine}[2]{line~\ref{#1} of algorithm~\ref{#2}}
\newcommand{\citeAlgLineTwo}[3]{line~\ref{#1} and~\ref{#2} of algorithm~\ref{#3}}
\newcommand{\citeAlgLineTo}[3]{lines~\ref{#1}-\ref{#2} of algorithm~\ref{#3}}

% Math commands
\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\vect}[1]{\widetilde{\vec{#1}}}
\newcommand{\vecb}[1]{\bar{\vec{#1}}}
\newcommand{\vecLarrow}[1]{\overleftarrow{\vec{#1}}}
\newcommand{\vecLRarrow}[1]{\overleftrightarrow{\vec{#1}}}


\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\matt}[1]{\widetilde{\mat{#1}}}
\newcommand{\matLarrow}[1]{\overleftarrow{\mat{#1}}}
\newcommand{\matLRarrow}[1]{\overleftrightarrow{\mat{#1}}}

\newcommand{\Lbrac}[1]{\left[ #1\right]}
\newcommand{\Lbrace}[1]{\left\{ #1\right\}}
\newcommand{\Lparen}[1]{\left( #1\right)}
\newcommand{\Cond}[2]{\left. #1 \vphantom{#2} \right\vert  #2}

% Operators
\newcommand{\Prob}{\text{P}}
\newcommand{\VAR}{\text{Var}}
\newcommand{\E}{\text{E}}
\newcommand{\COV}{\text{E}}

\newcommand{\optor}[2]{#1\Lparen{#2}}
\newcommand{\optorC}[3]{\optor{#1}{\Cond{#2}{#3}}}

\newcommand{\prop}[1]{\optor{\Prob}{#1}}
\newcommand{\propC}[2]{\optorC{\Prob}{#1}{#2}}

\newcommand{\expec}[1]{\optor{\E}{#1}}
\newcommand{\expecC}[2]{\optorC{\E}{#1}{#2}}

\newcommand{\varp}[1]{\optor{\VAR}{#1}}
\newcommand{\varpC}[2]{\optorC{\VAR}{#1}{#2}}

\newcommand{\covp}[1]{\optor{\COV}{#1}}
\newcommand{\covpC}[2]{\optorC{\COV}{#1}{#2}}

\newcommand{\propAproxC}[2]{\optorC{\widetilde{p}}{#1}{#2}}

\newcommand{\dirac}[1]{\optor{\delta}{#1}}

% Normal distribution
\newcommand{\normal}[2]{\optor{\mathcal{N}}{#1,#2}}
\newcommand{\normalC}[3]{\optorC{\mathcal{N}}{#1}{#2,#3}}

% ID: Importance density
\newcommand{\IDC}[2]{\optorC{q}{#1}{#2}}
\newcommand{\IDAproxC}[2]{\optorC{\widetilde{q}}{#1}{#2}}

% Diagonal operator
\newcommand{\diag}[1]{\optor{\text{diag}}{#1}}

% KF notation
\newcommand{\KF}[3]{#1_{\left. #2 \right\vert #3}}
\newcommand{\KFSup}[4]{#1_{\left. #2 \right\vert #3}^{(#4)}}

% PF notation
\newcommand{\partic}[3]{#1_{#2}^{\Lparen{#3}}}
% B for backwards
\newcommand{\particB}[3]{\widetilde{#1}_{#2}^{\Lparen{#3}}}
% S for smoothed
\newcommand{\particS}[3]{\widehat{#1}_{#2}^{\Lparen{#3}}}

\newcommand{\bigO}[1]{\mathcal{O}\Lparen{#1}}

% short hands
\newcommand{\dimState}{p}
\newcommand{\dimRng}{r}

\newcommand{\clo}{\mathcal{C}}
\newcommand{\nPart}{N}
\newcommand{\nPeriods}{d}
\newcommand{\nMax}{n_{\text{max}}}

% titlepage
\newcommand*{\myTitle}{\begingroup
\centering
{\LARGE Particle filters in the dynamichazard package} \\[\baselineskip]
\scshape

Benjamin Christoffersen \\[\baselineskip]
\today \\[\baselineskip]
\vspace*{3\baselineskip}
\endgroup}

\begin{document}
\myTitle
This is vignette covers the particle filter for the \verb|dynamichazard| package in \verb|R|. See \url{https://cran.r-project.org/web/packages/dynamichazard/vignettes/ddhazard.pdf} for more information on the package.

I assume that you are familiar with the setup in the \verb|dynamichazard| package and the other estimation methods in the package. Further, some prior knowledge of particle filters is required.  If you lag knowledge of particle filter then \cite{doucet09} provides a tutorial on particle filters and \cite{kantas15} covers parameter estimation with particle filters. This vignette relies heavily on \cite{fearnhead10}.

\section{Method}
\subsection*{Model}
The model is:

\begin{equation}
\begin{array}{ll}
 	y_{it} \sim \propC{y_{it}}{\eta_{it}} &  \\
%
 	\vec{\eta}_{t} = \mat{X}_t\mat{R}^{+}\vec{\alpha}_t + \vec{o}_t \\
%
 	\vec{\alpha}_t = \mat{F}\vec{\alpha}_{t - 1} + \mat{R}\vec{\epsilon}_t &
 		\vec{\epsilon}_t \sim N\Lparen{\vec{0}, \mat{Q}} \\
%
	&	\vec{\alpha}_0 \sim N\Lparen{\vec{a}_0, \mat{Q}_0}
\end{array}, \qquad
%
\begin{array}{l} i = 1, \dots, n_t \\ t = 1, \dots, d \end{array}
%
\end{equation}%
%
where I  denote the conditional densities as $\vec{y}_t \sim \optorC{g}{\cdot}{\mat{R}^{+}\vec{\alpha}_t}$ and $\vec{\alpha}_t \sim \optorC{f}{\cdot}{\vec{\alpha}_{t-1}}$. We are in a survival analysis setting where the simplest model has an indicator of death of individual $i$ in time $t$ such that $y_{it} \in \Lbrace{0, 1}$ where $\eta_{it}$ is the linear predictor where we use the logistic function as the link function. For each $t=1,\dots,\nPeriods$, we a have risk set given by $R_t \subseteq \Lbrace{1,2,\dots,n}$. Further, We let $n_t = \vert R_t \vert$ and $\nMax = \max_{t = 1,\dots \nPeriods} = n_t$. The observed outcomes are denoted by $\vec{y}_t = \Lbrace{y_{it}}_{i \in R_t}$. $\mat{X}_t$ is the design matrix of the covariates and $\vec{\alpha}_t$ is the vector of time-varying coefficients. The problems we are looking at have $\nMax \gg \dimState \geq \dimRng$ (e.g. $\nMax = 100000$ and $\dimRng = 20$).

Superscript $+$ denotes the Moore-Penrose inverse, %
the $i$'th row of $\mat{X}_t$ is $\vec{x}_{it}$, $\vec{x}_{it},\vec{\epsilon}_t\in\mathbb{R}^\dimRng$%
, $\vec{\alpha}_t\vec\in\mathbb{R}^\dimState$%
, $\mat{F} \in \mathbb{R}^{\dimState\times\dimState}$ and is invertible%
, $\mat{Q} \in \mathbb{R}^{\dimRng\times\dimRng}$ is a positive definite matrix%
, $\vec{o}_t$ are know offsets%
, and $\mat{R} \in \{0,1\}^{\dimState\times \dimRng}$%
~with $\dimState\geq\dimRng$ contains a subset of the columns of $\mat{I}_{\dimState}$ identity matrix with no duplicate columns in $\mat{R}$. The latter implies that $\mat{R}^+ = \mat{R}^\top$ and $\mat{R}$ is left inverse (i.e., $\mat{R}^\top\mat{R} = \mat{I}_\dimRng$). $\mat{R}\mat{R}^\top$ is a $\dimState\times\dimState$ diagonal matrix with $\dimRng$ diagonal entries with value 1 and $\dimState - \dimRng$ with value zero. We will let %
%
$$\vec{\xi}_{t} = \mat{R}^{+}\vec{\alpha}_t$$

I will use a particle filter and smoother to get smoothed estimates of $\vec{\alpha}_1, \dots, \vec{\alpha}_\nPeriods$ given the outcomes $\vec{y}_{1:\nPeriods} = \Lbrace{\vec{y}_1,\vec{y}_2,\dots, \vec{y}_\nPeriods}$ and use an EM-algorithm to estimate $\mat{Q}$ and $\vec{a}_0$. One choice of smoother is the generalized two-filter smoothing in \cite{fearnhead10} and \cite{briers10}. I have included the $\bigO{\nPart}$ smoother in \cite{fearnhead10} shown in algorithm~\ref{alg:ONsmoother}. The rest of vignette is structured as follows: first I cover the particle filter and smoother. Then I cover the EM-algorithm and other miscellaneous topics. I will end with what is implemented at this point.

\subsection*{Considerations}
Algorithm~\ref{alg:ONsmoother} shows one of the generalized two-filter smoother from \cite{fearnhead10}. It requires that we specify the following importance densities and re-sampling weights (optimal values are given as the right hand side):

\begin{equation}\begin{matrix}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = \propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \\
	\partic{\beta}{t}{j} \propto \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j} \\
%
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}}\particB{\beta}{t}{k} \approx %
		\gamma_t\Lparen{\vec{\alpha}_t}
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\particB{w}{t + 1}{k}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
%
	\IDAproxC{\particS{\alpha}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} =
		\propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}
\end{matrix}\end{equation}%
%
Further, we need to define a backwards filter distribution approximation%
%
\begin{equation}
	\propAproxC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}} \propto \gamma_t \Lparen{\vec{\alpha}_t}\propC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}
\end{equation}%
%
with an artificial prior distribution $\gamma_t \Lparen{\vec{\alpha}_t}$.

Given the models of interest we have that:

\begin{itemize}
	\item Evaluating $\propC{\vec{y}_t}{\vec{\alpha}_t}$ is an expensive operation as $\nMax \gg \dimRng$ and it has a $\bigO{\nMax\dimRng}$ computational cost. Any $\bigO{\nMax}$ operation is going to take considerable time.
	\item Evaluating $\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t -1}}$ and $\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t + 1}}$ is cheap and can be done in closed form and sampling from these distribution can be done in closed form.
	\item The second example in \cite{fearnhead10} is close to the model here though with $\nMax = 1$ and $\dimState = 2$.
\end{itemize}

The following sections will closely follow the example shown in \cite{fearnhead10} and the appendix of the paper.

\subsubsection*{Forward filter (algorithm~\ref{alg:forward})}
This section will cover some options for algorithm~\ref{alg:forward}. Let $\normalC{\cdot}{\cdot}{\cdot}$ denote a multivariate normal distribution. We can select the proposal density as%
%
\begin{equation}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = %
		\normalC{\vec{\xi}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
\end{equation}%
%
which we can sample from in $\bigO{\nPart \dimState^2}$ time if we have a pre-computed Cholesky decomposition of $\mat{Q}$. This is often called the \emph{bootstrap filter}. Another option is to use normal approximation of $\vec{y}_t$'s conditional density%
%
\begin{equation}\begin{array}{cl}
	\optorC{g}{\vec{y}_t}{\vec{\xi}_t} & \simeq  \optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\xi}_t} \\ &= %
		\normalC{
			\mat{X}_t\vec{\xi}_t
		}{ % end of arg1 \normalC
			\mat{X}_t\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1} -
			\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
			\vec{g}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}
		}{ % end of arg2 \normalC
			- \mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
		}
\end{array}\end{equation}
%
%
where:
\begin{equation}\begin{array}{c}
\mat{g}_t\Lparen{\vec{\xi}} =
		\Lbrace{\left.\frac{
		\partial \log \propC{y_{it}}{\eta_{it}}
	}{
		\partial\eta_{it}
	}\right|_{\eta_{it} = \vec{x}_{it}^\top\vec{\xi}} }_{i \in R_t} \\
%
	\mat{G}_t\Lparen{\vec{\xi}} =
		\diag{\Lbrace{\left.\frac{
		\partial^2 \log \propC{y_{it}}{\eta_{it}}
	}{
		\partial\eta_{it}^2
	}\right|_{\eta_{it} = \vec{x}_{it}^\top\vec{\xi}} }_{i \in R_t}}
\end{array}\end{equation}
%
%
to get%
%
\begin{equation}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \propto %
		\normalC{\vec{\xi}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}}{\vec{y}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}
\end{equation}
%
%
Thus, we need to sample from%
%
{\scriptsize %
\begin{equation}\label{eqn:TaylorProposalForward}\begin{split}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} &=  %
		\normalC{\vec{\xi}_t}{\vec{\mu}_t}{\mat{\Sigma}_t} \\
%
	\mat{\Sigma}_t^{-1} &= \mat{X}_t^\top
		\Lparen{-\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}}
		\mat{X}_t + \mat{Q}^{-1}  \\
%
	\vec{\mu}_t &= \mat{\Sigma}_t\Lparen{
		\mat{Q}^{-1}\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j} +
		\mat{X}_t^\top \Lparen{-\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}}
		\Lparen{
			\mat{X}_t\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1} -
			\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}^{-1}
			\vec{g}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}
		}
	} \\
%
	 &= \mat{\Sigma}_t\Lparen{
		\mat{Q}^{-1}\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j} +
		\mat{X}_t^\top
		\Lparen{
			-\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}
			\mat{X}_t\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1} +
			\vec{g}_t\Lparen{\mat{R}^{+}\mat{F}\vecb{\alpha}_{t - 1}}
		}
	}
\end{split}\end{equation}
}%
%
%
We can select  $\vecb{\alpha}_{t - 1}$ as the weighted mean given the particle cloud at time $t-1$ (that is, %
$\{\partic{\vec{\alpha}}{t-1}{1}, \partic{\vec{\alpha}}{t-1}{2}, \dots \partic{\vec{\alpha}}{t-1}{\nPart}\}$%
). This is similar to the second order random walk example in \cite{fearnhead10}. They use the mode which is feasible as the outcome only depends on one element of the state vector. The downside is an $\bigO{\nMax \dimState^2+\dimState^3}$ computational cost though independent of the number of particles. The total cost of sampling is $\bigO{\nMax\dimState^2+\dimState^3 + \nPart\dimState^2}$. Another option is to set $\vecb{\alpha}_{t - 1} = \partic{\vec{\alpha}}{t-1}{j}$ for each particle $j = 1, 2, \dots, \nPart$ in the particle cloud at time $t - 1$. This will improve the Taylor expansion but yields an $\bigO{\nPart\Lparen{\nMax\dimState^2+\dimState^3}}$ computational cost.

Next, we have the re-sampling weights. A simple solution is not to use an auxiliary particle filter as in the examples of \cite{fearnhead10} and set:

\begin{equation}
	\partic{\beta}{t}{j} \propto \partic{w}{t-1}{j}
\end{equation}
%
which has an $\bigO{\nPart}$ cost of sampling. Another options is to set%
%
\begin{equation}\label{eqn:FWWeights}
\begin{split}
	\partic{\beta}{t}{j} &\propto  \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j} \\
%
	& = \approx \partic{w}{t-1}{j} \int_{\mathbb{R}^\dimRng}
		\normalC{\vec{\xi}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{g}{\vec{y}_t}{\vec{\xi}_t}
		\partial \vec{\xi}_t \\
%
	& \approx \partic{w}{t-1}{j} \int_{\mathbb{R}^\dimRng}
		\normalC{\vec{\xi}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\xi}_t}
		\partial \vec{\xi}_t \\
%
	& \approx \frac{
		\partic{w}{t-1}{j}
		\normalC{\vec{\mu}_t}{\mat{R}^{+}\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
		\optorC{\widetilde{g}_t}{\vec{y}_t}{\vec{\mu}_t}
	}{ % end of frac arg1
		\IDC{\vec{\mu}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t}
	}
\end{split}
\end{equation}%
%
where $\IDC{\vec{\mu}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t}$ is meant as the right hand side of the first line in equation~\eqref{eqn:TaylorProposalForward} computed with $\vec{\mu}_t$ instead of $\vec{\xi}_t$. The come at an $\bigO{\nPart\dimState^2}$ computational cost assuming that we are using \eqref{eqn:TaylorProposalForward} already. Otherwise it has the same computational cost as mentioned when I covered the importance density since we have to make the Taylor expansion approximation.

\subsubsection*{Backward filter (algorithm~\ref{alg:backward})}
We need to specify the artificial prior $\gamma_t\Lparen{\vec{\alpha}_t}$. \citet[page 69 and 70]{briers10} provides recommendation on the selection. This leads to%
%
\begin{equation}\begin{split}
	\gamma_t\Lparen{\vec{\alpha}_t} &=
		\normalC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t} \\
%
	\vecLarrow{m}_t &= \mat{F}^t\vec{a}_0 \\
%
	\matLarrow{P}_t &= \left\{
		\begin{matrix} \mat{Q}_0 & t = 0 \\ \mat{F}\mat{P}_{t - 1}\mat{F}^\top + \mat{Q} & t > 0   \end{matrix} \right.
\end{split}\end{equation}
%
%
\cite{fearnhead10} writes that then we end with%
%
\begin{equation}\label{eqn:bwTransProp}\begin{split}
	\propC{\vec{\alpha}_t}{\vec{\alpha}_{t+1}} &=
	\normalC{\vec{\alpha}_t}{\vecLarrow{a}_t}{\matLarrow{S}_t} \\
%
	\matLarrow{S}_t &= \matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\mat{Q}\Lparen{\mat{F}^\top}^{-1} \\
%
	\vecLarrow{a}_t &=
		\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\vec{\alpha}_{t+1}
		+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t
\end{split}\end{equation}%
%
which simplifies for the first order random walk to%
%
\begin{equation}\begin{split}
	\vecLarrow{m}_t &= \vec{a}_0 \\
%
	\matLarrow{P}_t &= t\mat{Q} + \mat{Q}_0 \\
%
	\matLarrow{S}_t &=
		\Lparen{t\mat{Q} + \mat{Q}_0}
		\Lparen{(t+1)\mat{Q} + \mat{Q}_0}^{-1}\mat{Q} \\
%
	\vecLarrow{a}_t &=
		\Lparen{t\mat{Q} + \mat{Q}_0}
		\Lparen{(t+1)\mat{Q} + \mat{Q}_0}^{-1}\vec{\alpha}_{t+1}
		+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t
\end{split}\end{equation}%
%
Further, setting $\mat{Q}_0 = \mat{Q}$ (only in the artificial prior where we may alter $\gamma_0$ -- see \citet[page 70]{briers10}) gives us:
%
\begin{equation}\begin{split}\label{eqn:FirstOrderStrange}
	\matLarrow{S}_t &= \frac{t +1}{t + 2} \mat{Q} \\
%
	\vecLarrow{a}_t &= %
		\frac{t + 1}{t + 2}\vec{\alpha}_{t+1} +
		\frac{1}{ t+ 2} \vec{a}_0
\end{split}\end{equation}
%
%
We get the following backward version of equation~\eqref{eqn:TaylorProposalForward}%
%
{\scriptsize%
\begin{equation}\begin{split}\label{eqn:bw_approx}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} &=   %
		\normalC{\mat{R}^+\vec{\alpha}_t}{\vecLarrow{\mu}_t}{\matLarrow{\Sigma}_t} \\
%
	\matLarrow{\Sigma}_t^{-1} &=
		\mat{R}^{+}\matLarrow{P}_t^{-1}\mat{R}^{+\top} +
		\mat{X}_t^\top\Lparen{-\mat{G}_t\Lparen{
		    \mat{R}^{+}\mat{F}^{-1}\vecb{\alpha}_{t + 1}}}
		\mat{X}_t + 
		\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}\mat{Q}^{-1}
		\mat{R}^{+}\mat{F}^{-\top}\mat{R}^{+\top}  \\
%
	\vecLarrow{\mu}_t
	 &= \matLarrow{\Sigma}_t \Lparen{
		\mat{R}^{+}\matLarrow{P}_t^{-1}\vecLarrow{m}_t +
		\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}
		\mat{Q}^{-1}\mat{R}^{+}\particB{\vec{\alpha}}{t + 1}{k} +
		\mat{X}_t^\top
		\Lparen{
			-\mat{G}_t\Lparen{\mat{R}^{+}\mat{F}^{-1}\vecb{\alpha}_{t + 1}}
			\mat{X}_t\mat{R}^{+}\mat{F}^{-1}\vecb{\alpha}_{t + 1} +
			\vec{g}_t\Lparen{\mat{R}^{+}\mat{F}^{-1}\vecb{\alpha}_{t + 1}}
		}}
\end{split}\end{equation}
}%
%
which is an approximation of%
%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} & \propto
		\optorC{g}{\vec{y}_t}{\vec{\xi}_t}
		\optorC{f}{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\gamma_t\Lparen{\vec{\alpha}_t}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
%
	& \approx \optorC{\widetilde{g}}{\vec{y}_t}{\vec{\xi}_t}
		\normalC{\particB{\vec{\gamma}}{t + 1}{k}}{\mat{R}^+\mat{F}\vec{\alpha}_t}{\mat{Q}}
		\frac{
			\normalC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t}
		}{ % End of frac arg1
			\normalC{\particB{\vec{\alpha}}{t + 1}{k}}{\vecLarrow{m}_{t + 1}}{\matLarrow{P}_{t + 1}}
		}
\end{split}\end{equation}

The re-sampling weights can be computed similarly to the forward filter using the backward transition density in equation~\eqref{eqn:bwTransProp} in the numerator. We can also use a bootstrap like filter with the importance density by sampling from~\eqref{eqn:bwTransProp}.

\subsubsection*{Combining / smoothing (algorithm~\ref{alg:ONsmoother})}
We need to specify the importance density $\IDAproxC{\cdot}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}$ (see \citet[page 453] {fearnhead10}). Again, we can use a idea similar to those in the appendix of \cite{fearnhead10} and choose%
%
{\scriptsize%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}  &=   %
		\normalC{\vec{\xi}_t}{\vecLRarrow{\mu}_t}{\matLRarrow{\Sigma}_t} \\
%
	\matLRarrow{\Sigma}_t^{-1} &=
		\mat{Q}^{-1} +
		\mat{X}_t^\top\Lparen{-\mat{G}_t\Lparen{\vecb{\xi}_{t}}}
		\mat{X}_t + 
		\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}\mat{Q}^{-1}
		\mat{R}^{+}\mat{F}^{-\top}\mat{R}^{+\top}  \\
%
	\vecLRarrow{\mu}_t
	 &=  \matLRarrow{\Sigma}_t \Lparen{
		\mat{Q}^{-1}\mat{R}^+\mat{F}\partic{\vec{\alpha}}{t-1}{j} +
		\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}\mat{Q}^{-1}\mat{R}^+\particB{\vec{\alpha}}{t + 1}{k} +
		\mat{X}_t^\top
		\Lparen{
			-\mat{G}_t\Lparen{\vecb{\xi}_{t}}
			\mat{X}_t\vecb{\xi}_{t} +
			\vec{g}_t\Lparen{\vecb{\xi}_{t}}
		}}
\end{split}\end{equation}%
}%
%
where $\vecb{\xi}_t$ can be a combined mean given the cloud means at time $t - 1$ and $t + 1$ or a mean for each of the  two drawn particles in the $(j_i,k_i)$ pairs. This is to approximate%
%
%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} \propto %
%
	\optorC{\widetilde{g}}{\vec{y}_t}{\vec{\xi}_t}
		\optorC{f}{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}}
		\frac{
			\optorC{f}{\particB{\vec{\alpha}}{t+1}{k}}{\vec{\alpha}_t}
		}{
			\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t+1}{k}}
		}
\end{split}\end{equation}
%
We can also use a bootstrap like filter by sampling from%
%
\begin{equation}\begin{split}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} &=
		\normalC{\vec{\xi}_t}{\vect{m}}{\matt{S}} \\
%
	\matt{S} &= \Lparen{
	     \mat{Q}^{-1} + 
	     \mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}\mat{Q}^{-1}
	     \mat{R}^{+}\mat{F}^{-\top}\mat{R}^{+\top}}^{-1} \\
%
	\vect{m} &= \matt{S}\Lparen{
			 \mat{Q}^{-1}\mat{R}^+\mat{F}\partic{\vec{\alpha}}{t-1}{j} +
			 \mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}
			 \mat{Q}^{-1}\mat{R}^+\particB{\vec{\alpha}}{t + 1}{k}}
\end{split}\end{equation}

\newpage

\begin{algorithm}[H]
\caption{$\bigO{\nPart}$ generalized two filter smoother using the method in \cite{fearnhead10}.}\label{alg:ONsmoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $\mat{Q},\mat{Q}_0,\vec{a}_0,\mat{X}_1,\dots,\mat{X}_d,\vec{y}_1,\dots,\vec{y}_d,R_1,\dots,R_d,\mat{S}$
%
\Statex Importance density which optimally is (see \citet[page 453]{fearnhead10}):
\Statex \begin{equation}
	\IDAproxC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} =
%
	\propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}
\end{equation}
%
%
\Statex Let $\partic{\vec{\alpha}}{t}{i}$ denote particle $i$ at time $t$, $\partic{w}{t}{i}$ denote the weight of the particle and $\partic{\beta}{t}{i}$ denote the re-sampling weight.
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get a particle clouds %
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,\nPart}$ %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, \nPeriods$. See algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,\nPeriods}$  %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}$ for $t = \nPeriods + 1, \nPeriods, \nPeriods - 1, \dots, 1$. See algorithm~\ref{alg:backward}.
\EndProcedure
%
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, \nPart$}
\StateXX \emph{Re-sample:}
\State $i=1,2,\dots,\nPart_s$ pairs of $\Lparen{j_i, k_i}$ where each component is independently sampled using re-sampling weights $\partic{\beta}{t}{j}$ and $\particB{\beta}{t}{k}$.
%
\StateXX \emph{Propagate:}
\State Sample particles $\particS{\vec{\alpha}}{t}{i}$ from importance density %
	$\IDAproxC{\cdot}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k_i}}$%
.%
\StateXX \emph{Re-weight:}
\State Assign each particle weights:
\StateXX \begin{equation}\label{eqn:combineWeight}
 \particS{w}{t}{i} \propto \frac{
 	\propC{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j_i}}
 	\propC{\vec{y}_t}{\particS{\vec{\alpha}}{t}{i}}
 	\propC{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particS{\vec{\alpha}}{t}{i}}
 	\partic{w}{t - 1}{j_i}\particB{w}{t + 1}{k_i}
 	}{ % end of first argument of \frac
 	\IDAproxC{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k_i}}
 	\partic{\beta}{t}{j_i}\particB{\beta}{t}{k_i}\gamma_{t +1}\Lparen{\particB{\vec{\alpha}}{t+1}{k_i}}
 	} % end of frac
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Forward filter due to \cite{pitt99}. You can compare with \citet[page 20 and 25]{doucet09}. The version and notation below is from \citet[page 449]{fearnhead10}.}\label{alg:forward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex Importance density and specification of weights are optimally given by:
\Statex \begin{equation}\begin{matrix}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = \propC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} \\
	\partic{\beta}{t}{j} \propto \propC{\vec{y}_t}{\partic{\vec{\alpha}}{t-1}{j}}\partic{w}{t-1}{j}
\end{matrix}\end{equation}
%
\State Sample $\partic{\vec{\alpha}}{0}{1},\dots,\partic{\vec{\alpha}}{0}{\nPart_f}$ particles from $\normalC{\cdot}{\vec{a}_0}{\mat{Q}_0}$ and set the weights $\partic{w}{0}{1},\dots,\partic{w}{0}{\nPart_f}$ to $1 / \nPart_f$.
%
\For{$t=1,\dots, \nPeriods$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\partic{\beta}{t}{j}$ and re-sample according to $\partic{\beta}{t}{j}$ to get indices $j_1,\dots j_\nPart$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\partic{\vec{\alpha}}{t}{i}$ using importance density $\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using:
\StateX \begin{equation}\label{eqn:forwardWeight}
	\partic{w}{t}{i} \propto \frac{
		\propC{\vec{y}_t}{\partic{\vec{\alpha}}{t}{i}}
		\propC{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}}
		\partic{w}{t-1}{j_i}
	}{ % \frag arg1 end
		\IDC{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}
		\partic{\beta}{t}{j_i}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Backwards filter. See \cite{briers10} and \cite{fearnhead10}.}\label{alg:backward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex A backwards filter distribution approximation:
\begin{equation}
	\propAproxC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}} \propto \gamma_t \Lparen{\vec{\alpha}_t}\propC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}
\end{equation}
\Statex with an  artificial prior distribution $\gamma_t \Lparen{\vec{\alpha}_t}$. This is introduced as $\propC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}$ is not a density function in $\vec{\alpha}_t$.
\Statex Importance density and specification of weights {\footnotesize (\citet[page 451 -- look in the example in the appendix]{fearnhead10})}:
\Statex\begin{equation}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}}\particB{\beta}{t}{k} \approx %
		\gamma_t\Lparen{\vec{\alpha}_t}
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\particB{w}{t + 1}{k}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}}
\end{equation}
\Statex where we want {\footnotesize (see \citet[page 74]{briers10})}:
\Statex\begin{equation}\begin{matrix}
	\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}} \propto %
		\propC{\vec{y}_t}{\vec{\alpha}_t}
		\propC{\particB{\vec{\alpha}}{t + 1}{k}}{\vec{\alpha}_t}
		\frac{\gamma_t\Lparen{\vec{\alpha}_t}}{\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k}}} \\
	\particB{\beta}{t}{k} \propto %
		 \propAproxC{\vec{y}_t}{\particB{\vec{\alpha}}{t + 1}{k}}\particB{w}{t + 1}{k}
\end{matrix}\end{equation}
%
\State Sample $\particB{\vec{\alpha}}{\nPeriods+1}{1},\dots,\particB{\vec{\alpha}}{\nPeriods+1}{\nPart_f}$ particles from $\gamma_{\nPeriods+1}(\cdot)$ and set the weights $\particB{w}{\nPeriods + 1}{1},\dots,\partic{w}{\nPeriods+1}{\nPart_f}$ to $1 / \nPart_f$.
%
\For{$t=\nPeriods,\dots, 1$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\particB{\beta}{t}{k}$ and re-sample according to $\particB{\beta}{t}{k}$ to get indices $k_1,\dots k_\nPart$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\particB{\vec{\alpha}}{t}{i}$ using importance density $\IDAproxC{\vec{\alpha}_t}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using {\footnotesize (see \citet[page 72]{briers10} and add the ratio of prior probability and re-sampling weight)}:
\StateX \begin{equation}\label{eqn:backwardWeight}
	\particB{w}{t}{i} \propto \frac{
		\propC{\vec{y}_t}{\particB{\vec{\alpha}}{t}{i}}
		\propC{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particB{\vec{\alpha}}{t}{i}}
		\particB{w}{t + 1}{k_i}
		\gamma_t\Lparen{\particB{\vec{\alpha}}{t}{i}}
	}{ % \frag arg1 end
		\IDC{\particB{\vec{\alpha}}{t}{i}}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}
		\partic{\beta}{t}{k_i}
		\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k_i}}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}

\newpage

\section{Log likelihood evaluation}
We can evaluate the log likelihood for a particular value of $\vec{\theta} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec{a}_0, \mat{F}}$ as described in \citet[page 5]{doucet09} and \citet[page 193]{malik11} using the forward particle filter shown in algorithm~\ref{alg:forward}.

\section{Parameter estimation}
This section shows an example of parameter estimation in a random walk. The formulas for parameter estimation with a given order random with the EM-algorithm \citep{dempster77} are particularly simple. We need to estimate $\mat{Q}$ and $\vec{a}_0$ elements of $\vec{\theta} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec{a}_0, \mat{F}}$. We do this by running algorithm~\ref{alg:ONsmoother} for the current $\vec{\theta}$. Then we compute the so-called \emph{smoothed additive functional} or summary statistics%
%
\begin{equation}\begin{split}
\vec{t}_t^{(\vec{\theta})} &= \int_{\vec{\alpha}_t} \vec{\alpha}_t
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_t}{\vec{y}_{1:\nPeriods}} \partial \vec{\alpha}_t \\
%
& \approx \sum_{i = 1}^{\nPart_s} \particS{\vec{\alpha}}{t}{i} \particS{w}{t}{i}
\approx \sum_{i = 1}^{\nPart_s} \partic{\vec{\alpha}}{t}{j_i} \particS{w}{t + 1}{i}
\approx \sum_{i = 1}^{\nPart_s} \particB{\vec{\alpha}}{t}{k_i} \particS{w}{t-1}{i} \\
%
\vec{T}_t^{(\vec{\theta})} &= \int_{\mathbb{R}^{2\dimState}}
	\Lparen{\vec{\alpha}_t - \mat{F}\vec{\alpha}_{t-1}}
	\Lparen{\vec{\alpha}_t - \mat{F}\vec{\alpha}_{t-1}}^\top
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):t}}{\vec{y}_{1:\nPeriods}}
	\partial \vec{\alpha}_{(t-1):t} \\
%
&\approx \sum_{i = 1}^{\nPart_s}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_i}}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_i}}^\top
	\particS{w}{t}{i} \\
%
&\approx \sum_{i = 1}^{\nPart_s}
	\Lparen{\particB{\vec{\alpha}}{t}{k_i} - \mat{F}\particS{\vec{\alpha}}{t-1}{i}}
	\Lparen{\particB{\vec{\alpha}}{t}{k_i} - \mat{F}\particS{\vec{\alpha}}{t-1}{i}}^\top
	\particS{w}{t-1}{i}
\end{split}\end{equation}%
%
%
where $\vec{\alpha}_{s:t} = \Lbrace{\vec{\alpha}_s, \vec{\alpha}_{s +1}, \dots \vec{\alpha}_t}$ and the subscript in $\Prob$ denotes that it is the probability given the parameter $\vec{\theta}$. I use that the normalized weights $\particS{w}{t}{i}$ and the pairs $\Lbrace{\partic{\vec{\alpha}}{t-1}{j_i}, \particS{\vec{\alpha}}{t}{i}, \particB{\vec{\alpha}}{t + 1}{k_i}}$ form a discrete approximation of $\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):(t+1)}}{{\vec{y}_{1:\nPeriods}}}$. That is,%
%
\begin{equation}\begin{split}
\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_{(t-1):{t+1}}}{\vec{y}_{1:\nPeriods}} \hspace{-50pt} & \\
%
	& \approx \sum_{i=1}^{\nPart_s}\particS{w}{t}{i}
		\dirac{\vec{\alpha}_{t - 1} - \partic{\vec{\alpha}}{t-1}{j_i}}
		\dirac{\vec{\alpha}_{t} - \particS{\vec{\alpha}}{t}{i}}
		\dirac{\vec{\alpha}_{t + 1} - \particB{\vec{\alpha}}{t + 1}{k_i}}
\end{split}\end{equation} %
%
%
where $\dirac{\cdot}$ is the Dirac delta function. The update of $\vec{a}_0$ and $\mat{Q}$ given the summary statistics is%
%
\begin{equation}
\vec{a}_0 = \vec{t}_0^{(\vec{\theta})} \qquad
%
\mat{Q} = \frac{1}{\nPeriods}\sum_{t = 1}^\nPeriods \mat{R}^+\vec{T}_t^{(\vec{\theta})}\mat{R}^{+\top}
\end{equation}%

We then repeat with the new $\vec{a}_0$ and $\mat{Q}$ for a given number of iterations or till a convergence criteria is satisfied.  See \cite{kantas15}, \cite{del10} and \cite{schon11} for further details on parameter estimation with particle filters.

We can do parts of the probability estimates exact at time $1$ by using%
%
\begin{equation}\begin{split}
\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{\alpha}_0}{\vec{y}_{1:\nPeriods}} \hspace{-50pt} & \\
%
& = \optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}{\vec{\alpha}_1, \vec{y}_{1:\nPeriods}}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& = \frac{
		\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{y}_{1:\nPeriods}}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1, \vec{y}_{1:\nPeriods}}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& = \frac{
		\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:\nPeriods}}{\vec{\alpha}_1, \vec{\alpha}_0}
		\optorC{f_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}
		\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:\nPeriods}}{\vec{\alpha}_1}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& = \frac{
		\optorC{f_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{\alpha}_0}
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}
	}{ % end of frac arg1
		\optor{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}
	} % end of frac arg2
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& = \optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_0}{\vec{\alpha}_1}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& = \normalC{\vec{\alpha}_0}{
		\optor{\vec{m}_{\vec{\theta}}}{\vec{\alpha}_1}
	}{ % end of arg2 of normalC
		\mat{S}_{\vec{\theta}}
	}
	\optorC{\Prob_{\vec{\theta}}}{\vec{\alpha}_1}{\vec{y}_{1:\nPeriods}} \\
%
& \approx \sum_{i=1}^{\nPart_s}
	\normalC{\vec{\alpha}_0}{
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
	}{ % end of arg2 of normalC
		\mat{S}_{\vec{\theta}}
	}
	\particS{w}{t}{i}\dirac{\vec{\alpha}_1 - \particS{\vec{\alpha}}{1}{i}}
\end{split}\end{equation} %
%
%
where we use that %
$\optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:\nPeriods}}{\vec{\alpha}_1, \vec{\alpha}_0} = \optorC{\Prob_{\vec{\theta}}}{\vec{y}_{1:\nPeriods}}{\vec{\alpha}_1}$%
~and let %
%
\begin{equation}\begin{split}
	\mat{S}_{\vec{\theta}}^{-1} &=
		\mat{Q}_0^{-1} + \mat{F}^{-1}\mat{R}\mat{Q}^{-1}\mat{R}^\top\mat{F}^{-\top} \\
%
	\optor{\vec{m}_{\vec{\theta}}}{\vec{\alpha}} &=
		\mat{S}_{\vec{\theta}}
		\Lparen{\mat{Q}_0^{-1}\vec{a}_0 + \mat{F}^{-1}\mat{R}\mat{Q}^{-1}\mat{R}^+\vec{a}}
\end{split}\end{equation}%
%
Thus, we end with%
%
\begin{equation}\begin{split}
\vec{T}_1^{(\vec{\theta})} \approx
	\sum_{i = 1}^{\nPart_s} \hspace{30pt} & \hspace{-30pt} \particS{w}{1}{i}\left(
		\particS{\vec{\alpha}}{1}{i}\Lparen{\particS{\vec{\alpha}}{1}{i}}^\top \right. \\
%
	&  -\mat{F}\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
		\Lparen{\particS{\vec{\alpha}}{1}{i}}^\top
	- \particS{\vec{\alpha}}{1}{i}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}^\top\mat{F}^\top \\
%
	& \left. + \mat{F}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}
		\optor{\vec{m}_{\vec{\theta}}}{\particS{\vec{\alpha}}{1}{i}}^\top
	\mat{F}^\top \right) + \mat{S}_{\vec{\theta}}
\end{split}\end{equation}

\section{Other options}
The $\bigO{\nPart^2}$ two-filter smoother in \cite{fearnhead10} is going to be computationally expensive as an approximation is going to be needed for equation (8) in the article. For instance, only the Taylor expansion approximation around a single point to approximate $g$ would be feasible. The non-auxiliary version in \citet{briers10} is more feasible as it only requires evaluation of $f$ in the smoothing part of two-filter smoother (see equation (46) in the paper). Similar conclusions applies to the forward smoother in \cite{del10} and the backward smoother as presented in \cite{kantas15}. Both have a $\bigO{\nPart^2}$ computational cost.

Despite the $\bigO{\nPart^2}$ cost of the method in \citet{briers10} and \cite{del10} they are still worthy candidates as the computational cost is independent of the number of observations, $n$.  Further, the computational cost can be reduced to $\bigO{\nPart\log(\nPart)}$ with the approximations in \cite{klaas06}.

The method in \citet[see particularly section 6.2 on page 203]{malik11} can be used to do continuous likelihood evaluation. I am not sure how well these method scale with higher state dimension, $\dimState$.

\citet{kantas15} show empirically that it may be worth just using a forward filter. However, the example is with a univariate outcome ($n=1$ -- not to be confused with the number of periods $\nPeriods$). The cost here of the forward filter is at least $\bigO{\nPeriods\nPart\nMax\dimState}$. Every new particle yields an $\bigO{\nPeriods\nMax\dimState}$ cost which is expensive due to the large number of outcomes, $n$. Thus, the considerations are different and a $\bigO{\nPeriods\nPart\nMax\dimState + \nPart^2}$ method will not make a big difference unless $\nPart$ is large. Another alternative is to add noise to $\vec{\theta}_{t}$ and use the methods in \cite{andrieu02}.

\section{\citet{briers10}}
The $\bigO{\nPart^2}$ smother from \citet{briers10} is also implemented as it is feasible for a moderate number of particles (though, we can use the approximations in \cite{kantas15} to reduce the computational complexity). It is shown in algorithm \ref{alg:ON2smoother}. The weights in equation~\eqref{eqn:combineWeightO2} comes from the two-filter formula:

\begin{equation}\begin{split}
\propC{\vec{\alpha}_t}{\vec{y}_{1:\nPeriods}} &=
	\frac{
		\propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
		\propC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}
	}{ \propC{\vec{y}_{t:\nPeriods}}{\vec{y}_{1:{t-1}}}} \\
%
& \propto
	\propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}\propC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t} \\
%
& = \propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}\frac{
		\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}\prop{\vec{y}_{t:\nPeriods}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \propto \propC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
	\frac{\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& =
	\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}
	\frac{
		\Lbrac{\int_{\vec{\alpha}_{t - 1}}
		\propC{\vec{\alpha}_{t-1}}{\vec{y}_{1:{t-1}}}
		\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
		\partial\vec{\alpha}_{t - 1}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \approx \sum_{i=1}^\nPart
	\particB{w}{t}{i}
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\frac{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} }
\end{split}\end{equation}%
%
Similar arguments leads to:

\begin{equation}\begin{split}
\propC{\vec{\alpha}_t, \vec{\alpha}_{t-1}}{\vec{y}_{1:\nPeriods}} \hspace{-50pt} & \hspace{50pt} \\
%
& \propto
	\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}
	\frac{
		\propC{\vec{\alpha}_{t-1}}{\vec{y}_{1:{t-1}}}
		\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
	}{ \prop{\vec{\alpha}_t} } \\
%
& \approx \sum_{i=1}^\nPart\sum_{j=1}^\nPart
	\particB{w}{t}{i}
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\frac{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} }
	\frac{
		\partic{w}{t -1}{j}
		\dirac{\vec{\alpha}_{t -1} - \partic{\vec{\alpha}}{t - 1}{j}}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	} \\
%
& = \sum_{i=1}^\nPart\sum_{j=1}^\nPart
	\particS{w}{t}{i,j}
	\dirac{\vec{\alpha}_t - \particB{\vec{\alpha}}{t}{i}}
	\dirac{\vec{\alpha}_{t -1} - \partic{\vec{\alpha}}{t - 1}{j}} \\
\end{split}\end{equation}
%
%
where

\begin{equation}
\particS{w}{t}{i,j} = \particS{w}{t}{i}
	\frac{
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}
\end{equation}

The above is what we need for the EM-algorithm.

\begin{algorithm}[H]
\caption{$\bigO{\nPart^2}$ generalized two filter smoother using the method in \citet{briers10}.}\label{alg:ON2smoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $\mat{Q},\mat{Q}_0,\vec{a}_0,\mat{X}_1,\dots,\mat{X}_d,\vec{y}_1,\dots,\vec{y}_d,R_1,\dots,R_d,\mat{S}$
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get a particle clouds %
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,N}$ %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, \nPeriods$. See algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,N}$  %
	approximating $\propC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}$ for $t = \nPeriods + 1, \nPeriods, \nPeriods-1, \dots, 1$. See algorithm~\ref{alg:backward}.
\EndProcedure
%
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, \nPeriods$}
\State Assign each backward filter particle a smoothing weight given by:
\StateXX \begin{equation}\label{eqn:combineWeightO2}
\particS{w}{t}{i} \propto
	\particB{w}{t}{i} \frac{\Lbrac{
		\sum_{j = 1}^\nPart \partic{w}{t - 1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}}}
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}


\section{Implementation}
The \verb|PF_EM| method in the \verb|dynamichazard| package contains an implementation of the above described method. You specify the number of particles by the \verb|N_first|, \verb|N_fw_n_bw| and \verb|N_smooth| argument for respectively the $\nPart_f$, $\nPart$ and $\nPart_s$ in the algorithm \ref{alg:ONsmoother}-\ref{alg:backward}. We may want more particle in the smoothing step, $\nPart_s > \nPart$, as pointed out in the discussion in \citet[page 460 and 461]{fearnhead10}. Further, selecting $\nPart_f > \nPart$ may be preferable to ensure coverage of the state space at time $0$ and $\nPeriods + 1$.

The \verb|method| argument specify how the filters are set up. The argument can take the following values:

\begin{itemize}
	\item \verb|"bootstrap_filter"| for a bootstrap filter.
	\item \verb|"PF_normal_approx_w_cloud_mean"| and \verb|"AUX_normal_approx_w_cloud_mean"| for the Taylor expansion normal approximation of the conditional density of $\vec{y}_t$ made around the weighted mean of the previous cloud. The \verb|PF| and \verb|AUX| prefix specifies whether or not the auxiliary version should be used.
	\item \verb|"PF_normal_approx_w_particles"| and \verb|"AUX_normal_approx_w_particles"| for the Taylor expansion normal approximation of the conditional density of $\vec{y}_t$ made around the parent (or/and child) particle. The \verb|PF_| and \verb|AUX_| prefix specifies whether or not the auxiliary version should be used.
\end{itemize}

The smoother is selected with the \verb|smoother| argument. \verb|"Fearnhead_O_N"| gives the smoother in algorithm~\ref{alg:ONsmoother} and \verb|"Brier_O_N_square"| gives the smoother in algorithm~\ref{alg:ON2smoother}.

The \emph{Systematic Resampling} \citep{kitagawa96} is used in all re-sampling steps. See \cite{douc05} for a comparison of re-sampling methods. The rest of the arguments to \verb|PF_EM| are similar to those of the \verb|ddhazard| function.

\subsection{Linear maps}
The methods describe above involves many linear maps. These are implemented with \verb|C++| abstract class with specialized \verb|map| member functions for particular problem to decrease the computation. An alternative would have been to use a sparse matrix implementation. A.s. an example we have a mapping matrix $\mat{A}$ which \verb|C++| abstract member on the main data object used in the package called \verb|xyz|. E.g., this could $\mat{F}$ with name \verb|state_trans|. Then the following operations are implemented 

\begin{itemize}
\item \verb|map()|: Returns $\mat{A}$.
%
\item \verb|map(const arma::vec &x, bool tranpose)|: Returns $\mat{A}^\top\vec{x}$ if \verb|tranpose == true| and $\mat{A}\vec{x}$ otherwise.
%
\item \verb|map(const arma::mat &X, side s, bool tranpose)|: Let $\mat{B}=\mat{A}^\top$ if  \verb|tranpose == true| and otherwise $\mat{B}=\mat{A}$. Then the result is  $\mat{B}\mat{X}\mat{B}^\top$ if \verb|s == both|, $\mat{B}\mat{X}$ if \verb|s == right|, and $\mat{X}\mat{B}^\top$ if \verb|s == left|.
\end{itemize}

These are implemented for %
%
\begin{center}
\begin{tabular}{ l l } 
 \verb|C++| member name & Matrix $\mat{A}$ \\
 \hline
 \verb|err_state|           & $\mat{R}$ \\
 \verb|err_state_inv|       & $\mat{R}^{+} = \mat{R}^\top$ \\
 \verb|state_trans|         & $\mat{F}$ \\
 \verb|state_trans_err|     & $\mat{R}^{+}\mat{F} = \mat{R}^\top\mat{F}$ \\
 \verb|state_trans_inv|     & $\mat{F}^{-1}$ \\
 \verb|state_trans_inv_err| & $\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top} = 
  \mat{R}^\top\mat{F}^{-1}\mat{R}$
\end{tabular}
\end{center}

Further, we will need function to compute terms $\mat{R}^{+}\matLarrow{P}_t^{-1}\vecLarrow{m}_t$ and $\mat{R}^{+}\mat{P}_t^{-1}\mat{R}$ for equation~\eqref{eqn:bw_approx}. This is done with the virtual method \verb|uncond_mean| and \verb|uncond_covar|. These will computed once using equation~\eqref{eqn:bwTransProp}. 

The motivation for making functions for these is e.g., in the dense matrix case we reduce the computational cost of $\mat{R}^{+}\mat{F}\mat{R}^{+\top}\mat{Z}$ to $\bigO{\dimRng^3}$ from $\bigO{\dimState^3}$. Further, since the methods are virtual, then we can specialize for specific types of model. E.g., the first order random walk has%
%
\begin{center}
\begin{tabular}{ l l } 
 \verb|C++| member name & Matrix $\mat{A}$ \\
 \hline
 \verb|err_state|           & $\mat{R} = \mat{I}_\dimRng$ \\
 \verb|err_state_inv|       & $\mat{R}^{+} = \mat{I}_\dimRng$ \\
 \verb|state_trans|         & $\mat{F} = \mat{I}_\dimRng$ \\
 \verb|state_trans_err|     & $\mat{R}^{+}\mat{F} = \mat{I}_\dimRng$ \\
 \verb|state_trans_inv|     & $\mat{F}^{-1} = \mat{I}_\dimRng$ \\
 \verb|state_trans_inv_err| & $\mat{R}^{+}\mat{F}^{-1}\mat{R}^{+\top}  = \mat{I}_\dimRng$
\end{tabular}
\end{center}%
% 
where $\mat{I}_\dimRng$ is an $r$ dimensional identity matrix. Thus, there is a $\bigO{1}$ cost of all the above operations. 





\newpage
\bibliographystyle{plainnat}
\bibliography{PF}

\end{document}
