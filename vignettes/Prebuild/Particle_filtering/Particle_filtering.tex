\documentclass[notitlepage]{article}

\usepackage[round]{natbib}
\usepackage{amsmath} 
\usepackage{bm} 
\usepackage{amsfonts}
\usepackage{algorithm} 
\usepackage{algpseudocode} 
\usepackage{hyperref}
\usepackage{float} 
\usepackage{array} 
\usepackage{todonotes}
\usepackage[htt]{hyphenat}
\usepackage[margin=1.5in]{geometry}

% todonotes
\newcommand\todoin[2][]{\todo[inline, caption={2do}, size=\scriptsize,#1]{
\begin{minipage}{\textwidth-4pt}#2\end{minipage}}}

% algorithm and algpseudocode definitions
\newcommand\StateX{\Statex\hspace{\algorithmicindent}}
\newcommand\StateXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}}
\newcommand\StateXXX{\Statex\hspace{\algorithmicindent}\hspace{\algorithmicindent}\hspace{\algorithmicindent}}

\algnewcommand{\UntilElse}[2]{\Until{#1\ \algorithmicelse\ #2}}

\algtext*{EndFor} \algtext*{EndProcedure}

\algnewcommand\algorithmicinput{\textbf{Input:}}
\algnewcommand\INPUT{\item[\algorithmicinput]}

\newcommand{\citeAlgLine}[2]{line~\ref{#1} of Algorithm~\ref{#2}}
\newcommand{\citeAlgLineTwo}[3]{line~\ref{#1} and~\ref{#2} of Algorithm~\ref{#3}}
\newcommand{\citeAlgLineTo}[3]{lines~\ref{#1}-\ref{#2} of Algorithm~\ref{#3}}

% Math commands
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\renewcommand{\vec}[1]{\bm{#1}}
\newcommand{\vect}[1]{\widetilde{\vec{#1}}}
\newcommand{\vecb}[1]{\bar{\vec{#1}}}
\newcommand{\vecLarrow}[1]{\overleftarrow{\vec{#1}}}
\newcommand{\vecLRarrow}[1]{\overleftrightarrow{\vec{#1}}}


\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\matt}[1]{\widetilde{\mat{#1}}}
\newcommand{\matLarrow}[1]{\overleftarrow{\mat{#1}}}
\newcommand{\matLRarrow}[1]{\overleftrightarrow{\mat{#1}}}

\newcommand{\Lbrac}[1]{\left[ #1\right]}
\newcommand{\Lbrace}[1]{\left\{ #1\right\}}
\newcommand{\Lparen}[1]{\left( #1\right)}
\newcommand{\Lvert}[1]{\left\vert #1\right\vert}
\newcommand{\Cond}[2]{ #1 \middle\vert  #2}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\newcommand{\approptoinn}[2]{\mathrel{\vcenter{
  \offinterlineskip\halign{\hfil$##$\cr
    #1\propto\cr\noalign{\kern2pt}#1\sim\cr\noalign{\kern-2pt}}}}}

\newcommand{\appropto}{\mathpalette\approptoinn\relax}

% Operators
\newcommand{\Prob}{\text{P}}
\newcommand{\VAR}{\text{Var}}
\newcommand{\E}{\text{E}}
\newcommand{\COV}{\text{Cov}}

\newcommand{\optor}[2]{#1\Lparen{#2}}
\newcommand{\optorC}[3]{\optor{#1}{\Cond{#2}{#3}}}

\newcommand{\prop}[1]{\optor{\Prob}{#1}}
\newcommand{\propC}[2]{\optorC{\Prob}{#1}{#2}}
\newcommand{\propt}[1]{\optor{\widetilde{\Prob}}{#1}}
\newcommand{\proptC}[2]{\optorC{\widetilde{\Prob}}{#1}{#2}}

\newcommand{\pdens}[1]{\optor{p}{#1}}
\newcommand{\pdensC}[2]{\optorC{p}{#1}{#2}}
\newcommand{\pdenst}[1]{\optor{\widetilde p}{#1}}
\newcommand{\pdenstC}[2]{\optorC{\widetilde p}{#1}{#2}}

\newcommand{\gFunc}[3]{\optorC{g_{#3}}{#1}{#2}}
\newcommand{\fFunc}[2]{\optorC{f}{#1}{#2}}

\newcommand{\expec}[1]{\optor{\E}{#1}}
\newcommand{\expecC}[2]{\optorC{\E}{#1}{#2}}

\newcommand{\varp}[1]{\optor{\VAR}{#1}}
\newcommand{\varpC}[2]{\optorC{\VAR}{#1}{#2}}

\newcommand{\covp}[1]{\optor{\COV}{#1}}
\newcommand{\covpC}[2]{\optorC{\COV}{#1}{#2}}

\newcommand{\vecOP}[1]{\optor{\text{vec}}{#1}}

\newcommand\subCond[3]{#1_{\left. #2 \middle\vert #3\right.}}

% Normal distribution
\newcommand{\normal}[2]{\optor{\mathcal{N}}{#1,#2}}
\newcommand{\normalC}[3]{\optorC{\mathcal{N}}{#1}{#2,#3}}
\newcommand{\normald}[2]{\optor{\phi}{#1,#2}}
\newcommand{\normaldC}[3]{\optorC{\phi}{#1}{#2,#3}}

% ID: Proposal distributions
\newcommand{\IDC}[2]{\optorC{q}{#1}{#2}}
\newcommand{\IDAproxC}[2]{\optorC{\widetilde{q}}{#1}{#2}}

% Diagonal operator
\newcommand{\diag}[1]{\optor{\text{diag}}{#1}}

% Dirac delta function
\newcommand\dirac[2]{\optor{\delta_{#1}}{#2}}

% KF notation
\newcommand{\KF}[3]{#1_{\left. #2 \right\vert #3}}
\newcommand{\KFSup}[4]{#1_{\left. #2 \right\vert #3}^{(#4)}}

% PF notation
\newcommand{\partic}[3]{#1_{#2}^{\Lparen{#3}}}
% B for backwards
\newcommand{\particB}[3]{\widetilde{#1}_{#2}^{\Lparen{#3}}}
% S for smoothed
\newcommand{\particS}[3]{\widehat{#1}_{#2}^{\Lparen{#3}}}

\newcommand{\bigO}[1]{\mathcal{O}\Lparen{#1}}

% short hands
\newcommand{\dimState}{p}
\newcommand{\dimRng}{r}

\newcommand{\clo}{\mathcal{C}}
\newcommand{\nPart}{N}
\newcommand{\nPeriods}{d}
\newcommand{\nMax}{n_{\text{max}}}

\newcommand\Jaco{\mathrm D}
\newcommand\Hess{\mathrm H}

\newcommand\MVAR[1]{\optor{\text{VAR}}{#1}}

% titlepage
\newcommand*{\myTitle}{\begingroup
\centering
{\LARGE Particle filters and smoothers in the dynamichazard package} \\[\baselineskip]
\scshape

Benjamin Christoffersen \\[\baselineskip]
\today \\[\baselineskip]
\vspace*{3\baselineskip}
\endgroup}

\begin{document}
\myTitle
This vignette covers the particle filters and smoothers implemented in the \texttt{dynamichazard} package in \texttt{R}. Some prior knowledge of particle filters is assumed.  \cite{doucet09} provide a tutorial 
on particle filters and \cite{kantas15} cover parameter estimation with particle filters. 
See also \cite{cappe05} for a general introduction to Hidden Markov models. 
This vignette relies heavily on \cite{fearnhead10} and there is a big overlap between what
is presented here and the paper. 

\section{Method}
The models implemented in the package is survival analysis models for terminal
events. These can be in discrete times where we have binary indicators
$Y_{ik} = 1_{\{T_i \in (t_{k-1}, t_k]\}}$ which is one if the random event time
of individual $i$ denoted by 
$T_i\in (0,\infty)$ is in the interval $(t_{k-1}, t_k]$ and zero otherwise.
It can also be in continuous time where we model the distribution of the event 
time of individual $i$, $T_i$, with a
piecewise exponential distribution conditional on observable covariates 
and the path of a discrete latent variable. To be more concrete, the model is

\begin{equation}\label{eqn:model}
\begin{aligned}
 	y_{it} &\sim \optorC{g}{y_{it}}{\eta_{it}} &  \\
%
 	\vec{\eta}_{t} &= \mat{X}_t\mat R^+\vec{\alpha}_t + \vec{o}_t +  
 	\mat{Z}_t\vec{\omega} & \\
%
 	\vec{\alpha}_t &= \mat{F}\vec{\alpha}_{t - 1} + \mat{R}\vec{\epsilon}_t&
 		\vec{\epsilon}_t \sim \normal{\vec 0}{\mat Q} \\
%
	& \vphantom{a} &	\vec{\alpha}_0 \sim \normal{\vec\mu_0}{\mat{Q}_0}
\end{aligned}, \qquad
%
\begin{array}{l} i = 1, \dots, n_t \\ t = 1, \dots, d \end{array}
\end{equation}%
%
where I  denote the conditional densities as %
$\optorC{g_t}{\vec{y}_t}{\vec{\alpha}_t} = %
	\optorC{g}{\vec{y}_t}{\mat{X}_t\mat R^+\vec{\alpha}_t + \vec{o}_t +  \mat{Z}_t\vec{\omega}}$ and $\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t-1}}$. 
For each $t=1,\dots,\nPeriods$, we a have risk set given by $R_t \subseteq \Lbrace{1,2,\dots,n}$. 
Further, we let $n_t = \vert R_t \vert$ denote the number of observation 
at risk at time $t$ 
and $\nMax = \max_{t \in\{1,\dots \nPeriods\}} = n_t$. The observed outcomes 
are denoted by $\vec{y}_t = \Lbrace{y_{it}}_{i \in R_t}$. $\mat{X}_t$ is the 
design matrix of the covariates and $\vec{\alpha}_t$ is the state vector 
containing the time-varying coefficients. 
The $\mat{Z}_t$ is the design matrix for the covariates with time-invariant
coefficients and $\vec{\omega}$ are the corresponding coefficients.

The $i$'th row of $\mat{X}_t$ is $\vec{x}_{it}$, $\vec{x}_{it},\vec{\epsilon}_t\in\mathbb{R}^\dimRng$%
, $\vec\mu_0,\vec{\alpha}_t\vec\in\mathbb{R}^\dimState$%
, $\mat{F} \in \mathbb{R}^{\dimState\times\dimState}$%
, $\mat{Q} \in \mathbb{R}^{\dimRng\times\dimRng}$ is a positive definite matrix%
, $\mat{Q}_0 \in \mathbb{R}^{\dimState\times\dimState}$ is a positive definite matrix%
, $\vec{o}_t$s are known offsets%
, and $\mat{R}$ is a $\dimState\times\dimRng$ matrix%
~with $\dimState\geq\dimRng$ which contains a subset of $r$ columns of $\mat{I}_{\dimState}$. We will order the entires of $\mat R$ such that the first $\dimRng$ columns are the 
first $\dimRng$ columns of $\mat{I}_{\dimState}$. I.e.,%
%
$$\mat{R} = \begin{pmatrix}
	\mat I_\dimRng  \\
	\mat 0 
\end{pmatrix}$$%
%
Superscript $+$ denotes the Moore-Penrose inverse, $\mat{R}^+ = \mat{R}^\top$ and $\mat{R}$ is left inverse (i.e., $\mat{R}^\top\mat{R} = \mat{I}_\dimRng$). $\mat{R}\mat{R}^\top$ is a $\dimState\times\dimState$ diagonal matrix where the $\dimRng$ 
first diagonal entries has value 1 and the rest of the diagonal entries are zero. 
The data sets we are working with have 
$\nMax \gg \dimState \geq \dimRng$ (e.g. $\nMax = 10000$ and $\dimRng = 5$). We let %
%
$$\vec{\xi}_{t} = \mat{R}^{+}\vec{\alpha}_t$$

The above allows us to have an $o$th order vector autoregressions, $\MVAR{o}$, by settings%
%
\begin{align*}
\vec\alpha_t &= (\vec\xi_t,\vec\xi_{t-1},\dots, \vec\xi_{t - o + 1}) \\
\mat F &= \begin{pmatrix}
 \mat F_1    & \cdots & \cdots & \mat F_{o-1} & \mat F_o \\
 \mat I_\dimRng    & \mat 0      & \cdots & \mat 0 & \mat 0 \\
 \mat 0      &  \mat I_\dimRng    & \ddots & \vdots & \vdots \\
 \vdots & \ddots & \ddots & \mat 0 & \mat 0 \\
 \mat 0      & \cdots & \mat 0 & \mat I_\dimRng & \mat 0 
\end{pmatrix}, & \mat F_i &\in \mathbb{R}^{\dimRng\times\dimRng}
\end{align*}

I will use a particle filter to get a discrete approximation of
the conditional distribution of 
$\vec{\alpha}_1, \dots, \vec{\alpha}_\nPeriods$ given the outcomes 
$\vec{y}_{1:\nPeriods} = \Lbrace{\vec{y}_1,\vec{y}_2,\dots, \vec{y}_\nPeriods}$ and use 
an EM-algorithm to estimate $\mat{Q}$, $\vec\omega$, and $\vec\mu_0$. One choice of smoother is 
shown in \cite{fearnhead10} and another is the generalized two-filter smoother shown by \cite{briers09}. 
The rest of
vignette is structured as follows: first I give a brief introduction to the implemented particle
filters and smoothers. Then I cover what the effect is of some the arguments to 
particle functions in \texttt{R} in the packages. 
The implemented particle filter and smoother from \cite{fearnhead10} is presented next, followed by 
the used EM-algorithm and the smoother suggested by \cite{briers09}.
The last section covers the implemented approximations of the gradient and
observed information matrix. 
  
\subsection{Overview}
As a quick recap which will ease reading the next sections, we will start by 
recalling an application of importance sampling, use this to motivate particle filtering, 
and give a brief idea of the implemented particle smoothers. 
Suppose we want to approximate a
density $c(x) = \zeta\tilde c(x)$ where we only know $\tilde c(x)$ and not 
the normalization constant $\zeta$. One way to approximate this density is 
to %
%
\begin{itemize}
  \item sample $x_1,x_2,\dots,x_\nPart$ from a distribution with density $b(x)$.
  \item Compute the unnormalized weights $\bar w_i = \tilde c(x_i) / b(x_i)$.
  \item Normalize the weights $w_i = \bar w_i / \sum_{i = 1}^\nPart\bar w_i$. 
\end{itemize}%
%
This gives us the following discrete approximation of the density %
%
$$c(x) \approx \sum_{i = 1}^\nPart w_i\dirac{x_i}{x}$$%
% 
where $\delta_{x}$ is the Dirac delta function which has unit point mass
at $x$. This is directly applicable to the model
in Equation~\eqref{eqn:model} as at time 1 we want to approximate %
%
$$
\pdensC{\vec\alpha_1}{\vec y_1} = \frac{
	\optorC{g_1}{\vec y_1}{\vec\alpha_1} 
	\int\optorC{f}{\vec\alpha_1}{\vec a_0}
	\normaldC{\vec a_0}{\vec\mu_0}{\mat Q_0}\diff\vec a_0
	}{\pdens{\vec y_1}}
$$%
%
where $\normaldC{\cdot}{\vec m}{\mat M}$ is the density function of a multivariate normal 
distribution with mean $\vec m$ and covariance matrix $\mat M$. We can easily evaluate the 
numerator for each $\vec\alpha_1$ but not the normalization constant, $\pdens{\vec y_1}$. 

The extension to a particle filter (which I will call a forward particle filter) is that at 
time 2 we want to approximate %
%
$$
\pdensC{\vec\alpha_{1:2}}{\vec y_{1:2}} = 
	\pdensC{\vec\alpha_1}{\vec y_1}\frac{
		\optorC{g_2}{\vec y_2}{\vec\alpha_2}\optorC{f}{\vec\alpha_2}{\vec\alpha_1}
	}{
		\pdensC{\vec y_2}{\vec y_1}
	}
$$%
% 
Now, we can use the discrete approximation at time 1 of $\pdensC{\vec\alpha_1}{\vec y_1}$, 
sample $\vec \alpha_2$ given each sampled $\vec\alpha_1$, and apply importance sampling 
again. We can repeat this with similar arguments at time $3,4,\dots,\nPeriods$ giving us an approximation 
of $\pdensC{\vec\alpha_{1:\nPeriods}}{\vec y_{1:\nPeriods}}$. We will call the last element of 
a sampled path at time $t$ a particle. Further, we will denote the $j$th particle at time $t$ 
and its associated weight by $\partic{\vec\alpha}tj$ and $\partic wtj$ respectively.  

One issue that may arise is that 
our samples (particles) may degenerate so essentially only one sampled path of $\vec\alpha_{1:\nPeriods}$ 
has any weight in the end. 
To avoid this, we may introduce a re-sampling step. One way to re-sample is using the weights 
and letting the re-sampling weights be $\partic\beta{t+1}j = \partic wtj$ where $\partic\beta{t+1}j$ is 
the re-sampling weight of particle $j$ at time $t$. We then sample with replacement using 
$\partic\beta{t+1}j$. Another option when we re-sample the particles from time 
$t$ is to use the information of the outcomes at time $t+1$, $\vec y_{t+1}$. This is called 
an auxiliary particle filter and is introduced by \cite{pitt99}.

However, we may end up with few or only one unique value at the early time 
points (say $\vec\alpha_1$) when we re-sample. Thus, it will be useful to use a smoother to get 
a better approximation of the marginal density $\pdensC{\vec\alpha_t}{\vec y_{1:\nPeriods}}$. To do so, 
one idea is to use the two-filter formula from \cite{kitagawa94}. Though, this requires that
we can evaluate $\pdensC{\vec{y}_{t:d}}{\vec{\alpha}_t}$. It turns out that we can approximate 
this up to a constant which is just what need. This is covered in further details in Section~\ref{sec:Brier}. 

The approximation uses a particle filter
which is run backwards in time and which approximates an artificial distribution. The arguments 
for the backward particle filter is very similar to the forward particle filter presented above. 
The $k$th particle in the backward particle filter at 
time $t$, its re-sampling weight, and the associated weight will be denoted by 
respectively $\particB{\vec{\alpha}}{t}{k}$, $\particB\beta{t-1}k$ 
and $\particB{w}{t}{k}$. The final $i$th smoothed particle and weight at time $t$ will be denoted by 
 $\particS{\vec{\alpha}}{t}{i}$ and $\particS{w}{t}{i}$. The latter gives us the following approximation 
of the marginal density of $\vec\alpha_t \mid \vec y_{1:\nPeriods}$%
%
$$
\pdensC{\vec\alpha_t}{\vec y_{1:\nPeriods}} \approx
	\sum_{i = 1}^{\nPart_S} 
	\particS{w}{t}{i}\dirac{\particS{\vec{\alpha}}{t}{i}}{\vec\alpha_t}
$$%
%
if we sampled $\nPart_S$ smoothed particles at time $t$. 
The smoothing algorithm from \cite{fearnhead10} is shown in Algorithm~\ref{alg:ONsmoother}, 
the forward particle filter is shown Algorithm~\ref{alg:forward}, and the backward particle filter 
is shown in Algorithm~\ref{alg:backward}.



\subsection{Methods in the package}
The \texttt{PF\_EM} method in the \texttt{dynamichazard} package contains an implementation of the described methods. You specify the number of particles by the \texttt{N\_first}, \texttt{N\_fw\_n\_bw} and \texttt{N\_smooth} argument for respectively the $\nPart_f$, $\nPart$ and $\nPart_s$ in the Algorithm \ref{alg:ONsmoother}-\ref{alg:backward}. We may want more particles in the smoothing step, $\nPart_s > \nPart$, as pointed out in the discussion in \citet[p. 460-461]{fearnhead10}. Further, selecting $\nPart_f > \nPart$ may be preferable to ensure coverage of the state space at time $0$ and $\nPeriods + 1$.

\todoin{We do not need to sample the time $0$ and $\nPeriods + 1$ particles. Instead we can make a special proposal distribution for time $1$ and time $d$. This is not implemented though...}

The \texttt{method} argument specify how the filters are set up. The argument can take the following values

\begin{itemize}
	\item \texttt{"bootstrap\_filter"} for a bootstrap filter. This is where we sample using 
	Equation \eqref{eq:bootFW}, \eqref{eq:bootBW} and \eqref{eq:bootSM}. This is fast but the proposal 
	distribution may be a poor approximation of the distribution we want to target.
	\item \texttt{"PF\_normal\_approx\_w\_cloud\_mean"} and \texttt{"AUX\_normal\_approx\_w\_cloud\_mean"} for 
	the Taylor approximation of the conditional density of $\vec{y}_t$ made using the mean of the parent 
	particles and/or mean of the child particles. See Section \ref{sec:NonLinObs}. 
	The \texttt{PF} and \texttt{AUX} prefix specifies whether or not the auxiliary version 
	should be used.
	\item \texttt{"PF\_normal\_approx\_w\_particles"} and 
	 \texttt{"AUX\_normal\_approx\_w\_particles"} for the Taylor approximation of the conditional density 
	 of $\vec{y}_t$ made using the parent and/or child particle. 
	  See Section \ref{sec:NonLinObs}.
	  The \texttt{PF} and \texttt{AUX} prefix specifies whether or not the auxiliary version should be used.
\end{itemize}

The smoother is selected with the \texttt{smoother} argument. \texttt{"Fearnhead\_O\_N"} gives the smoother in Algorithm~\ref{alg:ONsmoother} and \texttt{"Brier\_O\_N\_square"} gives the smoother in Algorithm~\ref{alg:ON2smoother}. 
The \emph{Systematic Re-sampling} \citep{kitagawa96} is used in all re-sampling steps. See \cite{douc05} for a 
comparison of re-sampling methods. The rest of the arguments to \texttt{PF\_EM} are similar to those of the 
\texttt{ddhazard} function.

It is not clear what will give the best performance for a given data set
at a fixed computation cost. An advice is to use the \texttt{trace}
argument and check the effective sample at each point in time during the estimation. \texttt{"bootstrap\_filter"}
may not be that much cheaper in terms of computation time as we still have to evaluate $g_t$ in Equation
\eqref{eqn:combineWeight}, \eqref{eqn:forwardWeight}, and \eqref{eqn:backwardWeight} which is 
$\bigO{\nMax\nPart\dimRng}$ or $\bigO{\nMax\nPart_S\dimRng}$ 
which is typically computationally expensive as $\nMax$ is large. 
On the other hand, the \texttt{"...\_w\_particles"}
methods are $\bigO{\nMax\nPart\dimRng^2}$ or $\bigO{\nMax\nPart_S\dimRng^2}$ run times
with a potentially much larger constant. 
Thus, the \texttt{"...\_w\_cloud\_mean"} may be preferred.

The rest of the vignette covers the implemented methods. It is mainly included to show exactly what is 
computed and why. Further, I cover some currently not implemented extensions that may be implemented in the 
future. 


\subsection{Proposal distributions and re-sampling weights}
Algorithm~\ref{alg:ONsmoother} shows one of the particle smoothers shown by
\cite{fearnhead10} in the first order state space model. In this situation $\mat R = \mat I_\dimRng$,
$\dimRng = \dimState$ and $\vec\alpha_t = \vec\xi_t$. We need to specify a series of proposal distributions and 
re-sampling weights. To show what is implemented and why, we first 
consider the model where %
%
$$\vec y_t \mid \vec\alpha_t \sim \normal{%
	\mat{X}_t\vec{\alpha}_t + \vec{o}_t +  \mat{Z}_t\vec{\omega}}{\mat H_t}$$%
%
for some known positive definite matrix $\mat H_t$. This is not implemented 
in this package but deriving 
optimal re-sampling weights and proposal distributions is possible in this case. 
In fact, it makes little sense to use a particle filter and particle smoother in this case
since the Kalman filter and an exact smoother can be applied. However, the results here
will turn out to be useful to motivate the approximations we use
later. The state space model is%
%
$$\begin{aligned}
 	\vec y_t & \sim \normal{\vec\eta_t}{\mat H_t} &  \\
%
 	\vec{\eta}_{t} &= \mat{X}_t\vec{\alpha}_t + \vec{o}_t +   
 	\mat{Z}_t\vec\omega & \\
%
 	\vec{\alpha}_t &= \mat{F}\vec{\alpha}_{t - 1} + \mat{R}\vec{\epsilon}_t&
 		\vec{\epsilon}_t \sim \normal{\vec{0}}{\mat{Q}} \\
%
	& \vphantom{a} &	\vec{\alpha}_0 \sim \normal{\vec\mu_0}{\mat{Q}_0}
\end{aligned}, \qquad
%
\begin{array}{l} i = 1, \dots, n_t \\ t = 1, \dots, d \end{array}$$%
%
We let $\vec h_t = \vec{o}_t + \mat{Z}_t\vec\omega$ such that 
$\vec \eta_t = \mat X_t\vec \alpha_t + \vec h_t$ to ease the notation.  
We first turn to the forward particle filter in Algorithm \ref{alg:forward}. Ideally, we 
want the re-sampling weights to be 
%
\begin{align}\label{eq:fwReWeight}
\partic\beta tj &\propto \pdensC{\vec y_t}{\partic{\vec\alpha}{t-1}j}\partic w{t-1}j \\
	&=\int \optorC{g_t}{\vec y_t}{\vec\alpha_t}
		\optorC{f}{\vec a_t}{\partic{\vec\alpha}{t-1}j}\diff\vec a_t \partic w{t-1}j \nonumber\\
	&= \normaldC{\vec y_t }{\mat X_t\mat F\partic{\vec\alpha}{t-1}j + \vec h_t}{%
	\mat X_t \mat Q \mat X_t^\top + \mat H_t}
	\partic w{t-1}j\nonumber
\end{align}%
%  
We can notice that setting $\partic\beta tj = \partic w{t-1}j$ yields the 
so-called sequential importance 
re-sampling algorithm. For the proposal distribution, the optimal proposal density is%
%
$$
\IDC{\vec\alpha_t}{\partic{\vec\alpha}{t-1}j, \vec y_t} 
	= \pdensC{\vec\alpha_t}{\partic{\vec\alpha}{t-1}j, \vec y_t}
$$%
% 
where we find that %
%
\begin{align}
\log \pdensC{\vec\alpha_t}{\partic{\vec\alpha}{t-1}j, \vec y_t} 
	&=\log \pdensC{\vec\alpha_t, \vec y_t}{\partic{\vec\alpha}{t-1}j} + \dots 
	\nonumber\\
	&=\log \optorC{g_t}{\vec y_t}{\vec{\alpha}_t} + 
		\log\optorC{f}{\vec\alpha_t}{\partic{\vec\alpha}{t-1}j} + \dots 
		\nonumber\\
	&= -\frac 12\Lparen{\vec y_t - \mat X_t\vec \alpha_t - \vec h_t}^\top 
		\mat H^{-1}_t\Lparen{\vec y_t - \mat X_t\vec\alpha_t - \vec h_t} 
		\nonumber\\
		&\hspace{20pt}-\frac 12\Lparen{\vec\alpha_t - \mat F\partic{\vec\alpha}{t-1}j}^\top\mat Q^{-1}
		\Lparen{\vec\alpha_t - \mat F\partic{\vec\alpha}{t-1}j} + \dots 
		\nonumber\\
	&= - \frac 12\vec\alpha_t^\top\mat\Sigma^{-1}_t\vec\alpha_t
		+\vec\alpha_t^\top\mat \Sigma^{-1}_t\vec\mu\Lparen{\partic{\vec\alpha}{t-1}j} + \dots \nonumber\\
\mat\Sigma_t &= \Lparen{\mat Q^{-1} + \mat X_t^\top\mat H_t^{-1}\mat X_t}^{-1} 
	\label{eq:fwNormProCovar}\\
\vec\mu(\vec x) &= \mat\Sigma_t\Lparen{
	\mat Q^{-1}\mat F\vec x + \mat X^\top_t\mat H_t^{-1} (\vec y_t - \vec h_t)}
	\label{eq:fwNormProMean}
\end{align}%
% 
The $\dots$ are terms of the normalization constant. We recognize the multivariate normal distribution density and thus the optimal proposal density is %
%
$$\IDC{\vec\alpha_t}{\partic{\vec\alpha}{t-1}j, \vec y_t}  
	= \normaldC{\vec\alpha_t}{\vec\mu(\partic{\vec\alpha}{t-1}j)}{\mat\Sigma_t}
$$%
%
Alternatively, we can use the so-called bootstrap filter and let%
%
\begin{equation}\label{eq:bootFW}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t} = %
		\normaldC{\vec\alpha_t}{\mat{F}\partic{\vec{\alpha}}{t-1}{j}}{\mat{Q}}
\end{equation}%
%
which we can sample from in $\bigO{\nPart \dimState^2}$ time if we have a pre-computed Cholesky 
decomposition of $\mat{Q}$. This is computationally cheap 
compared to optimal solution which is $\bigO{\nPart \dimState^2  + \dimState^3 + \nMax \dimState^2}$ but it is not optimal.



\subsubsection*{Backward filter (Algorithm~\ref{alg:backward})}
We need to specify the artificial prior $\gamma_t\Lparen{\vec{\alpha}_t}$ for our artificial backward distribution. 
\citet[p. 69-70]{briers09} provides recommendation on the selection. One suggestion is the artificial density function %
%
\begin{equation}\begin{split}\label{eq:artfiPrior}
	\gamma_t\Lparen{\vec{\alpha}_t} &=
		\normaldC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t} \\
%
	\vecLarrow{m}_t &= \mat{F}^t\vec\mu_0 \\
%
	\matLarrow{P}_t &= \left\{
		\begin{matrix} \mat{Q}_0 & t = 0 \\ \mat{F}\matLarrow{P}_{t - 1}\mat{F}^\top + 
		\mat{Q} & t > 0   \end{matrix} \right.
\end{split}\end{equation}%
%
The backward arrows are added to stress that these are means and covariance matrices which we use in 
the artificial distribution we target in the backward particle filter. 
The artificial distribution we target in backward particle filters has
the following conditional density functions%
%
\begin{align}
\pdenstC{\vec{\alpha}_{t:d}}{\vec{y}_{t:\nPeriods}} &\propto 
	\gamma_t \Lparen{\vec{\alpha}_t}
	\prod_{i=t}^d \optorC{g_i}{\vec y_i}{\vec\alpha_i}
	\prod_{i=t}^{d-1} \optorC{f}{\vec\alpha_{i + 1}}{\vec\alpha_i} \nonumber\\
\pdenstC{\vec{\alpha}_t}{\vec{y}_{(t + 1):\nPeriods}} & \propto
	\gamma_t(\vec\alpha_t)
	\int \pdenstC{\vec a_{t+1}}{\vec{y}_{(t+1):\nPeriods}}
	\frac{
		\optorC{f}{\vec a_{t + 1}}{\vec\alpha_t}%
	}{
		\gamma_{t+1}(\vec a_{t+1})	
	}\diff\vec a_{t+1} \nonumber\\
\pdenstC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}} &\propto 
	\optorC{g_t}{\vec y_t}{\vec\alpha_t}
	\pdenstC{\vec{\alpha}_t}{\vec{y}_{(t + 1):\nPeriods}} \nonumber\\
\pdenstC{\vec{\alpha}_t}{\vec{\alpha}_{t +1}} &= \label{eq:bwTrans}
	\frac{
		\optorC{f}{\vec\alpha_{t+1}}{\vec\alpha_t}
		\gamma_t(\vec\alpha_t)
	}{\gamma_{t+1}(\vec\alpha_{t + 1})}
\end{align}%
%
where we have left out some of the normalization constants. 
Sampling from this artificial distribution turns out to be useful as it gives us an approximation of a
conditional density we need up to a constant (see Section \ref{sec:Brier}).
To derive the re-sampling weight, we first find an expression for the density $\pdenstC{\vec{\alpha}_t}{\vec{\alpha}_{t + 1}}$. 
We can observe that %
%
\begin{align*}
\log\pdenstC{\vec{\alpha}_t}{\vec{\alpha}_{t + 1}} &=  
	\log \optorC{f}{\vec\alpha_t}{\vec\alpha_{t + 1}}
	+ \log \gamma_t(\vec\alpha_t) + \dots \\
	&= -\frac 12\vec\alpha_t^\top\matLarrow{S}_t^{-1}
	\vec\alpha_t - \vec\alpha_t^\top\matLarrow{S}_t^{-1}
	\vecLarrow{a}_t(\vec\alpha_{t+1})
	+ \dots \\
\matLarrow{S}_t  &= \Lparen{\mat P^{-1}_t + \mat F^\top\mat Q^{-1}\mat F}^{-1} \\
\vecLarrow{a}_t(\vec x) &= 
	\matLarrow{S}_t\Lparen{\mat P_t^{-1}\vec m_t + \mat F^\top \mat Q^{-1}\vec x}
\end{align*}
%
so %
%
\begin{equation}\label{eqn:bwTransProp}
\pdenstC{\vec{\alpha}_t}{\vec{\alpha}_{t + 1}} = %
\normaldC{\vec\alpha_t}{\vecLarrow{a}_t(\vec{\alpha}_{t + 1})}%
{\matLarrow{S}_t}
\end{equation}. 

As shown by \cite{fearnhead10}, we can show that %
%
\begin{align}\label{eq:BWartCovar}
	\matLarrow{S}_t &= \matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\mat{Q}\mat{F}^{-\top} \\
%
	\vecLarrow{a}_t(\vec x) &=
		\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}\vec x
		+ \matLarrow{S}_t\matLarrow{P}_t^{-1} \vecLarrow{m}_t \nonumber
\end{align}%
%
e.g., by %
%
\begin{align*}
\Lparen{\matLarrow{P}_t\mat{F}^\top\matLarrow{P}_{t + 1}^{-1}
	\mat{Q}\mat{F}^{-\top}}^{-1}
	\Lparen{\mat P^{-1}_t + \mat F^\top\mat Q^{-1}\mat F}^{-1}
	\hspace{-175pt}& \\
&= \mat F^\top \mat Q^{-1}\matLarrow{P}_{t + 1}
	\mat F^{-\top}\matLarrow{P}_t^{-1}
	\Lparen{\mat P^{-1}_t + \mat F^\top\mat Q\mat F}^{-1} \\
&= \mat F^\top \mat Q^{-1}\matLarrow{P}_{t + 1}
	\mat F^{-\top}\matLarrow{P}_t^{-1}
	\Lparen{\matLarrow{P}_t - \matLarrow{P}_t
		\mat F^\top\Lparen{\mat Q + \mat F \matLarrow{P}_t 
			\mat F^\top}^{-1}
		\mat{F}\matLarrow{P}_t} \\
&= \mat F^\top \mat Q^{-1}\matLarrow{P}_{t + 1}
	\mat F^{-\top}
	\Lparen{\mat I -
		\mat F^\top\matLarrow{P}_{t + 1}^{-1}
		\mat{F}\matLarrow{P}_t} \\
&= \mat F^\top \mat Q^{-1}\matLarrow{P}_{t + 1}
	\mat F^{-\top} - \mat F^\top \mat Q^{-1} \mat F \matLarrow{P}_t \\
&= \mat F^\top \mat Q^{-1}\Lparen{
		\mat F \matLarrow{P}_t \mat F^\top + \mat Q}
	\mat F^{-\top} - \mat F^\top \mat Q^{-1} \mat F \matLarrow{P}_t \\
&= \mat I
\end{align*}
%
where we assume that all matrices are non-singular and we use the Woodbury matrix identity.
 Similar arguments can be used for $\vecLarrow{a}_t(\vec x)$. Using the above, we can 
 find that the optimal re-sampling weights are%
%
\begin{align}\label{eq:bwReWeight}
\particB{\beta}{t}{k} &\propto %
		\pdenstC{\vec{y}_t}{\particB{\vec\alpha}{t + 1}k}
		\particB w{t + 1}k \\
&\propto \int \nonumber
	\optorC{g_t}{\vec y_i}{\vec a_t}
	\pdenstC{\vec a_t}{\particB{\vec\alpha}{t + 1}k}
	\diff\vec a_t \particB w{t + 1}k \\
	&=\normaldC{\vec y_t }{
		\mat X_t \vecLarrow{a}_t(
		\particB{\vec\alpha}{t + 1}k) + \vec h_t}{%
	\mat X_t\matLarrow{S}_t\mat X_t^\top + \mat H_t}
	\particB w{t + 1}k\nonumber
\end{align}%
%
or we can set the re-sampling weights proportional to %
$\particB{\beta}{t}{k}\propto \particB w{t + 1}k$ and get a sequential importance re-sampling like algorithm. As for the proposal distribution, the optimal density is%
%
\begin{align*}
\log \IDAproxC{\vec\alpha_t}{\vec y_t, \particB{\vec{\alpha}}{t + 1}k}
	&= \log\pdenst{\vec\alpha_t, \particB{\vec\alpha}{t + 1}k, \vec y_t}
	+ \dots \\
	& = \log \gamma_t\Lparen{\vec{\alpha}_t}
	+ \log\optorC{g_t}{\vec y_t}{\vec{\alpha}_t}
	+ \log\optorC{f}{\partic{\vec\alpha}{t+1}k}{\vec\alpha_t} \\
	& = - \frac 12 \vec\alpha_t^\top \matLarrow\Sigma^{-1}_t\vec\alpha_t
		+ \vec\alpha_t^\top \matLarrow\Sigma_t^{-1}\vecLarrow\mu(
			\particB{\vec\alpha}{t + 1}k) + \dots \\
\matLarrow\Sigma_t &= \Lparen{\mat P_t^{-1} + \mat F^\top\mat Q^{-1}\mat F + 
		\mat X_t^\top \mat H^{-1}_t \mat X_t}^{-1} \\
\vecLarrow\mu_t(\vec x) &= \mat\Sigma_t\Lparen{
	\mat P_t^{-1}\vec m_t + \mat F^\top \mat Q^{-1}\vec x + 
	\mat X_t^\top\mat H_t^{-1}(\vec y_t - \vec h_t)}
\end{align*}%
%
Thus, we set %
%
$$
\IDAproxC{\vec\alpha_t}{\vec y_t, \particB{\vec{\alpha}}{t + 1}k} = 
\normaldC{\vec\alpha_t}{
		\vecLarrow\mu_t(\particB{\vec{\alpha}}{t + 1}k)}{
		\matLarrow\Sigma_t}
$$% 
% 
A computationally simpler but non-optimal option is to use a bootstrap filter like 
method and set%
%
\begin{equation}\label{eq:bootBW}
\IDAproxC{\vec\alpha_t}{\vec y_t, \particB{\vec{\alpha}}{t + 1}k} = 
	\pdenstC{\vec{\alpha}_t}{\particB{\vec{\alpha}}{t + 1}k}
\end{equation}

\subsubsection*{Combining / smoothing (Algorithm~\ref{alg:ONsmoother})}
We end this example with the conditional Gaussian observable outcome model with the 
proposal distribution needed for Algorithm~\ref{alg:ONsmoother}. We want to select 
%
\begin{align*}
\IDC{\vec\alpha_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} &=
		\pdensC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}} \\
&\propto \optorC{g}{\vec{y}_t}{\vec\alpha_t}
		\optorC{f}{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}}
		\optorC{f}{\particB{\vec{\alpha}}{t+1}{k}}{\vec{\alpha}_t}
\end{align*}
%
Looking at the log density as we did before, we find that %
%
\begin{align}
\log\IDC{\vec\alpha_t}{\partic{\vec{\alpha}}{t-1} j,\vec y_t,
 \particB{\vec{\alpha}}{t+1}k} 
	\hspace{-60pt}& \nonumber\\
&=\log\optorC{g}{\vec{y}_t}{\vec\alpha_t}
	+ \log\optorC{f}{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}}
	+ \log\optorC{f}{\particB{\vec{\alpha}}{t+1}{k}}{\vec{\alpha}_t} 		
	+ \dots \nonumber\\
& = - \frac 12 \vec\alpha_t^\top \matLRarrow\Sigma^{-1}_t\vec\alpha_t
		+ \vec\alpha_t^\top \matLRarrow\Sigma_t^{-1}\vecLRarrow\mu(
			\partic{\vec{\alpha}}{t-1} j,
			\particB{\vec\alpha}{t + 1}k) + \dots \nonumber\\
\matLRarrow\Sigma_t &= \Lparen{\mat Q^{-1} + \mat F^\top\mat Q^{-1}\mat F + 
		\mat X_t^\top \mat H^{-1} \mat X_t}^{-1} \label{eq:normalSmoothPropCov}\\
\vecLRarrow\mu_t(\vec x, \vecLarrow x) &= \mat\Sigma_t\Lparen{
	\mat Q^{-1}\mat F\vec x + \mat F^\top \mat Q^{-1}\vecLarrow x + 
	\mat X_t^\top\mat H_t^{-1}(\vec y_t - \vec h_t)} \label{eq:normalSmoothPropMean}
\end{align}% 
% 
so that
%
$$
\IDC{\vec\alpha_t}{\partic{\vec{\alpha}}{t-1} j,\vec y_t,
 \particB{\vec{\alpha}}{t+1}k} = 
 	\normaldC{\vec\alpha_t}{
		\vecLRarrow\mu_t(\partic{\vec{\alpha}}{t-1} j, 
			\particB{\vec{\alpha}}{t + 1}k)}{\mat\Sigma_t}
$$
%
Alternatively, we can use a bootstrap filter like proposal distribution with%
% 
\begin{equation}\label{eq:bootSM}\begin{split}
\matLRarrow\Sigma_t &= \Lparen{\mat Q^{-1} + \mat F^\top\mat Q^{-1}\mat F}^{-1} \\
\vecLRarrow\mu_t(\vec x, \vecLarrow x) &= \mat\Sigma_t\Lparen{
	\mat Q^{-1}\mat F\vec x + \mat F^\top \mat Q^{-1}\vecLarrow x}
\end{split}\end{equation}% 
% 
This is not optimal but faster.





\newpage

\begin{algorithm}[H]
\caption{$\bigO{\nPart}$ particle smoother using the method in \cite{fearnhead10}.}\label{alg:ONsmoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $
	\mat{Q},\mat{Q}_0,\vec{a}_0,
	\mat{X}_1,\dots,\mat{X}_d,
	\mat{Z}_1,\dots,\mat{Z}_d,
	\vec o_1,\dots,\vec o_d,
	\vec{y}_1,\dots,\vec{y}_d,
	R_1,\dots,R_d,\vec{\omega}$
%
\Statex Proposal distribution with density
\Statex \begin{equation}
	\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k}}
\end{equation}
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get particle clouds %
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,\nPart}$ %
	approximating the density $\pdensC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, \nPeriods$. See Algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,\nPeriods}$  %
	approximating the artificial density $\pdenstC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}$ for $t = \nPeriods + 1, \nPeriods, \nPeriods - 1, \dots, 1$. See Algorithm~\ref{alg:backward}.
\EndProcedure
%
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, \nPeriods$}
\StateXX \emph{Re-sample}
\State Sample $i=1,2,\dots,\nPart_s$ pairs of $\Lparen{j_i, k_i}\in\nPart^2$ where each component 
is independently sampled using re-sampling weights $\partic{\beta}{t}{j}$ and $\particB{\beta}{t}{k}$.
%
\StateXX \emph{Propagate}
\State Sample particles $\particS{\vec{\alpha}}{t}{i}$ from the proposal distribution %
	$\IDAproxC{\cdot}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k_i}}$%
.%
\StateXX \emph{Re-weight}
\State Assign each particle a weight
\StateXX \begin{equation}\label{eqn:combineWeight}
 \particS{w}{t}{i} \propto \frac{
 	\fFunc{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j_i}}
 	\gFunc{\vec{y}_t}{\particS{\vec{\alpha}}{t}{i}}{t}
 	\fFunc{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particS{\vec{\alpha}}{t}{i}}
 	\partic{w}{t - 1}{j_i}\particB{w}{t + 1}{k_i}
 	}{ % end of first argument of \frac
 	\IDAproxC{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i},\vec{y}_t, \particB{\vec{\alpha}}{t+1}{k_i}}
 	\partic{\beta}{t}{j_i}\particB{\beta}{t}{k_i}\gamma_{t +1}\Lparen{\particB{\vec{\alpha}}{t+1}{k_i}}
 	} % end of frac
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Forward filter as in \cite{pitt99}. It is equivalent with \citet[p. 20 and 25]{doucet09}. The version and notation below is from \citet[p. 449]{fearnhead10}.}\label{alg:forward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex Proposal distribution with density 
\Statex $$
\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}, \vec{y}_t}
$$
\Statex Function $h$ to compute re-sampling weights 
$$
	\partic{\beta}{t}{j} \propto h(\vec{y}_t,\partic{\vec{\alpha}}{t-1}{j})\partic{w}{t-1}{j}
$$
\State Sample $\partic{\vec{\alpha}}{0}{1},\dots,\partic{\vec{\alpha}}{0}{\nPart_f}$ particles from $\normal{\vec\mu_0}{\mat{Q}_0}$ and set the weights $\partic{w}{0}{1},\dots,\partic{w}{0}{\nPart_f}$ to $1 / \nPart_f$.
%
\For{$t=1,\dots, \nPeriods$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\partic{\beta}{t}{j}$ using $h$ and re-sample 
according to $\partic{\beta}{t}{j}$ to get indices $j_1,\dots j_\nPart$. If we do not 
re-sample then set $\partic{\beta}{t}{j} = 1 / \nPart$ or $1/ \nPart_f$ at time $t = 1$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\partic{\vec{\alpha}}{t}{i}$ using the proposal distribution $\IDC{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using 
\StateX \begin{equation}\label{eqn:forwardWeight}
	\partic{w}{t}{i} \propto \frac{
		\gFunc{\vec{y}_t}{\partic{\vec{\alpha}}{t}{i}}{t}
		\fFunc{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}}
		\partic{w}{t-1}{j_i}
	}{ % \frag arg1 end
		\IDC{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}, \vec{y}_t}
		\partic{\beta}{t}{j_i}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}



\begin{algorithm}[H]
\caption{Backwards filter. See \cite{briers09} and \cite{fearnhead10}.}\label{alg:backward}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex An artificial distribution
\begin{equation}
	\pdenstC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}} \propto \gamma_t \Lparen{\vec{\alpha}_t}\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}
\end{equation}
\Statex with an  artificial prior distribution $\gamma_t \Lparen{\vec{\alpha}_t}$. 
\Statex Proposal distribution  
$$\IDAproxC{\vec{\alpha}_t}{\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k}}$$
\Statex Function $h$ to compute re-sampling weights 
$$
\particB{\beta}{t}{k} \propto  h(
	\vec{y}_t, \particB{\vec{\alpha}}{t + 1}{k})
	\particB{w}{t + 1}{k}
$$
%
\State Sample $\particB{\vec{\alpha}}{\nPeriods+1}{1},\dots,\particB{\vec{\alpha}}{\nPeriods+1}{\nPart_f}$ particles from $\gamma_{\nPeriods+1}(\cdot)$ and set the weights $\particB{w}{\nPeriods + 1}{1},\dots,\partic{w}{\nPeriods+1}{\nPart_f}$ to $1 / \nPart_f$.
%
\For{$t=\nPeriods,\dots, 1$}
\Procedure{Re-sample}{}
\State Compute re-sampling weights $\particB{\beta}{t}{k}$ using $h$ and re-sample according to $\particB{\beta}{t}{k}$ to get indices $k_1,\dots k_\nPart$. If we do not re-sample then set $\particB{\beta}{t}{k} = 1 / \nPart$ 
or $1 / \nPart_f$ at time $t = \nPeriods$.
\EndProcedure
%
\Procedure{Propagate}{}
\State Sample new particles $\particB{\vec{\alpha}}{t}{i}$ using the proposal distribution $\IDAproxC{\vec{\alpha}_t}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}$.
\EndProcedure
%
\Procedure{Re-weight}{}
\State Re-weight particles using
\StateX \begin{equation}\label{eqn:backwardWeight}
	\particB{w}{t}{i} \propto \frac{
		\gFunc{\vec{y}_t}{\particB{\vec{\alpha}}{t}{i}}{t}
		\fFunc{\particB{\vec{\alpha}}{t + 1}{k_i}}{\particB{\vec{\alpha}}{t}{i}}
		\gamma_t\Lparen{\particB{\vec{\alpha}}{t}{i}}
		\particB{w}{t + 1}{k_i}
	}{ % \frag arg1 end
		\IDC{\particB{\vec{\alpha}}{t}{i}}{\particB{\vec{\alpha}}{t + 1}{k_i}, \vec{y}_t}
		\gamma_{t + 1}\Lparen{\particB{\vec{\alpha}}{t + 1}{k_i}}
		\partic{\beta}{t}{k_i}
	}
\end{equation}
\EndProcedure
\EndFor
\end{algorithmic}
\end{algorithm}

\newpage

\section{Non-linear conditional observation model}\label{sec:NonLinObs}
If we go back to the model in Equation~\eqref{eqn:model} then $\vec y_t
\mid \vec\alpha_t$ is not a multivariate normal distribution for the 
implemented models.   
In this case, we have no closed from solutions
for the optimal re-sampling weights, and we do not know the following conditional 
distributions: $\vec\alpha_t \mid \vec y_t, \vec\alpha_{t-1}$, 
$\vec\alpha_t \mid \vec y_t, \vec\alpha_{t+1}$ (in the artificial 
distribution $\widetilde{\Prob}$), and 
$\vec\alpha_t \mid \vec y_t, \vec\alpha_{t-1}, \vec\alpha_{t+1}$. 
However, assume that $\optorC{g_t}{\vec{y}_t}{\vec{\alpha}_t}$ 
is log-concave in $\vec{\alpha}_t$. If this is true then it is easy 
to show that all of the previous three conditional distributions are 
unimodal. Hence, we can make a multivariate normal approximation as in \cite{pitt99}. To do so, we
 make a second order Taylor expansion around some value $\vec z$ 
to get%
%
\begin{align*}
k_t(\vec\alpha_t) &= \log\optorC{g_t}{\vec y_t}{\vec\eta(\vec\alpha_t)}, 
	\qquad \vec\eta(\vec\alpha_t) = \mat{X}_t\vec{\alpha}_t + \vec h_t \\
\log\optorC{g_t}{\vec{y}_t}{\vec\alpha_t}&\approx
	\Jaco k_t(\vec z) (\vec\alpha_t - \vec z) 
	+  \frac 12(\vec\alpha_t - \vec z)^\top
	\Hess k_t(\vec z)
	(\vec\alpha_t - \vec z) + \dots \\
&\hspace{-40pt}= \vec\alpha_t^\top \Jaco k_t(\vec z)^\top -
	\frac 12(\vec\alpha_t - \vec z)^\top
	\Lparen{-\Hess k_t(\vec z)}
	(\vec\alpha_t - \vec z) + \dots \\
&\hspace{-40pt}= \vec\alpha_t^\top\Lparen{-\Hess k_t(\vec z)}\Lparen{
	\vec z - \Hess k_t(\vec z)^{-1}\Jaco k_t(\vec z)^\top} 
	- \frac 12 \vec\alpha_t^\top\Lparen{-\Hess k_t(\vec z)}\vec\alpha_t + \dots
\end{align*}%
%
where $\dots$ includes the zero order term, $\Jaco k_t$ is the Jacobian,
and $\Hess k_t$ denotes the Hessian. I add a subscript to $\Jaco$ and $\Hess$
to indicate when Jacobian or Hessian is with respect to a given variable.
We still assume that we use a first 
order state space model such that $\dimRng = \dimState$. We notice that %
%
\begin{align*}
\Hess k_t(\vec z) &= 
	\Jaco_{\vec\alpha_t}\vec\eta(\vec z)^\top
	\Hess_{\vec\eta}\log\optorC{g_t}{\vec y_t}{\vec\eta(\vec z)}
	\Jaco_{\vec\alpha_t}\vec\eta(\vec z) \\
	&=\mat X_t^\top(-\mat G_t(\vec z))\mat X_t, \qquad 
	\mat G_t(\vec z) = -\Hess_{\vec\eta}\log\optorC{g_t}{\vec y_t}{\vec\eta(\vec z)}
\end{align*}%
%
which follows from the chain rule and we use that %
$\Hess_{\vec\alpha_t}\vec\eta(\vec z) = \mat 0$. Thus, %
%
\begin{align*}
\log\optorC{g_t}{\vec{y}_t}{\vec\alpha_t} &\approx 
	\vec\alpha_t^\top\mat X_t^\top\mat G_t(\vec z)\vec u_t(\vec z)
	- \frac 12 \vec\alpha_t\mat X_t^\top
	\mat G_t(\vec z)\mat X_t\vec\alpha_t \\
\vec u_t(\vec z) &= 
	\mat X_t\vec z - \mat X_t\Hess k_t(\vec z)^{-1}\Jaco k_t(\vec z)^\top
\end{align*}
%
This yields the following multivariate normal approximation %
%
\begin{align*}
\optorC{g_t}{\vec{y}_t}{\vec\alpha_t} &\approx 
	\normaldC{\mat X_t\vec\alpha_t}{\vec u_t(\vec z)}{\mat G_t(\vec z)^{-1}}
\end{align*}

The Taylor approximation is easily used in the proposal distributions. E.g., for given $\vec z$, we get the following mean and covariance matrix analogues to Equation \eqref{eq:fwNormProCovar} and \eqref{eq:fwNormProMean} in the proposal distribution in the forward particle filter %
%
\begin{align*}
\mat\Sigma_t(\vec z) &= \Lparen{\mat Q^{-1} + \mat X_t^\top
	\mat G_t(\vec z)\mat X_t}^{-1} \\
\vec\mu_t(\vec x, \vec z) &= \mat\Sigma_t(\vec z)\Lparen{
	\mat Q^{-1}\mat F\vec x + \mat X^\top_t\mat G_t(\vec z)
	\vec u_t(\vec z)}
\end{align*}%
% 
As for the re-sampling weights, we can use%
%
\begin{align*}
\widehat{\vec\alpha} &= \vec\mu_t(\partic{\vec\alpha}{t-1}j, \vec z) \\
\partic\beta tj &\propto 
	\pdensC{\vec y_t}{\partic{\vec\alpha}{t-1}j}\partic w{t-1}j \\
	&= \frac{ %
		\pdensC{\vec y_t}{\partic{\vec\alpha}{t-1}j}
	}{%
		\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
		\optorC{f}{\widehat{\vec\alpha}}{\partic{\vec\alpha}{t-1}j}
	}
	\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
	\optorC{f}{\widehat{\vec\alpha}}{\partic{\vec\alpha}{t-1}j}
	\partic w{t-1}j \\
	&= \frac{ %
		\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
		\optorC{f}{\widehat{\vec\alpha}}{\partic{\vec\alpha}{t-1}j}
		\partic w{t-1}j
	}{%
		\pdensC{\widehat{\vec\alpha}}{
		\partic{\vec\alpha}{t-1}j, \vec y_t}
	} \\
	&\approx
	\frac{ %
		\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
		\optorC{f}{\widehat{\vec\alpha}}{\partic{\vec\alpha}{t-1}j}
		\partic w{t-1}j
	}{%
		\IDC{\widehat{\vec\alpha}}{\partic{\vec\alpha}{t-1}j, \vec y_t}
	}
\end{align*}
%
as in \cite{fearnhead10}. We can approximate the backwards particle filter re-sampling weights in equation~\eqref{eq:bwReWeight} in a similar way

\begin{align}
\particB{\beta}{t}{k} &\propto %
		\pdenstC{\vec{y}_t}{\particB{\vec\alpha}{t + 1}k}
		\particB w{t + 1}k\nonumber\\
	&\approx \frac{ %
		\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
		\pdenstC{\widehat{\vec\alpha}}{\particB{\vec{\alpha}}{t + 1}k}
		\particB w{t + 1}k
	}{%
		\IDAproxC{\widehat{\vec\alpha}}{\vec y_t, 
			\particB{\vec{\alpha}}{t + 1}k}
	}\nonumber\\
&= \frac{ %
		\optorC{g_t}{\vec{y}_t}{\widehat{\vec\alpha}}
		\optorC{f}{\particB{\vec{\alpha}}{t + 1}k}{\widehat{\vec\alpha}}
		\gamma_t(\widehat{\vec\alpha})
		\particB w{t + 1}k
	}{%
		\IDAproxC{\widehat{\vec\alpha}}{\vec y_t, 
			\particB{\vec{\alpha}}{t + 1}k}
		\gamma_{t+1}(\particB{\vec{\alpha}}{t + 1}k)
	}\label{eq:bwResampleW}\\
\widehat{\vec\alpha} &= 
	\vecLarrow\mu (\particB{\vec{\alpha}}{t + 1}k, \vec z)\nonumber\\
\vecLarrow\mu (\vec x, \vec z)
	&= \matLarrow\Sigma_t(\vec z)\Lparen{
	\mat P_t^{-1}\vec m_t + \mat F^\top \mat Q^{-1}\vec x + 
	\mat X_t^\top\mat G_t(\vec z)\vec u_t(\vec z)} \label{eq:bwPropBackMean}\\
\matLarrow\Sigma_t(\vec z) &= 
	\Lparen{\mat P_t^{-1} + \mat F^\top\mat Q^{-1}\mat F + 
		\mat X_t^\top \mat G_t(\vec z) \mat X_t}^{-1} \label{eq:bwPropBackCov} 
\end{align}

We may also use a multivariate $t$-distribution for the proposal distribution to get heavier
tails than we do with the multivariate normal distribution. This is important as too light tailed 
proposal distributions (relative to the target) can yield few large importance weights.

\subsection{Where to make the expansion}
An options is to make the Taylor expansion at a mode for each particle or particle pair in the smoothing step. This yields%
%
\begin{align*}
\vec z^{(j)} &= \argmax_{\vec z }
	\optorC{g_t}{\vec{y}_t}{\vec z}
	\optorC{f}{\vec z}{\partic{\vec\alpha}{t-1}j} \\
\vec z^{(k)} &= \argmax_{\vec z }
	\optorC{g_t}{\vec{y}_t}{\vec z}
	\gamma_t(\vec{z})
	\optorC{f}{\particB{\vec{\alpha}}{t + 1}k}{\vec z}\\
\vec z^{(i)} &= \argmax_{\vec z }
	\fFunc{\vec z}{\partic{\vec{\alpha}}{t - 1}{j_i}}
 	\gFunc{\vec{y}_t}{\vec z}{t}
 	\fFunc{\particB{\vec{\alpha}}{t + 1}{k_i}}{\vec z}
\end{align*}%
% 
for respectively the forward particle filter, backward particle filter, and smoother.
The downside is a $\bigO{\dimRng^2\nMax\nPart_S}$ or $\bigO{\dimRng^2\nMax\nPart}$ 
computational complexity at each time point 
as we have to evaluate $\mat X_t^\top \mat G_t(\vec z) \mat X_t$
for each particle or particle pair. Instead we can make the approximation 
once at each time point at 
respectively $\sum_{i=1}^\nPart \partic w{t-1}j\partic{\vec\alpha}{t-1}j$, %
$\sum_{i=1}^\nPart \particB w{t+1}j\particB{\vec\alpha}{t+1}j$, and %
%
$$
\Lparen{\mat Q^{-1} + \mat F^\top \mat Q^{-1}\mat F}^{-1}
\Lparen{\mat Q^{-1}\mat F\sum_{i=1}^\nPart \partic w{t-1}j\partic{\vec\alpha}{t-1}j + 
	\mat F^\top\mat Q^{-1}\sum_{i=1}^\nPart \particB w{t+1}j\particB{\vec\alpha}{t+1}j}
$$%
% 
which will reduce the computational complexity  at each time point to %
$\bigO{\dimRng\nMax\nPart_S + \dimRng\dimState\nMax}$ %
or $\bigO{\dimRng\nMax\nPart  + \dimRng\dimState\nMax}$. 


\section{Higher order state-space models}
Now, we will consider the case where $\dimState > \dimRng$. 
Currently this is not supported in the package but may be in the future. 
An example is a seconder 
order vector auto-regression, $\MVAR{2}$, with $2\dimRng = \dimState$ and %
%
\begin{align*}
\mat F &= \begin{pmatrix}
		\mat F_1 & \mat F_2 \\
		\mat I_\dimRng & \mat 0
	\end{pmatrix}, \quad \mat F_i \in \mathbb{R}^{\dimRng\times\dimRng} \\
\vec\alpha_t &= \begin{pmatrix}
	\vec\xi_t^\top & \vec\xi_{t-1}^\top
\end{pmatrix}^\top
\end{align*}%
%
Here %
%
\begin{align*}
\optorC{f}{\vec\alpha_t}{\vec\alpha_{t - 1}} &= 
	\dirac{\mat K\mat F\vec\alpha_{t-1}}{\mat K\vec\alpha_t}
	\normaldC{\mat R^+\vec\alpha_t}{
		\mat R^+\mat F\vec\alpha_{t-1}}{\mat Q}, 
	& \mat K &=
		\begin{pmatrix} \mat 0 \\ \mat I_{\dimState - \dimRng} \end{pmatrix}  \\
&= \dirac{\vec \xi_{t-1}}{\mat K\vec\alpha_t}
	\normaldC{\vec\xi_t}{\mat R^+\mat F\vec\alpha_{t-1}}{\mat Q}
\end{align*}%
%
the second equality follows in a seconder order vector auto-regression. 
This is easily implemented in the forward 
particle filter by sampling $\vec\xi_t \mid \vec\alpha_{t-1}$ and setting the remaining
$\dimState - \dimRng$ variables of $\vec\alpha_t$ to 
$\mat K\mat F\vec\alpha_{t-1}$ (the last $\dimState - \dimRng$ rows of 
$\mat F\vec\alpha_{t-1}$). It is not as easy for the backward filter. To see this, consider the artificial transition density in Equation~\eqref{eq:bwTrans}%
%
\begin{align*}
\pdenstC{\vec{\alpha}_t}{\vec{\alpha}_{t+1}} &= 
	\frac{
		\optorC{f}{\vec\alpha_{t+1}}{\vec\alpha_t}
		\gamma_t(\vec\alpha_t)
	}{\gamma_{t+1}(\vec\alpha_{t + 1})} \\
& = \frac{
		\dirac{\mat K\mat F\vec\alpha_t}{\mat K\vec\alpha_{t + 1}}
		\normaldC{\mat R^+\vec\alpha_{t +1}}{
			\mat R^+\mat F\vec\alpha_t}{\mat Q}
		\gamma_t(\vec\alpha_t)
	}{\gamma_{t+1}(\vec\alpha_{t + 1})}
\end{align*}%
%
where the last equality holds in this example. This distribution is obviously degenerate 
as it only has mass at the point $\vec\xi_t = \mat K\mat F\vec\alpha_t$ in the 
$\text{VAR}(2)$ model. 

\subsection{Backward particle filter}
What we can do in the backward particle filter in a $\MVAR{o}$ model with $o > 1$ is to 
sample $\vec\xi_t$ at 
time $t$ given $\particB{\vec\alpha}{t + o}k$. Thus, we start Algorithm \ref{alg:backward} by 
sampling $\vec\alpha_{d + o}$. 
Further, we change the artificial 
prior distribution density in Equation~\eqref{eq:artfiPrior} to %
%
\begin{align*}
	\gamma_t\Lparen{\vec{\alpha}_t} &=
		\normaldC{\vec{\alpha}_t}{\vecLarrow{m}_t}{\matLarrow{P}_t} \\
	\gamma_t\Lparen{\vec\xi_t} &= 
		\normaldC{\vec{\alpha}_t}{\mat R^+\vecLarrow{m}_t}{
			\mat R^+\matLarrow{P}_t\mat R^{+\top}} \\
%
	\vecLarrow{m}_t &= \mat{F}^t\vec\mu_0 \\
%
	\matLarrow{P}_t &= \left\{
		\begin{matrix} \mat{Q}_0 & t = 0 \\ \mat{F}\matLarrow{P}_{t - 1}\mat{F}^\top + 
		\mat R\mat Q\mat R^\top & t > 0   \end{matrix} \right.
\end{align*}%
%
Next, we find the conditional distribution $\particB{\vec\alpha}{t + o}k \mid \vec\xi_t$. 
To do so, we first find the join distribution of %
$(\vec \alpha_{t + o}^\top, \vec \xi_t^\top)^\top$.  We can find that%
%
\begin{align*}
\vec\xi_k &= 
	\mat R^+\mat F^k \vec\alpha_0 + \sum_{i = 1}^k \mat G(k - i) \vec\epsilon_i \\
\mat G(j) &= \left\{ \begin{matrix}
	\mat I_\dimRng & j = 0 \\
	\sum_{i = 1}^{\min (j, o)} \mat F_i \mat G(j - i) & j > 0
\end{matrix}\right.
\end{align*}
% 
Thus, %
%
\begin{align*}
\expec{\vec\xi_t} &= \mat R^+\mat F^k\vec\mu_0 = \mat R^+\vec m_t \\
\expec{\vec\alpha_t} &= \vec m_t \\
\varp{\vec\xi_t} &= \sum_{i = 1}^t \mat G(t - i) \mat Q \mat G(t - i)^\top + 
	\mat R^+\mat F^t\mat Q_0 \mat F^{t\top}\mat R^{+\top} \\ 
	&= \mat R^+\mat P_t \mat R^{+\top} \\
\covp{\vec\xi_k, \vec\xi_l} &= 
	\sum_{i = 1}^l\mat G(k - i)\mat Q \mat G(l - i)^\top
	+ \mat R^+\mat F^k\mat Q_0\mat F^{l\top}\mat R^{+\top}, 
	& k &> l \\
\varp{\vec\alpha_t} &= \mat P_t 
\end{align*}%
% 
with which we can find that the joint distribution is %
%
$$
\begin{pmatrix}
	\vec \alpha_{t + o} \\ \vec \xi_t
\end{pmatrix} \sim  \normal{%
	\begin{pmatrix} \vec m_{t+o} \\ \mat R^+\vec m_t  \end{pmatrix}}{%
	\begin{pmatrix}
		\mat P_{t + o} & \covp{\vec\alpha_{t + o}, \vec\xi_t} \\
		\covp{\vec\xi_t, \vec\alpha_{t + o}} &  \mat R^+\mat P_t \mat R^{+\top} \\
	\end{pmatrix}
}
$$%
% 
We are now able to compute %
%
\begin{align*}
\expecC{\vec \alpha_{t + o}}{\vec \xi_t} &= 
	\subCond{\vec\mu}{\alpha_{t + o}}{\vec\xi_t}
	= \vec m_{t + o} + \covp{\vec\alpha_{t + o}, \vec\xi_t}
		\mat R^\top\mat P_t^{-1} \mat R\Lparen{\vec\xi_t - \mat R^+\vec m_t} \\
	&= \vec v_t + \mat V_t\vec\xi_t \\
\mat V_t &= \covp{\vec\alpha_{t + o}, \vec\xi_t}\mat R^\top\mat P_t^{-1} \mat R \\
\vec v_t &= \vec m_{t + o} - \mat V_t\mat R^+\vec m_t \\
\varpC{\vec \alpha_{t + o}}{\vec \xi_t} &=
	\subCond{\mat\Sigma}{\vec\alpha_{t + o}}{\vec\xi_t} 
	= \mat P_{t + o} - \covp{\vec\alpha_{t + o}, \vec\xi_t}
		\mat R^\top\mat P_t^{-1} \mat R\covp{\vec\xi_t, \vec\alpha_{t + o}}
\end{align*}

Having found this conditional distribution then we can apply similar arguments as we did 
before and find the following mean and covariance matrix in the proposal distribution %
%
\begin{align*}
\vecLarrow\mu (\particB{\vec{\alpha}}{t + o}k, \vec z)
	&= \matLarrow\Sigma_t(\vec z)\Lparen{
	\mat R^\top\mat P_t^{-1}\vec m_t + 
	\mat V_t^\top\subCond{\mat\Sigma}{\alpha_{t + o}}{\vec\xi_t}^{-1}
	(\particB{\vec{\alpha}}{t + o}k - \vec v_t) + 
	\mat X_t^\top\mat G_t(\vec z)\vec u_t(\vec z)} \\
\matLarrow\Sigma_t(\vec z) &= 
	\Lparen{
		\mat R^\top\mat P_t^{-1} \mat R + 
		\mat V_t^\top\subCond{\mat\Sigma}{\vec{\alpha}_{t + o}}{\vec\xi_t}^{-1}\mat V_t + 
		\mat X_t^\top \mat G_t(\vec z) \mat X_t}^{-1}
\end{align*} %
%
which replaces the mean and covariance matrix in Equation \eqref{eq:bwPropBackMean} and \eqref{eq:bwPropBackCov},
$\vec z_t\in\mathbb R^\dimRng$ is the value of $\vec\xi_t$ at which we make the Taylor expansion, and
$\mat G_t$ and $\vec u_t$ are defined in terms of $\vec\xi_t$. The new proposal distribution 
is used in Equation \eqref{eq:bwResampleW} when we compute the re-sampling weights where 
we change the $\gamma_t$ and $\gamma_{t+1}$ function. The two densities are changed to be 
$\gamma_t(\widehat{\vec\xi})$ in the numerator and 
$\gamma_{\nPeriods + 1}(\particB{\vec{\alpha}}{\nPeriods + 1}k)$ or 
$\gamma_{t + 1}(\particB{\vec\xi}{t + 1}k)$ at $t < \nPeriods$ in the denominator 
where $\gamma_t$ is understood as marginal density of $\vec\xi_t$ when xi is used instead 
of alpha.

\subsection{Combining/smoothing}
Similarly, in Algorithm~\ref{alg:ONsmoother} we sample pairs of particles 
$(\partic{\vec{\alpha}}{t - 1}{j_i}, \particB{\vec{\alpha}}{t + o}{k_i})$, 
and sample $\vec\xi_t$ given each pair. We can replace the mean and covariance matrix in 
the proposal distribution in Equation~\eqref{eq:normalSmoothPropMean} and 
\eqref{eq:normalSmoothPropCov} with the approximation %
%
\begin{align*}
\matLRarrow\Sigma_t(\vec z) &= \Lparen{
	\mat Q^{-1} + 
	\mat V_t^\top\subCond{\mat\Sigma}{\alpha_{t + o}}{\vec\xi_t}^{-1}\mat V_t + 
	\mat X_t^\top \mat G_t(\vec z) \mat X_t}^{-1}\\
\vecLRarrow\mu_t(\partic{\vec{\alpha}}{t - 1}{j_i}, 
	\particB{\vec{\alpha}}{t + o}{k_i}, \vec z) & \\
	&\hspace{-50pt}=
	\mat\Sigma_t(\vec z)\Lparen{
		\mat Q^{-1}\mat R^+\mat F\partic{\vec{\alpha}}{t - 1}{j_i} + 
		\mat V_t^\top\subCond{\mat\Sigma}{\alpha_{t + o}}{\vec\xi_t}^{-1}
			(\particB{\vec{\alpha}}{t + o}{k_i} - \vec v_t) + 
		\mat X_t^\top \mat G_t(\vec z) \mat X_t}
\end{align*}%
% 
where $\vec z$ is the value of $\vec\xi_t$ that we make the Taylor expansion at. 





\section{Log likelihood evaluation}
We can evaluate the log likelihood for a particular value of $\vec{\theta} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec \mu_0, \mat{F}}$ as described in \citet[p. 5]{doucet09} and \citet[p. 193]{malik11} using the forward particle filter shown in Algorithm~\ref{alg:forward}.

\section{Parameter estimation}
In this section I first show an example of parameter estimation in the first 
order random walk using the EM-algorithm \citep{dempster77}. Then I cover the 
general vector auto-regression model and how one can estimate the fixed 
effects.

The formulas for parameter estimation for the first order random are particularly simple. We need to estimate $\mat{Q}$ and $\vec{a}_0$ elements of $\vec{\varphi} = \Lbrace{\mat{Q}, \mat{Q}_0, \vec\mu_0}$. We do this by running Algorithm~\ref{alg:ONsmoother} for the current $\vec{\varphi}$. This yields the following quantities from the E-step%
%
\begin{equation}\begin{split}
\vec{t}_t^{(\vec{\varphi})} &\approx \sum_{i = 1}^{\nPart_s} \particS{\vec{\alpha}}{t}{i} \particS{w}{t}{i} \\
%
\vec{T}_t^{(\vec{\varphi})} & \approx \sum_{i = 1}^{\nPart_s}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_{it}}}
	\Lparen{\particS{\vec{\alpha}}{t}{i} - \mat{F}\partic{\vec{\alpha}}{t-1}{j_{it}}}^\top
	\particS{w}{t}{i}
\end{split}\end{equation}%
%
%
where  we have extended the notation in Algorithm~\ref{alg:ONsmoother} such that superscript $j_{it}$ is the index from forward cloud at time $t-1$ matching with $i$th smoothed particle at time $t$.
Then we carry out the M-step by updating $\vec\mu_0$ and $\mat{Q}$ given the summary statistics above%
%
\begin{equation}
\vec\mu_0 = \vec{t}_1^{(\vec{\varphi})} \qquad
%
\mat{Q} = \frac{1}{\nPeriods - 1}\sum_{t = 2}^\nPeriods \mat{R}^+\vec{T}_t^{(\vec{\varphi})}\mat{R}^{+\top}
\end{equation}%

We then take another iteration of the EM-algorithm with the new $\vec\mu_0$ and $\mat{Q}$ 
and repeat
till a convergence criteria is satisfied.  See \cite{kantas15}, \cite{del10} and \cite{schon11} for further details on parameter estimation with particle filters.

\subsection{Vector auto-regression models}\label{subsec:VAR}
We start by defining the following matrices to cover estimation in general vector auto-regression models for the latent space variable %
%
\begin{align*}
\mat{N} &= \Lparen{
    	\particS{\vec{\alpha}}{2}{1},
    	\dots, 
    	\particS{\vec{\alpha}}{2}{\nPart_s}, 
    	\particS{\vec{\alpha}}{3}{1},
    	\dots, 
    	\particS{\vec{\alpha}}{3}{\nPart_s},
    	\particS{\vec{\alpha}}{4}{1},
    	\dots, 
   		\particS{\vec{\alpha}}{\nPeriods}{\nPart_s}
	}^\top\mat{R}^{+\top} \\
%
\mat{M} &= \Lparen{
    	\partic{\vec{\alpha}}{1}{j_{12}},
    	\dots, 
    	\partic{\vec{\alpha}}{1}{j_{\nPart_s2}}, 
    	\partic{\vec{\alpha}}{2}{j_{13}},
    	\dots, 
    	\partic{\vec{\alpha}}{2}{j_{\nPart_s3}},
    	\partic{\vec{\alpha}}{3}{j_{14}},
    	\dots, 
   		\partic{\vec{\alpha}}{\nPeriods - 1}{j_{\nPart_s\nPeriods}}
	}^\top \\
%
\mat{W} &= \diag{
		\particS{w}{2}{1}, \dots, \particS{w}{2}{\nPart_s},
		\particS{w}{3}{1}, \dots, \particS{w}{3}{\nPart_s},
		\particS{w}{4}{1}, \dots,\particS{w}{\nPeriods}{\nPart_s}
	}
\end{align*}%
% 
where $\diag{\cdot}$ is a diagonal matrix. We suppress the dependence above
 on the result of the E-step in 
a given iteration of the EM-algorithm to ease the notation. The goal is to estimate $\mat{F}$ and $\mat{Q}$ 
in Equation~\eqref{eqn:model}. We can find that the M-step maximizers are%
% 
\begin{align}
\widehat{\mat{F}}^\top\mat{R}^{+\top} &=
	\Lparen{\mat{M}^\top\mat{W}\mat{M}}^{-1}	
	\mat{M}^\top\mat{W}\mat{N} \label{eqn:VARF} \\
%
\widehat{\mat{Q}} &= 
	\frac{1}{\nPeriods - 1}
	\Lparen{\mat{N} - \mat{R}^+\widehat{\mat{F}}\mat{M}}^\top
	\mat{W}
	\Lparen{\mat{N} - \mat{R}^+\widehat{\mat{F}}\mat{M}} \label{eqn:VARQ}
\end{align}%
%
which are the typical vector auto-regression estimators with weights. Equation \eqref{eqn:VARF}~and \eqref{eqn:VARQ} can easily be computed in parallel using QR decompositions as in the \texttt{bam} function in the \texttt{mgcv} package with a low memory footprint \citep[see][]{wood14}. This is currently implemented. Though, the gains from a parallel implementation may be small as the computational complexity 
is independent of the number of observations. Consequently, the computation involved here is often fast
as the dimension of the state vector is small.

\subsection{Restricted vector auto-regression models}
Suppose that we want to restrict some of the parameters of $\mat{F}$ and $\mat{Q}$. Let%
%
\begin{align*}
  (s_1,s_2,\dots, s_\dimRng)^\top&=\mat{J}\vec\psi \\
  (o_{21},o_{31},\dots,o_{\dimRng1},o_{32},\dots,o_{r2},o_{43},\dots,o_{\dimRng,\dimRng-1})^\top&=\mat{K}\vec\phi  
\end{align*} %
%
Then we can restrict the model such that %
%
\begin{align*}
\sigma_i &= \exp(s_i) & 
  \rho_{ij}&= \frac{2}{1 + \exp(-o_{ij})} - 1 \\
\vecOP{\mat{R}^+\mat{F}} &= \mat{G}\vec{\theta} &  
  \mat{Q} &= \mat{V}\mat{C}\mat{V} \\
\mat{V} &= \begin{pmatrix} 
     \sigma_1 & 0 & \cdots & 0 \\
     0 & \sigma_2 & \ddots & 0 \\
     \vdots & \ddots & \ddots & \vdots \\
     0 & \dots & 0 & \sigma_\dimRng
   \end{pmatrix} &
  \mat{C} &= \begin{pmatrix} 
     1 & \rho_{21} & \cdots & \rho_{\dimRng1} \\
     \rho_{21} & 1 & \ddots & \rho_{\dimRng2} \\
     \vdots & \ddots & \ddots & \vdots \\
     \rho_{\dimRng1} & \dots & \rho_{\dimRng,\dimRng-1} & 1
   \end{pmatrix}
\end{align*}%
%
and where $\vecOP{\cdot}$ is the vectorization function which stacks the the columns of a matrix from left to right. E.g., %
%
\begin{align*}
\vecOP{\mat{A}} &= \Lparen{
	a_{11}, a_{21}, a_{31}, 
	a_{12}, a_{22}, a_{32},
	a_{13}, a_{23}, a_{33}}^\top \\
\mat{A} &= \begin{pmatrix}
	a_{11} & a_{12} & a_{13} \\
	a_{21} & a_{22} & a_{23} \\
	a_{31} & a_{32} & a_{33}
\end{pmatrix}
\end{align*}
%
$\mat{G}\in\mathbb{R}^{\dimRng\dimState \times g}$ is a known matrix with $g \leq \dimRng\dimState$ and we assume that it has full column rank. Similarly, $\mat{J}\in\mathbb{R}^{\dimRng \times l}$ with $l \leq \dimRng$ and $\mat{K}\in\mathbb{R}^{\dimRng(\dimRng - 1)/2 \times k}$ with $k\leq \dimRng(\dimRng - 1)/2$. Both are known and have full column rank. 
We assume that $\mat{G}$ is such that $\mat{F}$ is non-singular for some $\vec{\theta}$ since 
Equation~\eqref{eq:BWartCovar} used. Further, we assume that $\mat{J}$ and $\mat{K}$ are such that $\mat{Q}$ is a positive definite matrix for some $\vec{\psi}$ and $\vec{\phi}$ pair. $\mat{V}$ is a diagonal matrix containing the standard deviations and $\mat{C}$ is the correlation matrix.

We cannot jointly maximize $\vec{\theta}$, $\vec{\psi}$, and $\vec{\phi}$ analytically but we can maximize $\vec{\theta}$ analytically conditional on $\vec{\psi}$ and $\vec{\phi}$. Hence, we can employ a Monte Carlo expectation conditional maximization algorithm in which we take two so-called conditional maximization steps \citep[see][for the, non-Monte Carlo, expectation maximization algorithm]{meng93}. 
The first conditional maximization step is %
%
\begin{equation}\label{eqn:restric_F_est}
\vec{\theta}^{(i + 1)} =
	\mat{G}^+
	\Lparen{\mat{Q}^{(i)} \otimes \Lparen{\mat{M}^\top\mat{W}\mat{M}}^{-1}}
	\mat{G}^{+\top}\mat{G}^\top	
	\vecOP{\mat{M}^\top\mat{W}\mat{N}\mat{Q}^{-(i)}}
\end{equation}%
% 
where $\otimes$ is the Kronecker product and $\mat{Q}^{-(i)}$ is the inverse 
of $\mat{Q}^{(i)}$. Equation~\eqref{eqn:restric_F_est} is easily computed 
with the QR decomposition we 
make to compute for Equation~\eqref{eqn:VARF}. Having obtained the new 
$\vec{\theta}^{(i + 1)}$, we update the variable elements of $\mat{F}$ (those 
columns "picked out" by $\mat{R}$ in $\mat{R}^+\mat{F}$) and denote the new 
estimate $\widehat{\mat{F}}^{(i + 1)}$. The second conditional maximization 
step which updates $\vec{\psi}$ and $\vec{\phi}$ is %
%
\begin{align*}
\mat{Z} &= \Lparen{\mat{N} - \mat{R}^+\widehat{\mat{F}}^{(i +1)}\mat{M}}^\top\mat{W}
           \Lparen{\mat{N} - \mat{R}^+\widehat{\mat{F}}^{(i +1)}\mat{M}} \\
\vec{\psi}^{(i+1)},\vec{\phi}^{(i+1)} &= \argmax_{\vec{\psi},\vec{\phi}} 
   -(\nPeriods - 1)\log\Lvert{\mat{Q}(\vec{\psi},\vec{\phi})}
   -\text{tr}\Lparen{\mat{Q}(\vec{\psi},\vec{\phi})^{-1}\mat{Z}}
\end{align*}%
% 
which can be done numerically. We have made $\mat{Q}$'s dependence on $\vec{\psi}$ and $\vec{\phi}$ explicit to emphasize which factors are affected. $\mat{C}$ may not be a valid correlation matrix for all $\vec\phi\in\mathbb{R}^k$ for some choices of $\mat{K}$. Thus, the numerical optimization algorithm is constrained to valid correlation matrices. This completes the two conditional maximization steps. The next E-step is then performed using $\vec{\theta}^{(i + 1)}$, $\vec{\psi}^{(i +1)}$, $\vec{\phi}^{(i + 1)}$. \citet[][see the discussion]{meng93} comments that it may be beneficial to perform an E-step between each conditional maximization step when the E-step is relatively cheap. 
This is not the case here since all the above computations are independent 
of the number observations, $\nMax$.
Thus, if we have a moderately large number of observations at each time point relative to 
the dimension of the state vector, then we will use most of the 
computation time performing the E-step.

\subsection{Estimating fixed effect coefficients}
Next, we turn to estimating the fixed effect coefficients, $\vec{\omega}$, in Equation~\eqref{eqn:model}. 
If we assume that observations, $y_{it}$s, are from an exponential family then it is easy to show that the M-step estimator amounts to generalized linear model with $\nPart_s$ observations for each $y_{it}$ which differ only by an offset term and a weight. The offset term comes from the $\vec{x}_{it}^\top\mat{R}^{+}\particS{\vec{\alpha}}{j}{t}$ term in Equation~\eqref{eqn:model} for each of the $j = 1, \dots, \nPart_s$ smoothed particles. The corresponding weights are the smoothed weights, $\particS{w}{j}{t}$. The problem can be solved in parallel using QR decompositions as in Section~\ref{subsec:VAR}. This is what is done in the current implementation.

\todoin{Currently, I only take one iteration of the iteratively re-weighted least squares. I gather I have to repeat till convergence though... This is however not nice computationally and the difference in the estimate from one M-step iteration to the next is very minor when you only take one iteratively re-weighted least square iteration...}

\section{Other filter and smoother options}
The $\bigO{\nPart^2}$ two-filter smoother in \cite{fearnhead10} is going to be computationally expensive as an approximation is going to be needed for Equation (8) in their article.
The non-auxiliary version in \citet{briers09} is more feasible as it only requires evaluation of $f$ in the smoothing part of the generalized two-filter smoother (see Equation (46) in their paper). Similar conclusions applies to the forward smoother in \cite{del10} and the backward smoother as presented in \cite{kantas15}. Both have a $\bigO{\nPart^2}$ computational cost.

Despite the $\bigO{\nPart^2}$ cost of the method in \citet{briers09} and \cite{del10} 
they may still be useful 
as the computational cost in the smoothing step is independent of the number of observations, $\nMax$.  Further, the computational cost can be reduced to 
$\bigO{\nPart\log(\nPart)}$ run times 
with approximations like in \cite{klaas06}.

The method in \citet[see particularly section 6.2 on page 203]{malik11} can be used to do continuous likelihood evaluation. I am not sure how well this method scale with higher state dimensions, $\dimState$.

\citet{kantas15} show empirically that it may be worth just using a forward filter. However, the example is with an univariate outcome ($n=1$ -- not to be confused with the number of periods $\nPeriods$). In this case, the cost of the forward filter is at least $\bigO{\nPeriods\nPart\nMax\dimState}$. Every new particle yields an $\bigO{\nPeriods\nMax\dimState}$ cost which is expensive due to the large number of outcomes, $\nMax$. Thus, the considerations are different and a $\bigO{\nPeriods\nPart\nMax\dimState + \nPart^2}$ method will not make a big difference unless $\nPart$ is large.

\section{Generalized two-filter smoother}\label{sec:Brier}
The $\bigO{\nPart^2}$ smother from \citet{briers09} is also implemented as it is feasible for a moderate number of particles (though, we can use the approximations in \Citealp{kantas15} to reduce the computational complexity). It is shown in Algorithm \ref{alg:ON2smoother}. The weights in Equation~\eqref{eqn:combineWeightO2} comes from the generalized two-filter formula. 
To motivate the smoother, we use %
%
$$
\pdensC{\vec{y}_{t:d}}{\vec{\alpha}_t} =	
	\pdenst{\vec{y}_{t:d}}\frac{
		\pdenstC{\vec{\alpha}_{t}}{\vec{y}_{t:d}}	
	} {	\gamma_t(\vec{\alpha}_t) }
$$%
%
to generalize the two-filter formula in \cite{kitagawa94} as follows %
%
\begin{align}
\pdensC{\vec{\alpha}_t}{\vec{y}_{1:\nPeriods}} &= \label{eqn:brierWeightsDerive}
	\frac{
		\pdensC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
		\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t}
	}{ \pdensC{\vec{y}_{t:\nPeriods}}{\vec{y}_{1:{t-1}}}} \\
%
& \propto \nonumber
	\pdensC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t} \\
%
& = \pdensC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}} \nonumber
	\pdenst{\vec{y}_{t:d}}\frac{
		\pdenstC{\vec{\alpha}_{t}}{\vec{y}_{t:d}}	
	} {	\gamma_t(\vec{\alpha}_t) } \\
%
& \propto \pdensC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}} \nonumber
	\frac{
		\pdenstC{\vec{\alpha}_{t}}{\vec{y}_{t:d}}	
	} {	\gamma_t(\vec{\alpha}_t) } \\
%
& = \nonumber
	\pdenstC{\vec{\alpha}_{t}}{\vec{y}_{t:d}}
	\frac{
		\Lbrac{\int
		\pdensC{\vec{\alpha}_{t-1}}{\vec{y}_{1:{t-1}}}
		\optorC{f}{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
		\diff\vec{\alpha}_{t - 1}}
	}{ \gamma_t(\vec{\alpha}_t) } \\
%
& \appropto \sum_{i=1}^\nPart \nonumber
	\particB{w}{t}{i}
	\dirac{\particB{\vec{\alpha}}{t}{i}}{\vec{\alpha}_t}
	\frac{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} }
\end{align}%
%
where $\appropto$ means approximately proportional. Similar arguments leads to %
%
\begin{equation}\begin{split}
\pdensC{\vec{\alpha}_{t - 1: t}}{\vec{y}_{1:\nPeriods}} \hspace{-25pt} & \hspace{25pt} \\
%
& \propto \pdensC{\vec{\alpha}_{t - 1 : t}}{\vec{y}_{1:{t-1}}}
	\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_{t - 1: t}} \\
%
& = \fFunc{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
	\pdensC{\vec{\alpha}_{t - 1}}{\vec{y}_{1:{t-1}}}
	\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_{t}} \\
%
& \propto \fFunc{\vec{\alpha}_t}{\vec{\alpha}_{t - 1}}
	\pdensC{\vec{\alpha}_{t - 1}}{\vec{y}_{1:{t-1}}}
	\frac{
		\pdenstC{\vec{\alpha}_{t}}{\vec{y}_{t:d}}	
	} {	\gamma_t(\vec{\alpha}_t) } \\
%
& \appropto \sum_{i=1}^\nPart\sum_{j=1}^\nPart
	\particB{w}{t}{i}
	\dirac{\particB{\vec{\alpha}}{t}{i}}{\vec{\alpha}_t}
	\frac{
		\Lbrac{\sum_{k = 1}^\nPart
		\partic{w}{t -1}{k}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{k}}}
	}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}} } \\
&\hspace{110pt}
	\cdot \frac{
		\partic{w}{t -1}{j}
		\dirac{\partic{\vec{\alpha}}{t - 1}{j}}{\vec{\alpha}_{t -1}}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{k = 1}^\nPart
		\partic{w}{t -1}{k}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{k}}}
	} \nonumber \\
%
& = \sum_{i=1}^\nPart\sum_{j=1}^\nPart
	\particS{w}{t}{i,j}
	\dirac{\particB{\vec{\alpha}}{t}{i}}{\vec{\alpha}_t}
	\dirac{\partic{\vec{\alpha}}{t - 1}{j}}{\vec{\alpha}_{t -1}} \\
\end{split}\end{equation}
%
where %
%
\begin{equation}
\particS{w}{t}{i,j} = \particS{w}{t}{i}
	\frac{
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}{
		\Lbrac{\sum_{j = 1}^\nPart
		\partic{w}{t -1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}}
	}
\end{equation} %
%
We need the latter for the EM-algorithm.

\begin{algorithm}[H]
\caption{$\bigO{\nPart^2}$ generalized two-filter smoother using the method in \citet{briers09}.}\label{alg:ON2smoother}
\begin{algorithmic}[1]\raggedright
\INPUT
\Statex $\mat{Q},\mat{Q}_0,\vec{a}_0,\mat{X}_1,\dots,\mat{X}_d,\vec{y}_1,\dots,\vec{y}_d,R_1,\dots,R_d,\vec{\omega}$
%
\Procedure{Filter forward}{}
\State Run a forward particle filter to get particle clouds %
	$\Lbrace{\partic{\vec{\alpha}}{t}{j}, \partic{w}{t}{j}, \partic{\beta}{t + 1}{j}}_{j=1,\dots,N}$ %
	approximating $\pdensC{\vec{\alpha}_t}{\vec{y}_{1:t}}$ for $t = 0, 1, \dots, \nPeriods$. See Algorithm~\ref{alg:forward}.
\EndProcedure
%
\Procedure{Filter backwards}{}
\State Run a similar backward filter to get %
	$\Lbrace{\particB{\vec{\alpha}}{t}{k}, \particB{w}{t}{k}, \particB{\beta}{t - 1}{k}}_{k=1,\dots,N}$  %
	approximating $\pdenstC{\vec{\alpha}_t}{\vec{y}_{t:\nPeriods}}$ for $t = \nPeriods + 1, \nPeriods, \nPeriods-1, \dots, 1$. See Algorithm~\ref{alg:backward}.
\EndProcedure
%
\Procedure{Smooth (combine)}{}
\For{$t=1,\dots, \nPeriods$}
\State Assign each backward filter particle a smoothing weight given by
\StateXX \begin{equation}\label{eqn:combineWeightO2}
\particS{w}{t}{i} \propto
	\particB{w}{t}{i} \frac{\Lbrac{
		\sum_{j = 1}^\nPart \partic{w}{t - 1}{j}
		\optorC{f}{\particB{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t - 1}{j}}
	}}{ \optor{\gamma_t}{\particB{\vec{\alpha}}{t}{i}}}
\end{equation}
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}

With the result above, we can show the arguments behind the 
smoother from \cite{fearnhead10}. Similar to Equation~\eqref{eqn:brierWeightsDerive} we find that 

\begin{align*}
\pdensC{\vec{\alpha}_t}{\vec{y}_{1:\nPeriods}} & \propto
	\pdensC{\vec{\alpha}_t}{\vec{y}_{1:t-1}}
	\pdensC{\vec{y}_{t:\nPeriods}}{\vec{\alpha}_t} \\
%
& = \pdensC{\vec{\alpha}_t}{\vec{y}_{1:{t-1}}}
	\gFunc{\vec{y}_t}{\vec{\alpha}_t}{t}
	\pdensC{\vec{y}_{t + 1:\nPeriods}}{\vec{\alpha}_t} \\
%
& = \int \fFunc{\vec{\alpha}_t}{\vec{\alpha}_{t-1}}
	\pdensC{\vec{\alpha}_{t - 1}}{\vec{y}_{1:t-1}}\diff\vec{\alpha}_{t-1}
	\gFunc{\vec{y}_t}{\vec{\alpha}_t}{t} \\
&\hspace{80pt}\cdot 
	\int \fFunc{\vec{\alpha}_{t + 1}}{\vec{\alpha}_t}
	\pdensC{\vec{y}_{t + 1:\nPeriods}}{\vec{\alpha}_{t + 1}} 
	\diff\vec{\alpha}_{t + 1} \\
%
&\propto \int \fFunc{\vec{\alpha}_t}{\vec{\alpha}_{t-1}}
	\pdensC{\vec{\alpha}_{t - 1}}{\vec{y}_{1:t-1}}d\vec{\alpha}_{t-1}
	\gFunc{\vec{y}_t}{\vec{\alpha}_t}{t}\\
&\hspace{80pt}\cdot
	\int \fFunc{\vec{\alpha}_{t + 1}}{\vec{\alpha}_t}
	\frac{
		\pdenstC{\vec{\alpha}_{t + 1}}{\vec{y}_{t + 1:\nPeriods}}	
	} {	\gamma_{t + 1}(\vec{\alpha}_{t + 1}) } 
	\diff\vec{\alpha}_{t + 1} \\
%
& \appropto \sum_{i=1}^\nPart\sum_{j=1}^\nPart
	\fFunc{\vec{\alpha}_t}{\partic{\vec{\alpha}}{t-1}{j}}	
	\partic{w}{t -1}{j}
	\gFunc{\vec{y}_t}{\vec{\alpha}_t}{t}
	\fFunc{\particB{\vec{\alpha}}{t + 1}{i}}{\vec{\alpha}_t}
	\frac{
		\particB{w}{t + 1}{i}
	} {	\gamma_{t + 1}(\particB{\vec{\alpha}}{t + 1}{i}) }
\end{align*}%
%
Thus, we can sample $\vec{\alpha}_t$ from a proposal distribution given the time $t - 1$ forward filter particle, $\partic{\vec{\alpha}}{t-1}{j}$, and time $t + 1$ backward filter particle, $\particB{\vec{\alpha}}{t + 1}{i}$, for all $\nPart^2$ particle pairs. Alternatively, we can sample the $t - 1$ and $t + 1$ particles independently which yields Algorithm~\ref{alg:ONsmoother}. Further, we can find that%
%
\begin{align*}
\pdensC{\vec{\alpha}_{t - 1:t}}{\vec{y}_{1:\nPeriods}} &=
	\pdensC{\vec{\alpha}_{t - 1:t}}{\vec{y}_{1:{t-1}}}
	\gFunc{\vec{y}_t}{\vec{\alpha}_{t - 1: t}}{t}
	\pdensC{\vec{y}_{t + 1:\nPeriods}}{\vec{\alpha}_{t - 1 : t}} \\
%
&\propto \fFunc{\vec{\alpha}_t}{\vec{\alpha}_{t-1}}
	\pdensC{\vec{\alpha}_{t - 1}}{\vec{y}_{1:t-1}}
	\gFunc{\vec{y}_t}{\vec{\alpha}_t}{t} \\
&\hspace{100pt}\cdot
	\int \fFunc{\vec{\alpha}_{t + 1}}{\vec{\alpha}_t}
	\frac{
		\pdenstC{\vec{\alpha}_{t + 1}}{\vec{y}_{t + 1:\nPeriods}}	
	} {	\gamma_{t + 1}(\vec{\alpha}_{t + 1}) } 
	\diff\vec{\alpha}_{t + 1} \\
%
& \appropto \sum_{i=1}^{\nPart_s}
	\dirac{\particS{\vec{\alpha}}{t}{i}}{\vec{\alpha}_t}
	\dirac{\partic{\vec{\alpha}}{t-1}{j_i}}{\vec{\alpha}_t}
	\fFunc{\particS{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j_i}}	
	\partic{w}{t - 1}{j_i}
	\gFunc{\vec{y}_t}{\particS{\vec{\alpha}}{t}{i}}{t}\\
&\hspace{100pt}\cdot
	\int \fFunc{\vec{\alpha}_{t + 1}}{\particS{\vec{\alpha}}{t}{i}}
	\frac{
		\pdenstC{\vec{\alpha}_{t + 1}}{\vec{y}_{t + 1:\nPeriods}}	
	} {	\gamma_{t + 1}(\vec{\alpha}_{t + 1}) } 
	\diff\vec{\alpha}_{t + 1} \\
%
& \appropto \sum_{i=1}^{\nPart_s}
	\particS{w}{t}{i}
	\dirac{\particS{\vec{\alpha}}{t}{i}}{\vec{\alpha}_t}
	\dirac{\partic{\vec{\alpha}}{t-1}{j_i}}{\vec{\alpha}_t}
\end{align*}
%
where superscripts $j_i$ are used as in Algorithm~\ref{alg:ONsmoother} which implicitly dependent on $t$.

\section{Gradient and observed information matrix}
An alternative to the EM-algorithm is to approximate the gradient and use it to perform the maximization
with a gradient descent algorithm. 
Moreover, one may be interested in the observed information matrix in order to perform parameter inference. 
Two methods are implemented in order to make such approximations. The first method is the method 
covered in  \citet[section 8.3 and chapter 11]{cappe05}. It has the advantage that it uses the output from 
the forward particle filter. However, the variance of the estimates increase at least quadratically in time, $d$. 
An alternative is to use the method shown by \cite{poyiadjis11}. Like the smoothing algorithm from 
\cite{briers09}, this method has the disadvantage of having a computational complexity which is quadratic 
in the number of particles, $\nPart$.

I will give a brief introduction to the two methods in this section. What is presented here closely follow 
\cite{poyiadjis11}. First, we will need some notation. We denote the complete data
log likelihood by %
%
\begin{align*}
c\Lparen{\vec y_{1:t}, \vec\alpha_{0:t}} &= \log h\Lparen{\vec y_{1:t}, \vec\alpha_{0:t}} \\
%
h\Lparen{\vec y_{1:t}, \vec\alpha_{0:t}} &= 
	\nu\Lparen{\vec\alpha_0}\prod_{k = 1}^t 
	\optorC{g_k}{\vec y_k}{\vec\alpha_k}
	\optorC{f}{\vec\alpha_k}{\vec\alpha_{k - 1}}
\end{align*}% 
% 
where $\nu$ is the density function of the state vector at time zero, 
all functions may implicitly depend on the unknown parameters, 
and the dimension of the arguments to $c$ and $h$ is given 
by the superscript of the arguments. A direct application of the results by \cite{louis82}
shows that the gradient of the observed data log likelihood %
%
$$o\Lparen{\vec y_{1:t}} = 
	\log \int h\Lparen{\vec y_{1:t}, \vec a_{0:t}}\diff\vec a_{0:t}$$
%
w.r.t. the unknown parameters are %
%
\begin{align}
\nabla o\Lparen{\vec y_{1:t}}
&= \frac{\partial}{\partial\vec\theta} \log \int h\Lparen{\vec y_{1:t}, \vec a_{0:t}} 
		\diff\vec a_{0:t}
%
= \frac{\int h'\Lparen{\vec y_{1:t}, \vec a_{0:t}}d\vec a_{0:t}
	}{
	\int h\Lparen{\vec y_{1:t}, \vec a_{0:t}}\diff\vec a_{0:t}}\label{eqn:ONscore}\\
%
&= \int c'\Lparen{\vec y_{1:t}, \vec a_{0:t}}\optorC{p}{\vec a_{0:t}}{\vec y_{1:t}}
	\diff\vec a_{0:t}\nonumber
\end{align}%
% 
where $\vec\theta$ are the unknown parameters in the model, 
derivatives are w.r.t. $\vec\theta$, and 
$\optorC{p}{\vec a_{0:t}}{\vec y_{1:t}}$ is the conditional density function of 
$\vec a_{0:t}$ given $\vec y_{1:t}$. Moreover, the Hessian is%
%
\begin{align}
\nabla^2 o\Lparen{\vec y_{1:t}}
&= \frac{\int h''\Lparen{\vec y_{1:t}, \vec a_{0:t}}d\vec a_{0:t}}{
	\int h\Lparen{\vec y_{1:t}, \vec a_{0:t}}\diff\vec a_{0:t}} - 
	 \nabla o\Lparen{\vec y_{1:t}}
	 \nabla o\Lparen{\vec y_{1:t}}^\top \nonumber\\
%
&= \int c''\Lparen{\vec y_{1:t}, \vec a_{0:t}}\optorC{p}{\vec a_{0:t}}{\vec y_{1:t}}
	\diff\vec a_{0:t} \label{eqn:ONsqHess}\\
&\hspace{20pt}+\int c'\Lparen{\vec y_{1:t}, \vec a_{0:t}}
    c'\Lparen{\vec y_{1:t}, \vec a_{0:t}}^\top
	\optorC{p}{\vec a_{0:t}}{\vec y_{1:t}}\diff\vec a_{0:t} 
	- \nabla o\Lparen{\vec y_{1:t}}
	  \nabla o\Lparen{\vec y_{1:t}}^\top \nonumber
\end{align}

We can use that the forward particle filter yields not just an approximation of 
$\optorC{p}{\vec a_{d}}{\vec y_{1:d}}$ but the entire path 
$\optorC{p}{\vec a_{0:d}}{\vec y_{1:d}}$. That is, we can use the weights at time 
$d$ from Equation \eqref{eqn:forwardWeight} and make a discrete approximation 
of Equation \eqref{eqn:ONscore} and \eqref{eqn:ONsqHess} as shown in \cite{cappe05}. 
However, the variance of the estimates grows at-least quadratically in $d$ as shown 
by \cite{poyiadjis11}; For larger $d$, then few if not only one unique value 
of the initial state vector values ($\vec\alpha_i$ with $0\leq i <\!\!< d$) 
are present in the discrete approximation.  

As an alternative, \cite{poyiadjis11} develop a marginal 
version of Equation \eqref{eqn:ONscore} and \eqref{eqn:ONsqHess}. 
That is,  %
%
\begin{align}
\tilde c\Lparen{\vec y_{1:t}, \vec\alpha_t} &= 
	\log\tilde h\Lparen{\vec y_{1:t}, \vec\alpha_t} \nonumber\\
%
\tilde h\Lparen{\vec y_{1:t}, \vec\alpha_t} &=
	\begin{cases} 
	\optorC{g_t}{\vec y_t}{\vec\alpha_t}	
	\int 
	\optorC{f}{\vec\alpha_t}{\vec a_{t - 1}}	
	\tilde h\Lparen{\vec y_{1:(t - 1)}, \vec a_{t- 1}}\diff\vec a_{t-1} & t > 0 \\
	\nu\Lparen{\vec a_{t}} & t = 0
	\end{cases}	
	\label{eqn:scoreNSqArg2} \\
%
\nabla o\Lparen{\vec y_{1:t}}
&= \int \tilde c'\Lparen{\vec y_{1:t}, \vec a_t}\optorC{p}{\vec a_t}{\vec y_{1:t}}
	\diff\vec a_t \label{eqn:scoreNsq}\\
%
\nabla^2 o\Lparen{\vec y_{1:t}}
&= \int \tilde c''\Lparen{\vec y_{1:t}, \vec a_t}\optorC{p}{\vec a_t}{\vec y_{1:t}}
	\diff\vec a_t \nonumber\\
&\hspace{20pt}+\int 
	\tilde c'\Lparen{\vec y_{1:t}, \vec a_t}
    \tilde c'\Lparen{\vec y_{1:t}, \vec a_t}^\top
	\optorC{p}{\vec a_t}{\vec y_{1:t}}\diff\vec a_t 
	- \nabla o\Lparen{\vec y_{1:t}}
	 \nabla o\Lparen{\vec y_{1:t}}^\top \nonumber\\
%
&= \int \Lparen{
	\frac{%
	\tilde h''\Lparen{\vec y_{1:t}, \vec a_t}}{
	\tilde h  \Lparen{\vec y_{1:t}, \vec a_t}}
	- \tilde c'\Lparen{\vec y_{1:t}, \vec a_t}
      \tilde c'\Lparen{\vec y_{1:t}, \vec a_t}^\top}
	\optorC{p}{\vec a_t}{\vec y_{1:t}}
	\diff\vec a_t \label{eqn:hessNsq}\\
&\hspace{20pt}+\int 
	\tilde c'\Lparen{\vec y_{1:t}, \vec a_t}
    \tilde c'\Lparen{\vec y_{1:t}, \vec a_t}^\top
	\optorC{p}{\vec a_t}{\vec y_{1:t}}\diff\vec a_t 
	- \nabla o\Lparen{\vec y_{1:t}}
	 \nabla o\Lparen{\vec y_{1:t}}^\top \nonumber
\end{align}

While there is no analytical expression for the derivatives then one can 
establish a pointwise approximation recursively
for $c'\Lparen{\vec y_{1:t}, \vec a_t}$ and $c''\Lparen{\vec y_{1:t}, \vec a_t}$ 
as suggested by \cite{poyiadjis11}. Let%
%
$$
s_t\Lparen{\vec\alpha_t, \vec\alpha_{t - 1}} 
	= \log\optorC{g_k}{\vec y_t}{\vec \alpha_t} + 
		\log\optorC{f}{\vec\alpha_t}{\vec\alpha_{t - 1}}
$$%
% 
Then 
%
\begin{align}
\tilde h'\Lparen{\vec y_{1:t}, \vec\alpha_t}
	&= o\Lparen{\vec y_{1:{t - 1}}}\optorC{g_t}{\vec y_t}{\vec\alpha_t}
	\int \optorC{f}{\vec\alpha_t}{\vec a_{t - 1}}
		\optorC{p}{\vec a_{t - 1}}{\vec y_{1:{t - 1}}} \label{eqn:scoreNSqArg1}\\
&\hspace{75pt}\cdot
		\Lparen{s_t'\Lparen{\vec\alpha_t, \vec a_{t - 1}}
			+
		\tilde c'\Lparen{\vec y_{1:(t - 1)}, \vec a_{t - 1}}}
		\diff\vec a_{t - 1} \nonumber
\end{align}%
%
Taking the ratio of Equation \eqref{eqn:scoreNSqArg1} and \eqref{eqn:scoreNSqArg2}
yields $\tilde c'\Lparen{\vec y_{1:t}, \vec\alpha_t}$ in Equation \eqref{eqn:scoreNsq}.
Moreover, for Equation \eqref{eqn:hessNsq} %
%
\begin{align*}
\tilde h''\Lparen{\vec y_{1:t}, \vec\alpha_t}
	&= o\Lparen{\vec y_{1:{t - 1}}}\optorC{g_t}{\vec y_t}{\vec\alpha_t}
	\int\optorC{f}{\vec\alpha_t}{\vec a_{t - 1}}
	\optorC{p}{\vec a_{t - 1}}{\vec y_{1:{t - 1}}}\nonumber\\
&\hspace{15pt}\cdot
		\left(\vphantom{\int}\right.
		\Lparen{s_t'\Lparen{\vec\alpha_t, \vec a_{t - 1}}
			+ \tilde c'\Lparen{\vec y_{1:(t - 1)}, \vec a_{t - 1}}} 
		\Lparen{s_t'\Lparen{\vec\alpha_t, \vec a_{t - 1}}
			+ \tilde c'\Lparen{\vec y_{1:(t - 1)}, \vec a_{t - 1}}}^\top \\
&\hspace{28pt}+
		s_t''\Lparen{\vec\alpha_t, \vec a_{t - 1}} + 
		\tilde c''\Lparen{\vec y_{1:(t - 1)}, \vec a_{t - 1}}
		\left.\vphantom{\int}\right)\diff\vec a_{t - 1}\nonumber
\end{align*}%
% 
where we again take the ratio with \eqref{eqn:scoreNSqArg2}. Unlike before, 
we need to evaluate two ratios, 
$\tilde h'\Lparen{\vec y_{1:t}, \vec a_t}/\tilde h\Lparen{\vec y_{1:t}, \vec a_t}$
and
$\tilde h''\Lparen{\vec y_{1:t}, \vec a_t}/\tilde h\Lparen{\vec y_{1:t}, \vec a_t}$, 
which require evaluation of expressions of the form%
%
\begin{equation}\label{eqn:NsqNeedApprox}
\frac{\int\optorC{f}{\vec\alpha_t}{\vec a_{t - 1}}
	\optorC{p}{\vec a_{t - 1}}{\vec y_{1:{t - 1}}}
	\kappa_t\Lparen{\vec\alpha_t, \vec a_{t - 1}}
	d\vec a_{t - 1}}{
	\int\optorC{f}{\vec\alpha_t}{\vec a_{t - 1}}
	\optorC{p}{\vec a_{t - 1}}{\vec y_{1:{t - 1}}}
	\diff\vec a_{t - 1}}
\end{equation}%
% 
for some function $\kappa_t$. To do so, redefine the weights 
in Equation \eqref{eqn:forwardWeight} in the forward particle filter shown 
in Algorithm \ref{alg:forward} to %
%
\begin{align*}
\partic{w}{t}{i} \propto \frac{
		\gFunc{\vec{y}_t}{\partic{\vec{\alpha}}{t}{i}}{t}
		\sum_{j=1}^N\fFunc{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j}}
		\partic{w}{t-1}{j}
	}{
		\IDC{\partic{\vec{\alpha}}{t}{i}}{
		\Lbrace{\Lparen{
			\partic{\vec{\alpha}}{t-1}{j}, \partic{w}{t-1}{j}}}_{j=1,\dots,N}, \vec{y}_t}
	}
\end{align*}%
% 
where we have made it explicit that the proposal distribution may depend on 
the previous particle cloud and assume that we use the same number of particles 
at time 0. Further, define the weights
%
\begin{equation}\label{eqn:NsqGradWeights}
\partic{\bar w}{t}{i,j} = 
	\frac{
	\fFunc{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{j}}
	\partic{w}{t-1}{j}}{
	\sum_{k=1}^N\fFunc{\partic{\vec{\alpha}}{t}{i}}{\partic{\vec{\alpha}}{t-1}{k}}
	\partic{w}{t-1}{k}
	}
\end{equation}
%
Now a discrete approximation of expression in 
Equation \eqref{eqn:NsqNeedApprox} is given by %
%
$$
\sum_{j=1}^N 
\partic{\bar w}{t}{i,j}
\kappa_t\Lparen{
	\partic{\vec{\alpha}}{t}{i}, \partic{\vec{\alpha}}{t-1}{j}}
$$
%
Thus, the recursive formula for the gradient approximation is 
%
\begin{align}
\partic{\vec\zeta}{t}{i} &= \sum_{j = 1}^N
	\partic{\bar w}{t}{i,j}\Lparen{
	s_t'\Lparen{\partic{\vec{\alpha}}{t}{i}, 
		\partic{\vec{\alpha}}{t-1}{j}} +  
		\partic{\vec\zeta}{t-1}{j}}\label{eqn:NSqGrad}\\
%
\nabla o\Lparen{\vec y_{1:t}} &\approx 
	\sum_{i = 1}^N
	\partic{w}{t}{i}\partic{\vec\zeta}{t}{i}\nonumber
\end{align}
%
and for the Hessian we have %
%
\begin{align}
\partic{\mat\Upsilon}{t}{i} &= \sum_{j = 1}^N
	\partic{\bar w}{t}{i,j}
	\left(\vphantom{\int}\right.
		\Lparen{s_t'\Lparen{
			\partic{\vec{\alpha}}{t}{i}, 
			\partic{\vec{\alpha}}{t-1}{j}}
			+ \partic{\vec\zeta}{t-1}{j}} 
		\Lparen{s_t'\Lparen{
			\partic{\vec{\alpha}}{t}{i}, 
			\partic{\vec{\alpha}}{t-1}{j}}
			+ \partic{\vec\zeta}{t-1}{j}}^\top\label{eqn:NSqHess} \\
&\hspace{75pt}+
		s_t''\Lparen{
			\partic{\vec{\alpha}}{t}{i}, 
			\partic{\vec{\alpha}}{t-1}{j}} + 
		\partic{\mat\Upsilon}{t - 1}{j}
		\left.\vphantom{\int}\right) - 
		\partic{\vec\zeta}{t}{i}\vec\zeta_t^{(i)\top}\nonumber
\end{align}%
% 
such that %
%
$$
\nabla^2 o\Lparen{\vec y_{1:t}} \approx 
	\sum_{i = 1}^N
	\partic{w}{t}{i}\Lparen{
		\partic{\vec\zeta}{t}{i}\vec\zeta_t^{(i)\top}
		+ \partic{\mat\Upsilon}{t}{i}}
	- \nabla o\Lparen{\vec y_{1:t}}
	  \nabla o\Lparen{\vec y_{1:t}}^\top
$$

The issue with the latter method is that the method has an $\bigO{\nPart^2}$ 
computational complexity because of the sums in Equation \eqref{eqn:NsqGradWeights}, 
\eqref{eqn:NSqGrad}, and \eqref{eqn:NSqHess}. A particular type of particle filters
that are well suited for approximations like those in Equation \eqref{eqn:NsqNeedApprox}
are the so-called independent particle filters
suggest by \cite{Lin05}. The key point in these filters is that they 
use a proposal distribution 
which only depends on the observed outcome, $\vec y_t$, or also the previous particle 
cloud but not any particular particle. 

An alternative to the methods in the \texttt{dynamichazard} package is the \texttt{mssm} package. It contains 
both the method shown in \cite{cappe05} and the method suggested by \cite{poyiadjis11} but for more general 
models. Moreover, the \texttt{mssm} package has an implementation of the dual k-d tree approximation method like in 
\cite{klaas06}. This reduces the average-case complexity to $\bigO{\nPart\log\nPart}$ and allows one 
to use substantially more particles. Lastly, the \texttt{mssm} also allows for two types of 
antithetic variables like those suggest by \cite{Durbin97}. This decreases the variance of the estimates for 
the same computational cost.


\newpage
\bibliographystyle{plainnat}
\bibliography{PF}

\end{document}
