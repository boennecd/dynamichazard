---
title: "Note on convergenec issues with EKF"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Convergence issues

Sometimes the Extended Kalman filter (EKF) fails to convergence like in the case below (details of the simulation function is omitted to shorten this note):

```{r}
# Source script with simulation function
gsub("(^.*)(dynamichazard.*)", ".../\\2", getwd()) # We are in the vignettes folder
source("../R/test_utils.R")

set.seed(28650)
sim_args <- list(n_series = 1e4, n_vars = 10, t_0 = 0, t_max = 10,
                 x_range = 1, x_mean = 0, re_draw = T, beta_start = 0,
                 intercept_start = -5, sds = c(.1, rep(1, 10)))
sims <- do.call(test_sim_func_exp, sim_args)

library(dynamichazard)                
arg_list <- list(
  formula = survival::Surv(tstart, tstop, event) ~ . - id - tstart - tstop - event,
  data = sims$res,
  by = (by_ <- 1),
  n_max = 10^4, eps = 10^-2,
  a_0 = rep(0, 11),
  Q_0 = diag(100, 11),
  Q = diag(1e-3, 11),
  est_Q_0 = F,
  max_T = 10,
  id = sims$res$id, order_ = 1,
  model = "exponential")

try(do.call(ddhazard, arg_list))
```

## Solution
We can follow the suggestion at page 504 in for Fahrmeir, Ludwig. *Posterior mode estimation by extended Kalman filtering for multivariate dynamic generalized linear models*. Journal of the American Statistical Association 87.418 (1992): 501-509. That is, recognize that the filter step is a Newton Rapshon (NR) algorithm where we only take a single step

To make this more concrete let us return to what we currently do. Currently, we take the current estimate $\vec{a}_{t|t-1}$ and $\mathbf{V}_{t|t-1}$, compute:
$$\begin{array}{c}
  \vec{a} = \vec{a}_{t|t-1} \\
  \vec{u}_t(\vec{a}) = \sum_{i \in R_t} \vec{x_{it}} 
    \left. \frac{\partial h(\eta) / \partial\eta}{\widehat{\text{Var}}(y_{it})} (y_{it} - h(\eta))  \right|_{\eta = \vec{x}_{it}^T\vec{\alpha}} \\
  \mathbf{U}_t(\vec{a}) = \sum_{i \in R_t} \vec{x_{it}}\vec{x_{it}}^T
    \left. \frac{\left(\partial h(\eta) / \partial\eta\right)^2}{\widehat{\text{Var}}(y_{it})}  \right|_{\eta = \vec{x}_{it}^T\vec{\alpha}} \\
  \widehat{\mathbf{V}} = \mathbf{F}\mathbf{V}_{t-1 | t-1}\mathbf{F} + \mathbf{Q} \\
  \widehat{\vec{\alpha}} = \vec{a} +  \widehat{\mathbf{V}}\vec{u}_t(\vec{a})
\end{array}$$

where $h$ is the link function. We then set $\mathbf{V}_{t|t} = \widehat{\mathbf{V}}$ and $\vec{a}_{t|t} = \widehat{\vec{\alpha}}$. Fahrmier suggests to take further iteration if $\widehat{\vec{\alpha}}$ is far from $\vec{\alpha}$ with $\vec{\alpha} = \widehat{\vec{\alpha}}$. I further propose to add a learning rate $l$ such that we set:
$$\widehat{\vec{\alpha}} = \vec{a} +  l \cdot \widehat{\mathbf{V}}\vec{u}_t(\vec{a})$$

The motivation is that divergence seems to happen due to "over-stepping" (I figure this is the right term?). Hence, we may solve the issue by setting $l<1$

## Implementation
I have implemented both of the above. Passing a list with `NR_eps` will cause the algorithm to potentially take multiple NR steps. At the end of each NR iteration, we test whether the relative norm ($\lVert\widehat{\vec{\alpha}} - \vec{\alpha}\rVert/(\lVert\vec{\alpha}\rVert + 10^{-6})$) is less then `NR_eps`. We take an extra iteration if not. The code below shows that this does not solve the issue:

```{r}
arg_list$control <- list(NR_eps = 1e-4)
try(do.call(ddhazard, arg_list))
```

Another idea is to set the learning rate $l$. We do so by passing a control list with an `LR` element. This makes the method converge


```{r}
arg_list$control <- list(LR = .75)
fit <- do.call(ddhazard, arg_list)
```

A question is how well we estimate the coefficients. The plot below shows that the estimates somewhat match the coefficients:

```{r}
matplot(seq_len(nrow(sims$betas)) - 1, sims$betas, type = "l", lty = 1, 
        ylim = range(sims$betas, fit$a_t_d_s), 
        xlab = "Interval", ylab = "Coeffecient")
matplot(fit$times, fit$a_t_d_s, type = "l", lty = 2, add = T)
  
mean((fit$a_t_d_s - sims$betas)^2)
```

Dashed lines are estimates while continuous lines are true coefficients. Note that we print the mean square error in the end. A further point is that both taking multiple iterations and adding a learning rate provides lower mean square error as shown below:

```{r}
arg_list$control <- c(arg_list$control, list(NR_eps = 1e-4))
fit <- do.call(ddhazard, arg_list)

matplot(seq_len(nrow(sims$betas)) - 1, sims$betas, type = "l", lty = 1, 
        ylim = range(sims$betas, fit$a_t_d_s), 
        xlab = "Interval", ylab = "Coeffecient")
matplot(fit$times, fit$a_t_d_s, type = "l", lty = 2, add = T)
  
mean((fit$a_t_d_s - sims$betas)^2)
```

Another question is what would have happens with other outcomes of the same simulation. Thus, we simulate a number of set of series below. For each set, we fit four models: 

1) "Regular" being with no extra NR repetition and a learning rate of 1
2) "Only extra rep" with potentially extra NR repetitions and a learning rate of 1
3) "Only learning rate" with a learning rate below 1 and no extra NR repetitions
4) 2) and 3) combined which we denote "Combined"

Each of the models are then compared in terms of mean square error of the coefficient estimates

```{r}
mse_func <- function(f, s) 
  mean((f$a_t_d_s - s$betas)^2)

n_series <- 2
MSE_res <- matrix(
  NA_real_, ncol = 4, nrow = n_series, dimnames = 
    list(NULL, c("Regular", "Only extra rep", "Only learning rate", "Combined")))

set.seed(20161002) # A good day
for(i in 1:n_series){
  sims <- do.call(test_sim_func_exp, sim_args)
  
  arg_list$data <- sims$res
  arg_list$id <- sims$res$id
  arg_list$control <- NULL
  
  # Regular method
  try({
    fit <- do.call(ddhazard, arg_list)
    MSE_res[i, 1] <- mse_func(fit, sims)
  })
  
  # Only extra NR iterations
  arg_list$control <- list(NR_eps = 1e-4)
  try({
    fit <- do.call(ddhazard, arg_list)
    MSE_res[i, 2] <- mse_func(fit, sims)
  })
  
  # Only learning rate
  arg_list$control <- list(LR = .75)
  try({
    fit <- do.call(ddhazard, arg_list)
    MSE_res[i, 3] <- mse_func(fit, sims)
  })
  
  # Combined
  arg_list$control <- list(LR = .75, NR_eps = 1e-4)
  try({
    fit <- do.call(ddhazard, arg_list)
    MSE_res[i, 4] <- mse_func(fit, sims)
  })
}

MSE_res
colMeans(MSE_res[complete.cases(MSE_res),])
```

The two last printouts are the mean square errors and the average of the mean square errors in the case where all four fits were successful. The main take away seems to be that the extra NR repetitions may be worth it in terms of lower mean square error. Further, the learning rate seem to enable us to fit the model 

However, this adds two new tuning parameters. I figure these can be chosen through generalized cross validation or a similar schema
